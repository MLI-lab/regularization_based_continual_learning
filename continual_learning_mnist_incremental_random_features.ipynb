{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continual learning on the MNIST incremental learning task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision import datasets\n",
    "from torch.nn import functional as F\n",
    "#from torch import nn\n",
    "from torch import autograd\n",
    "\n",
    "from include import *\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and test data loaders for incremental MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "import torchvision.transforms as T\n",
    "train_data = datasets.MNIST(root = './data', train = True,\n",
    "                        transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: torch.flatten(x/255.))]),#transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_data = datasets.MNIST(root = './data', train = False,\n",
    "                       transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: torch.flatten(x/255.))]) #transform = transforms.ToTensor()\n",
    "                          )\n",
    "\n",
    "def get_indices(dataset,classes):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        if dataset.targets[i] in classes:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "pairs = [ [0,1],[2,3],[4,5],[6,7],[8,9] ]\n",
    "\n",
    "for pair in pairs:\n",
    "    idx = get_indices(train_data, pair)\n",
    "    train_loaders += [torch.utils.data.DataLoader(train_data,batch_size=batch_size, sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))]\n",
    "    idx = get_indices(test_data, pair)\n",
    "    test_loaders += [torch.utils.data.DataLoader(test_data,batch_size=batch_size, sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders_all = []\n",
    "test_loaders_all = []\n",
    "pairs = [ [0,1],[0,1,2,3],[0,1,2,3,4,5],[0,1,2,3,4,5,6,7],[0,1,2,3,4,5,6,7,8,9] ]\n",
    "\n",
    "for pair in pairs:\n",
    "    idx = get_indices(train_data, pair)\n",
    "    train_loaders_all += [torch.utils.data.DataLoader(train_data,batch_size=batch_size, sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))]\n",
    "    idx = get_indices(test_data, pair)\n",
    "    test_loaders_all += [torch.utils.data.DataLoader(test_data,batch_size=batch_size, sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to evaluate the EWC variants, and training on all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_gen,ewc,num_epochs=20):\n",
    "    optimizer = torch.optim.Adam( model.parameters(), lr=lr)\n",
    "    #optimizer = torch.optim.SGD( model.parameters(), lr=lr)    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i ,(images,labels) in enumerate(train_gen):\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss_function = nn.MSELoss()\n",
    "            labels = torch.nn.functional.one_hot(labels,num_classes=10).to(torch.float32)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            #if i==0 and epoch==0:\n",
    "            #    print(\"std:\",loss.data)\n",
    "            loss += ewc.loss(model)\n",
    "            #if i==0 and epoch==0:\n",
    "            #    print(\"ewc:\",loss.data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i == 0: #and epoch == num_epochs - 1:\n",
    "                print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data.item()))\n",
    "\n",
    "\n",
    "def test_model(model,test_gen):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images,labels in test_gen:\n",
    "        images = Variable(images).cuda()\n",
    "        labels = labels.cuda()\n",
    "  \n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output,1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        total += labels.size(0)\n",
    "    #return ((100.0*correct)/(total+1))\n",
    "    return ((100.0*correct)/(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(net,train_loader,test_loader,ewc,num_epochs=20):\n",
    "    #net = Net(input_size, hidden_size, num_classes).cuda()\n",
    "    num_tasks = len(train_loader)\n",
    "    res = np.zeros(num_tasks)\n",
    "    individual_errors = []\n",
    "    for k in range(num_tasks): \n",
    "        \n",
    "        # train model\n",
    "        train_model(net,train_loader[k],ewc,num_epochs=num_epochs)\n",
    "        # compute Hessian before updating\n",
    "        if ewc.lam>0 and k < num_tasks-1:\n",
    "            #ewc.compute_data( net,train_loader[k] )\n",
    "            ewc.update( net,train_loader[k] )\n",
    "\n",
    "        inderrors = []\n",
    "        for i in range(k+1):\n",
    "            erri = test_model(net,test_loader[i])\n",
    "            inderrors += [erri.cpu().numpy()]\n",
    "            res[k] += erri / (k+1)\n",
    "        print(\"test performance : \", res)\n",
    "        print(\"individual errors: \", inderrors)\n",
    "        individual_errors += [inderrors]\n",
    "    return res,individual_errors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model_plain(model,train_gen,num_epochs=20):\n",
    "    optimizer = torch.optim.Adam( model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i ,(images,labels) in enumerate(train_gen):\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss_function = nn.MSELoss()\n",
    "            labels = torch.nn.functional.one_hot(labels,num_classes=10).to(torch.float32)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            if i == 0: #and epoch == num_epochs - 1:\n",
    "                print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, loss.data.item()))\n",
    "\n",
    "def train_on_all(net,train_loader,test_loader,num_epochs=20):\n",
    "    #net = Net(input_size, hidden_size, num_classes).cuda()\n",
    "    num_tasks = len(train_loader)\n",
    "    res = np.zeros(num_tasks)\n",
    "    for k in range(num_tasks):\n",
    "        ### get new model\n",
    "        net = get_random_feature_model()\n",
    "        train_model_plain(net, train_loader[k] ,num_epochs=num_epochs)\n",
    "        res[k] = test_model(net,test_loader[k])\n",
    "        print(\"test performance : \", res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random feature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "  \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def get_random_feature_model(input_size = 784,hidden_size = 4*784,num_classes = 10):\n",
    "    net = Net(input_size, hidden_size, num_classes).cuda()\n",
    "    for param in net.fc1.parameters():\n",
    "        param.requires_grad = False\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 60\n",
    "lr = 1e-1 # size of step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  50 1e-05\n",
      "Epoch [1/60], Loss: 0.1025\n",
      "Epoch [2/60], Loss: 0.1506\n",
      "Epoch [3/60], Loss: 0.0640\n",
      "Epoch [4/60], Loss: 0.0357\n",
      "Epoch [5/60], Loss: 0.0291\n",
      "Epoch [6/60], Loss: 0.0245\n",
      "Epoch [7/60], Loss: 0.0188\n",
      "Epoch [8/60], Loss: 0.0163\n",
      "Epoch [9/60], Loss: 0.0126\n",
      "Epoch [10/60], Loss: 0.0106\n",
      "Epoch [11/60], Loss: 0.0094\n",
      "Epoch [12/60], Loss: 0.0076\n",
      "Epoch [13/60], Loss: 0.0060\n",
      "Epoch [14/60], Loss: 0.0062\n",
      "Epoch [15/60], Loss: 0.0054\n",
      "Epoch [16/60], Loss: 0.0056\n",
      "Epoch [17/60], Loss: 0.0051\n",
      "Epoch [18/60], Loss: 0.0042\n",
      "Epoch [19/60], Loss: 0.0048\n",
      "Epoch [20/60], Loss: 0.0043\n",
      "Epoch [21/60], Loss: 0.0050\n",
      "Epoch [22/60], Loss: 0.0045\n",
      "Epoch [23/60], Loss: 0.0040\n",
      "Epoch [24/60], Loss: 0.0044\n",
      "Epoch [25/60], Loss: 0.0041\n",
      "Epoch [26/60], Loss: 0.0039\n",
      "Epoch [27/60], Loss: 0.0041\n",
      "Epoch [28/60], Loss: 0.0044\n",
      "Epoch [29/60], Loss: 0.0039\n",
      "Epoch [30/60], Loss: 0.0038\n",
      "Epoch [31/60], Loss: 0.0039\n",
      "Epoch [32/60], Loss: 0.0044\n",
      "Epoch [33/60], Loss: 0.0043\n",
      "Epoch [34/60], Loss: 0.0037\n",
      "Epoch [35/60], Loss: 0.0035\n",
      "Epoch [36/60], Loss: 0.0038\n",
      "Epoch [37/60], Loss: 0.0035\n",
      "Epoch [38/60], Loss: 0.0031\n",
      "Epoch [39/60], Loss: 0.0035\n",
      "Epoch [40/60], Loss: 0.0031\n",
      "Epoch [41/60], Loss: 0.0037\n",
      "Epoch [42/60], Loss: 0.0029\n",
      "Epoch [43/60], Loss: 0.0036\n",
      "Epoch [44/60], Loss: 0.0029\n",
      "Epoch [45/60], Loss: 0.0022\n",
      "Epoch [46/60], Loss: 0.0029\n",
      "Epoch [47/60], Loss: 0.0026\n",
      "Epoch [48/60], Loss: 0.0033\n",
      "Epoch [49/60], Loss: 0.0029\n",
      "Epoch [50/60], Loss: 0.0031\n",
      "Epoch [51/60], Loss: 0.0027\n",
      "Epoch [52/60], Loss: 0.0027\n",
      "Epoch [53/60], Loss: 0.0029\n",
      "Epoch [54/60], Loss: 0.0044\n",
      "Epoch [55/60], Loss: 0.0040\n",
      "Epoch [56/60], Loss: 0.0029\n",
      "Epoch [57/60], Loss: 0.0026\n",
      "Epoch [58/60], Loss: 0.0021\n",
      "Epoch [59/60], Loss: 0.0026\n",
      "Epoch [60/60], Loss: 0.0030\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(471.7063, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.810875, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1603\n",
      "Epoch [2/60], Loss: 0.2117\n",
      "Epoch [3/60], Loss: 0.1829\n",
      "Epoch [4/60], Loss: 0.1077\n",
      "Epoch [5/60], Loss: 0.0999\n",
      "Epoch [6/60], Loss: 0.0946\n",
      "Epoch [7/60], Loss: 0.0898\n",
      "Epoch [8/60], Loss: 0.0857\n",
      "Epoch [9/60], Loss: 0.0807\n",
      "Epoch [10/60], Loss: 0.0766\n",
      "Epoch [11/60], Loss: 0.0732\n",
      "Epoch [12/60], Loss: 0.0681\n",
      "Epoch [13/60], Loss: 0.0649\n",
      "Epoch [14/60], Loss: 0.0620\n",
      "Epoch [15/60], Loss: 0.0584\n",
      "Epoch [16/60], Loss: 0.0543\n",
      "Epoch [17/60], Loss: 0.0521\n",
      "Epoch [18/60], Loss: 0.0497\n",
      "Epoch [19/60], Loss: 0.0464\n",
      "Epoch [20/60], Loss: 0.0434\n",
      "Epoch [21/60], Loss: 0.0442\n",
      "Epoch [22/60], Loss: 0.0416\n",
      "Epoch [23/60], Loss: 0.0386\n",
      "Epoch [24/60], Loss: 0.0383\n",
      "Epoch [25/60], Loss: 0.0370\n",
      "Epoch [26/60], Loss: 0.0348\n",
      "Epoch [27/60], Loss: 0.0332\n",
      "Epoch [28/60], Loss: 0.0320\n",
      "Epoch [29/60], Loss: 0.0311\n",
      "Epoch [30/60], Loss: 0.0296\n",
      "Epoch [31/60], Loss: 0.0287\n",
      "Epoch [32/60], Loss: 0.0294\n",
      "Epoch [33/60], Loss: 0.0271\n",
      "Epoch [34/60], Loss: 0.0277\n",
      "Epoch [35/60], Loss: 0.0266\n",
      "Epoch [36/60], Loss: 0.0278\n",
      "Epoch [37/60], Loss: 0.0255\n",
      "Epoch [38/60], Loss: 0.0271\n",
      "Epoch [39/60], Loss: 0.0255\n",
      "Epoch [40/60], Loss: 0.0260\n",
      "Epoch [41/60], Loss: 0.0218\n",
      "Epoch [42/60], Loss: 0.0248\n",
      "Epoch [43/60], Loss: 0.0299\n",
      "Epoch [44/60], Loss: 0.0246\n",
      "Epoch [45/60], Loss: 0.0288\n",
      "Epoch [46/60], Loss: 0.0245\n",
      "Epoch [47/60], Loss: 0.0319\n",
      "Epoch [48/60], Loss: 0.0258\n",
      "Epoch [49/60], Loss: 0.0524\n",
      "Epoch [50/60], Loss: 0.0221\n",
      "Epoch [51/60], Loss: 0.0348\n",
      "Epoch [52/60], Loss: 0.0394\n",
      "Epoch [53/60], Loss: 0.0197\n",
      "Epoch [54/60], Loss: 0.0231\n",
      "Epoch [55/60], Loss: 0.2075\n",
      "Epoch [56/60], Loss: 0.0234\n",
      "Epoch [57/60], Loss: 0.0209\n",
      "Epoch [58/60], Loss: 0.0194\n",
      "Epoch [59/60], Loss: 0.0195\n",
      "Epoch [60/60], Loss: 0.0253\n",
      "update data..\n",
      "task data norm and number entries: tensor(419.0105, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494 85.38067627  0.          0.          0.        ]\n",
      "individual errors:  [array(76.78487, dtype=float32), array(93.976494, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1493\n",
      "Epoch [2/60], Loss: 1.7835\n",
      "Epoch [3/60], Loss: 0.3012\n",
      "Epoch [4/60], Loss: 0.1198\n",
      "Epoch [5/60], Loss: 0.1127\n",
      "Epoch [6/60], Loss: 0.1094\n",
      "Epoch [7/60], Loss: 0.1059\n",
      "Epoch [8/60], Loss: 0.1036\n",
      "Epoch [9/60], Loss: 0.0983\n",
      "Epoch [10/60], Loss: 0.0951\n",
      "Epoch [11/60], Loss: 0.0933\n",
      "Epoch [12/60], Loss: 0.0880\n",
      "Epoch [13/60], Loss: 0.0882\n",
      "Epoch [14/60], Loss: 0.0836\n",
      "Epoch [15/60], Loss: 0.0811\n",
      "Epoch [16/60], Loss: 0.0776\n",
      "Epoch [17/60], Loss: 0.0747\n",
      "Epoch [18/60], Loss: 0.0753\n",
      "Epoch [19/60], Loss: 0.0700\n",
      "Epoch [20/60], Loss: 0.0689\n",
      "Epoch [21/60], Loss: 0.0665\n",
      "Epoch [22/60], Loss: 0.0650\n",
      "Epoch [23/60], Loss: 0.0621\n",
      "Epoch [24/60], Loss: 0.0606\n",
      "Epoch [25/60], Loss: 0.0588\n",
      "Epoch [26/60], Loss: 0.0565\n",
      "Epoch [27/60], Loss: 0.0539\n",
      "Epoch [28/60], Loss: 0.0562\n",
      "Epoch [29/60], Loss: 0.0530\n",
      "Epoch [30/60], Loss: 0.0503\n",
      "Epoch [31/60], Loss: 0.0474\n",
      "Epoch [32/60], Loss: 0.0482\n",
      "Epoch [33/60], Loss: 0.0466\n",
      "Epoch [34/60], Loss: 0.0461\n",
      "Epoch [35/60], Loss: 0.0441\n",
      "Epoch [36/60], Loss: 0.0413\n",
      "Epoch [37/60], Loss: 0.0428\n",
      "Epoch [38/60], Loss: 0.0391\n",
      "Epoch [39/60], Loss: 0.0383\n",
      "Epoch [40/60], Loss: 0.0413\n",
      "Epoch [41/60], Loss: 0.0393\n",
      "Epoch [42/60], Loss: 0.0385\n",
      "Epoch [43/60], Loss: 0.0377\n",
      "Epoch [44/60], Loss: 0.0360\n",
      "Epoch [45/60], Loss: 0.0352\n",
      "Epoch [46/60], Loss: 0.0357\n",
      "Epoch [47/60], Loss: 0.0334\n",
      "Epoch [48/60], Loss: 0.0318\n",
      "Epoch [49/60], Loss: 0.0339\n",
      "Epoch [50/60], Loss: 0.0341\n",
      "Epoch [51/60], Loss: 0.0308\n",
      "Epoch [52/60], Loss: 0.0318\n",
      "Epoch [53/60], Loss: 0.0306\n",
      "Epoch [54/60], Loss: 0.0302\n",
      "Epoch [55/60], Loss: 0.0324\n",
      "Epoch [56/60], Loss: 0.0285\n",
      "Epoch [57/60], Loss: 0.0301\n",
      "Epoch [58/60], Loss: 0.0353\n",
      "Epoch [59/60], Loss: 0.0305\n",
      "Epoch [60/60], Loss: 0.0406\n",
      "update data..\n",
      "task data norm and number entries: tensor(442.0760, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494 85.38067627 74.43987274  0.          0.        ]\n",
      "individual errors:  [array(70.6383, dtype=float32), array(57.590595, dtype=float32), array(95.09071, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1462\n",
      "Epoch [2/60], Loss: 0.1825\n",
      "Epoch [3/60], Loss: 0.3052\n",
      "Epoch [4/60], Loss: 0.1397\n",
      "Epoch [5/60], Loss: 0.1229\n",
      "Epoch [6/60], Loss: 0.1180\n",
      "Epoch [7/60], Loss: 0.1158\n",
      "Epoch [8/60], Loss: 0.1127\n",
      "Epoch [9/60], Loss: 0.1096\n",
      "Epoch [10/60], Loss: 0.1068\n",
      "Epoch [11/60], Loss: 0.1041\n",
      "Epoch [12/60], Loss: 0.0991\n",
      "Epoch [13/60], Loss: 0.0968\n",
      "Epoch [14/60], Loss: 0.0929\n",
      "Epoch [15/60], Loss: 0.0905\n",
      "Epoch [16/60], Loss: 0.0884\n",
      "Epoch [17/60], Loss: 0.0851\n",
      "Epoch [18/60], Loss: 0.0816\n",
      "Epoch [19/60], Loss: 0.0792\n",
      "Epoch [20/60], Loss: 0.0783\n",
      "Epoch [21/60], Loss: 0.0760\n",
      "Epoch [22/60], Loss: 0.0722\n",
      "Epoch [23/60], Loss: 0.0685\n",
      "Epoch [24/60], Loss: 0.0692\n",
      "Epoch [25/60], Loss: 0.0657\n",
      "Epoch [26/60], Loss: 0.0653\n",
      "Epoch [27/60], Loss: 0.0593\n",
      "Epoch [28/60], Loss: 0.0591\n",
      "Epoch [29/60], Loss: 0.0580\n",
      "Epoch [30/60], Loss: 0.0559\n",
      "Epoch [31/60], Loss: 0.0535\n",
      "Epoch [32/60], Loss: 0.0525\n",
      "Epoch [33/60], Loss: 0.0496\n",
      "Epoch [34/60], Loss: 0.0504\n",
      "Epoch [35/60], Loss: 0.0481\n",
      "Epoch [36/60], Loss: 0.0469\n",
      "Epoch [37/60], Loss: 0.0445\n",
      "Epoch [38/60], Loss: 0.0471\n",
      "Epoch [39/60], Loss: 0.0433\n",
      "Epoch [40/60], Loss: 0.0409\n",
      "Epoch [41/60], Loss: 0.0439\n",
      "Epoch [42/60], Loss: 0.0380\n",
      "Epoch [43/60], Loss: 0.0380\n",
      "Epoch [44/60], Loss: 0.0378\n",
      "Epoch [45/60], Loss: 0.0354\n",
      "Epoch [46/60], Loss: 0.0357\n",
      "Epoch [47/60], Loss: 0.0335\n",
      "Epoch [48/60], Loss: 0.0353\n",
      "Epoch [49/60], Loss: 0.0332\n",
      "Epoch [50/60], Loss: 0.0320\n",
      "Epoch [51/60], Loss: 0.0295\n",
      "Epoch [52/60], Loss: 0.0305\n",
      "Epoch [53/60], Loss: 0.0327\n",
      "Epoch [54/60], Loss: 0.0285\n",
      "Epoch [55/60], Loss: 0.0281\n",
      "Epoch [56/60], Loss: 0.0289\n",
      "Epoch [57/60], Loss: 0.0287\n",
      "Epoch [58/60], Loss: 0.0247\n",
      "Epoch [59/60], Loss: 0.0291\n",
      "Epoch [60/60], Loss: 0.0346\n",
      "update data..\n",
      "task data norm and number entries: tensor(446.2757, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494 85.38067627 74.43987274 72.94593811  0.        ]\n",
      "individual errors:  [array(65.0591, dtype=float32), array(47.50245, dtype=float32), array(83.35112, dtype=float32), array(95.8711, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1361\n",
      "Epoch [2/60], Loss: 0.1895\n",
      "Epoch [3/60], Loss: 0.3776\n",
      "Epoch [4/60], Loss: 0.1410\n",
      "Epoch [5/60], Loss: 0.1238\n",
      "Epoch [6/60], Loss: 0.1198\n",
      "Epoch [7/60], Loss: 0.1177\n",
      "Epoch [8/60], Loss: 0.1175\n",
      "Epoch [9/60], Loss: 0.1162\n",
      "Epoch [10/60], Loss: 0.1144\n",
      "Epoch [11/60], Loss: 0.1109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/60], Loss: 0.1122\n",
      "Epoch [13/60], Loss: 0.1100\n",
      "Epoch [14/60], Loss: 0.1076\n",
      "Epoch [15/60], Loss: 0.1066\n",
      "Epoch [16/60], Loss: 0.1054\n",
      "Epoch [17/60], Loss: 0.1037\n",
      "Epoch [18/60], Loss: 0.1016\n",
      "Epoch [19/60], Loss: 0.0988\n",
      "Epoch [20/60], Loss: 0.1001\n",
      "Epoch [21/60], Loss: 0.0960\n",
      "Epoch [22/60], Loss: 0.0957\n",
      "Epoch [23/60], Loss: 0.0941\n",
      "Epoch [24/60], Loss: 0.0914\n",
      "Epoch [25/60], Loss: 0.0926\n",
      "Epoch [26/60], Loss: 0.0921\n",
      "Epoch [27/60], Loss: 0.0880\n",
      "Epoch [28/60], Loss: 0.0879\n",
      "Epoch [29/60], Loss: 0.0858\n",
      "Epoch [30/60], Loss: 0.0851\n",
      "Epoch [31/60], Loss: 0.0828\n",
      "Epoch [32/60], Loss: 0.0832\n",
      "Epoch [33/60], Loss: 0.0805\n",
      "Epoch [34/60], Loss: 0.0814\n",
      "Epoch [35/60], Loss: 0.0786\n",
      "Epoch [36/60], Loss: 0.0791\n",
      "Epoch [37/60], Loss: 0.0779\n",
      "Epoch [38/60], Loss: 0.0748\n",
      "Epoch [39/60], Loss: 0.0734\n",
      "Epoch [40/60], Loss: 0.0729\n",
      "Epoch [41/60], Loss: 0.0722\n",
      "Epoch [42/60], Loss: 0.0704\n",
      "Epoch [43/60], Loss: 0.0730\n",
      "Epoch [44/60], Loss: 0.0685\n",
      "Epoch [45/60], Loss: 0.0660\n",
      "Epoch [46/60], Loss: 0.0692\n",
      "Epoch [47/60], Loss: 0.0654\n",
      "Epoch [48/60], Loss: 0.0634\n",
      "Epoch [49/60], Loss: 0.0638\n",
      "Epoch [50/60], Loss: 0.0640\n",
      "Epoch [51/60], Loss: 0.0653\n",
      "Epoch [52/60], Loss: 0.0627\n",
      "Epoch [53/60], Loss: 0.0608\n",
      "Epoch [54/60], Loss: 0.0582\n",
      "Epoch [55/60], Loss: 0.0582\n",
      "Epoch [56/60], Loss: 0.0596\n",
      "Epoch [57/60], Loss: 0.0580\n",
      "Epoch [58/60], Loss: 0.0564\n",
      "Epoch [59/60], Loss: 0.0557\n",
      "Epoch [60/60], Loss: 0.0529\n",
      "test performance :  [99.81087494 85.38067627 74.43987274 72.94593811 69.13201904]\n",
      "individual errors:  [array(68.179665, dtype=float32), array(35.504406, dtype=float32), array(66.11526, dtype=float32), array(89.375626, dtype=float32), array(86.48512, dtype=float32)]\n",
      "EWC++  100 1e-05\n",
      "Epoch [1/60], Loss: 0.0975\n",
      "Epoch [2/60], Loss: 0.1633\n",
      "Epoch [3/60], Loss: 0.0652\n",
      "Epoch [4/60], Loss: 0.0347\n",
      "Epoch [5/60], Loss: 0.0285\n",
      "Epoch [6/60], Loss: 0.0226\n",
      "Epoch [7/60], Loss: 0.0187\n",
      "Epoch [8/60], Loss: 0.0139\n",
      "Epoch [9/60], Loss: 0.0110\n",
      "Epoch [10/60], Loss: 0.0094\n",
      "Epoch [11/60], Loss: 0.0092\n",
      "Epoch [12/60], Loss: 0.0058\n",
      "Epoch [13/60], Loss: 0.0053\n",
      "Epoch [14/60], Loss: 0.0053\n",
      "Epoch [15/60], Loss: 0.0049\n",
      "Epoch [16/60], Loss: 0.0044\n",
      "Epoch [17/60], Loss: 0.0039\n",
      "Epoch [18/60], Loss: 0.0044\n",
      "Epoch [19/60], Loss: 0.0043\n",
      "Epoch [20/60], Loss: 0.0044\n",
      "Epoch [21/60], Loss: 0.0045\n",
      "Epoch [22/60], Loss: 0.0038\n",
      "Epoch [23/60], Loss: 0.0042\n",
      "Epoch [24/60], Loss: 0.0041\n",
      "Epoch [25/60], Loss: 0.0037\n",
      "Epoch [26/60], Loss: 0.0042\n",
      "Epoch [27/60], Loss: 0.0032\n",
      "Epoch [28/60], Loss: 0.0032\n",
      "Epoch [29/60], Loss: 0.0034\n",
      "Epoch [30/60], Loss: 0.0040\n",
      "Epoch [31/60], Loss: 0.0043\n",
      "Epoch [32/60], Loss: 0.0038\n",
      "Epoch [33/60], Loss: 0.0036\n",
      "Epoch [34/60], Loss: 0.0029\n",
      "Epoch [35/60], Loss: 0.0035\n",
      "Epoch [36/60], Loss: 0.0035\n",
      "Epoch [37/60], Loss: 0.0036\n",
      "Epoch [38/60], Loss: 0.0037\n",
      "Epoch [39/60], Loss: 0.0031\n",
      "Epoch [40/60], Loss: 0.0032\n",
      "Epoch [41/60], Loss: 0.0032\n",
      "Epoch [42/60], Loss: 0.0027\n",
      "Epoch [43/60], Loss: 0.0026\n",
      "Epoch [44/60], Loss: 0.0031\n",
      "Epoch [45/60], Loss: 0.0028\n",
      "Epoch [46/60], Loss: 0.0040\n",
      "Epoch [47/60], Loss: 0.0036\n",
      "Epoch [48/60], Loss: 0.0032\n",
      "Epoch [49/60], Loss: 0.0026\n",
      "Epoch [50/60], Loss: 0.0023\n",
      "Epoch [51/60], Loss: 0.0028\n",
      "Epoch [52/60], Loss: 0.0026\n",
      "Epoch [53/60], Loss: 0.0027\n",
      "Epoch [54/60], Loss: 0.0029\n",
      "Epoch [55/60], Loss: 0.0025\n",
      "Epoch [56/60], Loss: 0.0026\n",
      "Epoch [57/60], Loss: 0.0025\n",
      "Epoch [58/60], Loss: 0.0037\n",
      "Epoch [59/60], Loss: 0.0025\n",
      "Epoch [60/60], Loss: 0.0021\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(476.8736, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.90543, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1577\n",
      "Epoch [2/60], Loss: 0.1751\n",
      "Epoch [3/60], Loss: 0.2224\n",
      "Epoch [4/60], Loss: 0.1166\n",
      "Epoch [5/60], Loss: 0.1040\n",
      "Epoch [6/60], Loss: 0.1006\n",
      "Epoch [7/60], Loss: 0.0962\n",
      "Epoch [8/60], Loss: 0.0925\n",
      "Epoch [9/60], Loss: 0.0874\n",
      "Epoch [10/60], Loss: 0.0841\n",
      "Epoch [11/60], Loss: 0.0798\n",
      "Epoch [12/60], Loss: 0.0756\n",
      "Epoch [13/60], Loss: 0.0737\n",
      "Epoch [14/60], Loss: 0.0702\n",
      "Epoch [15/60], Loss: 0.0662\n",
      "Epoch [16/60], Loss: 0.0622\n",
      "Epoch [17/60], Loss: 0.0606\n",
      "Epoch [18/60], Loss: 0.0563\n",
      "Epoch [19/60], Loss: 0.0551\n",
      "Epoch [20/60], Loss: 0.0533\n",
      "Epoch [21/60], Loss: 0.0509\n",
      "Epoch [22/60], Loss: 0.0484\n",
      "Epoch [23/60], Loss: 0.0461\n",
      "Epoch [24/60], Loss: 0.0443\n",
      "Epoch [25/60], Loss: 0.0427\n",
      "Epoch [26/60], Loss: 0.0406\n",
      "Epoch [27/60], Loss: 0.0404\n",
      "Epoch [28/60], Loss: 0.0385\n",
      "Epoch [29/60], Loss: 0.0383\n",
      "Epoch [30/60], Loss: 0.0379\n",
      "Epoch [31/60], Loss: 0.0367\n",
      "Epoch [32/60], Loss: 0.0368\n",
      "Epoch [33/60], Loss: 0.0325\n",
      "Epoch [34/60], Loss: 0.0341\n",
      "Epoch [35/60], Loss: 0.0335\n",
      "Epoch [36/60], Loss: 0.0331\n",
      "Epoch [37/60], Loss: 0.0313\n",
      "Epoch [38/60], Loss: 0.0323\n",
      "Epoch [39/60], Loss: 0.0315\n",
      "Epoch [40/60], Loss: 0.0309\n",
      "Epoch [41/60], Loss: 0.0276\n",
      "Epoch [42/60], Loss: 0.0277\n",
      "Epoch [43/60], Loss: 0.0271\n",
      "Epoch [44/60], Loss: 0.0273\n",
      "Epoch [45/60], Loss: 0.0264\n",
      "Epoch [46/60], Loss: 0.0266\n",
      "Epoch [47/60], Loss: 0.0266\n",
      "Epoch [48/60], Loss: 0.0297\n",
      "Epoch [49/60], Loss: 0.0254\n",
      "Epoch [50/60], Loss: 0.0268\n",
      "Epoch [51/60], Loss: 0.0256\n",
      "Epoch [52/60], Loss: 0.0241\n",
      "Epoch [53/60], Loss: 0.0266\n",
      "Epoch [54/60], Loss: 0.0248\n",
      "Epoch [55/60], Loss: 0.0263\n",
      "Epoch [56/60], Loss: 0.0250\n",
      "Epoch [57/60], Loss: 0.0235\n",
      "Epoch [58/60], Loss: 0.0225\n",
      "Epoch [59/60], Loss: 0.0240\n",
      "Epoch [60/60], Loss: 0.0249\n",
      "update data..\n",
      "task data norm and number entries: tensor(463.5497, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365 93.78236389  0.          0.          0.        ]\n",
      "individual errors:  [array(95.79196, dtype=float32), array(91.772766, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1602\n",
      "Epoch [2/60], Loss: 2.2888\n",
      "Epoch [3/60], Loss: 0.3695\n",
      "Epoch [4/60], Loss: 0.1353\n",
      "Epoch [5/60], Loss: 0.1282\n",
      "Epoch [6/60], Loss: 0.1258\n",
      "Epoch [7/60], Loss: 0.1218\n",
      "Epoch [8/60], Loss: 0.1198\n",
      "Epoch [9/60], Loss: 0.1168\n",
      "Epoch [10/60], Loss: 0.1144\n",
      "Epoch [11/60], Loss: 0.1114\n",
      "Epoch [12/60], Loss: 0.1093\n",
      "Epoch [13/60], Loss: 0.1052\n",
      "Epoch [14/60], Loss: 0.1025\n",
      "Epoch [15/60], Loss: 0.1006\n",
      "Epoch [16/60], Loss: 0.0971\n",
      "Epoch [17/60], Loss: 0.0961\n",
      "Epoch [18/60], Loss: 0.0922\n",
      "Epoch [19/60], Loss: 0.0912\n",
      "Epoch [20/60], Loss: 0.0886\n",
      "Epoch [21/60], Loss: 0.0865\n",
      "Epoch [22/60], Loss: 0.0866\n",
      "Epoch [23/60], Loss: 0.0809\n",
      "Epoch [24/60], Loss: 0.0788\n",
      "Epoch [25/60], Loss: 0.0769\n",
      "Epoch [26/60], Loss: 0.0768\n",
      "Epoch [27/60], Loss: 0.0759\n",
      "Epoch [28/60], Loss: 0.0742\n",
      "Epoch [29/60], Loss: 0.0708\n",
      "Epoch [30/60], Loss: 0.0701\n",
      "Epoch [31/60], Loss: 0.0676\n",
      "Epoch [32/60], Loss: 0.0664\n",
      "Epoch [33/60], Loss: 0.0637\n",
      "Epoch [34/60], Loss: 0.0653\n",
      "Epoch [35/60], Loss: 0.0646\n",
      "Epoch [36/60], Loss: 0.0604\n",
      "Epoch [37/60], Loss: 0.0612\n",
      "Epoch [38/60], Loss: 0.0585\n",
      "Epoch [39/60], Loss: 0.0580\n",
      "Epoch [40/60], Loss: 0.0570\n",
      "Epoch [41/60], Loss: 0.0566\n",
      "Epoch [42/60], Loss: 0.0542\n",
      "Epoch [43/60], Loss: 0.0539\n",
      "Epoch [44/60], Loss: 0.0520\n",
      "Epoch [45/60], Loss: 0.0525\n",
      "Epoch [46/60], Loss: 0.0505\n",
      "Epoch [47/60], Loss: 0.0517\n",
      "Epoch [48/60], Loss: 0.0484\n",
      "Epoch [49/60], Loss: 0.0474\n",
      "Epoch [50/60], Loss: 0.0475\n",
      "Epoch [51/60], Loss: 0.0455\n",
      "Epoch [52/60], Loss: 0.0468\n",
      "Epoch [53/60], Loss: 0.0427\n",
      "Epoch [54/60], Loss: 0.0462\n",
      "Epoch [55/60], Loss: 0.0448\n",
      "Epoch [56/60], Loss: 0.0452\n",
      "Epoch [57/60], Loss: 0.0433\n",
      "Epoch [58/60], Loss: 0.0435\n",
      "Epoch [59/60], Loss: 0.0437\n",
      "Epoch [60/60], Loss: 0.0412\n",
      "update data..\n",
      "task data norm and number entries: tensor(427.8778, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365 93.78236389 89.25639343  0.          0.        ]\n",
      "individual errors:  [array(95.271866, dtype=float32), array(85.35749, dtype=float32), array(87.13981, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1516\n",
      "Epoch [2/60], Loss: 0.1742\n",
      "Epoch [3/60], Loss: 0.3474\n",
      "Epoch [4/60], Loss: 0.1468\n",
      "Epoch [5/60], Loss: 0.1296\n",
      "Epoch [6/60], Loss: 0.1253\n",
      "Epoch [7/60], Loss: 0.1222\n",
      "Epoch [8/60], Loss: 0.1193\n",
      "Epoch [9/60], Loss: 0.1164\n",
      "Epoch [10/60], Loss: 0.1146\n",
      "Epoch [11/60], Loss: 0.1117\n",
      "Epoch [12/60], Loss: 0.1076\n",
      "Epoch [13/60], Loss: 0.1053\n",
      "Epoch [14/60], Loss: 0.1038\n",
      "Epoch [15/60], Loss: 0.1002\n",
      "Epoch [16/60], Loss: 0.0984\n",
      "Epoch [17/60], Loss: 0.0945\n",
      "Epoch [18/60], Loss: 0.0925\n",
      "Epoch [19/60], Loss: 0.0904\n",
      "Epoch [20/60], Loss: 0.0865\n",
      "Epoch [21/60], Loss: 0.0862\n",
      "Epoch [22/60], Loss: 0.0826\n",
      "Epoch [23/60], Loss: 0.0813\n",
      "Epoch [24/60], Loss: 0.0791\n",
      "Epoch [25/60], Loss: 0.0776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/60], Loss: 0.0746\n",
      "Epoch [27/60], Loss: 0.0748\n",
      "Epoch [28/60], Loss: 0.0715\n",
      "Epoch [29/60], Loss: 0.0700\n",
      "Epoch [30/60], Loss: 0.0701\n",
      "Epoch [31/60], Loss: 0.0657\n",
      "Epoch [32/60], Loss: 0.0665\n",
      "Epoch [33/60], Loss: 0.0636\n",
      "Epoch [34/60], Loss: 0.0636\n",
      "Epoch [35/60], Loss: 0.0612\n",
      "Epoch [36/60], Loss: 0.0602\n",
      "Epoch [37/60], Loss: 0.0583\n",
      "Epoch [38/60], Loss: 0.0580\n",
      "Epoch [39/60], Loss: 0.0553\n",
      "Epoch [40/60], Loss: 0.0542\n",
      "Epoch [41/60], Loss: 0.0556\n",
      "Epoch [42/60], Loss: 0.0558\n",
      "Epoch [43/60], Loss: 0.0501\n",
      "Epoch [44/60], Loss: 0.0528\n",
      "Epoch [45/60], Loss: 0.0503\n",
      "Epoch [46/60], Loss: 0.0482\n",
      "Epoch [47/60], Loss: 0.0489\n",
      "Epoch [48/60], Loss: 0.0467\n",
      "Epoch [49/60], Loss: 0.0458\n",
      "Epoch [50/60], Loss: 0.0470\n",
      "Epoch [51/60], Loss: 0.0449\n",
      "Epoch [52/60], Loss: 0.0463\n",
      "Epoch [53/60], Loss: 0.0424\n",
      "Epoch [54/60], Loss: 0.0428\n",
      "Epoch [55/60], Loss: 0.0415\n",
      "Epoch [56/60], Loss: 0.0423\n",
      "Epoch [57/60], Loss: 0.0392\n",
      "Epoch [58/60], Loss: 0.0397\n",
      "Epoch [59/60], Loss: 0.0406\n",
      "Epoch [60/60], Loss: 0.0379\n",
      "update data..\n",
      "task data norm and number entries: tensor(452.4384, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365 93.78236389 89.25639343 86.07501984  0.        ]\n",
      "individual errors:  [array(94.184395, dtype=float32), array(81.58668, dtype=float32), array(75.88047, dtype=float32), array(92.64854, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1448\n",
      "Epoch [2/60], Loss: 0.1954\n",
      "Epoch [3/60], Loss: 0.3861\n",
      "Epoch [4/60], Loss: 0.1499\n",
      "Epoch [5/60], Loss: 0.1308\n",
      "Epoch [6/60], Loss: 0.1278\n",
      "Epoch [7/60], Loss: 0.1256\n",
      "Epoch [8/60], Loss: 0.1251\n",
      "Epoch [9/60], Loss: 0.1245\n",
      "Epoch [10/60], Loss: 0.1229\n",
      "Epoch [11/60], Loss: 0.1212\n",
      "Epoch [12/60], Loss: 0.1190\n",
      "Epoch [13/60], Loss: 0.1178\n",
      "Epoch [14/60], Loss: 0.1167\n",
      "Epoch [15/60], Loss: 0.1141\n",
      "Epoch [16/60], Loss: 0.1135\n",
      "Epoch [17/60], Loss: 0.1113\n",
      "Epoch [18/60], Loss: 0.1110\n",
      "Epoch [19/60], Loss: 0.1084\n",
      "Epoch [20/60], Loss: 0.1068\n",
      "Epoch [21/60], Loss: 0.1038\n",
      "Epoch [22/60], Loss: 0.1031\n",
      "Epoch [23/60], Loss: 0.1045\n",
      "Epoch [24/60], Loss: 0.1023\n",
      "Epoch [25/60], Loss: 0.0991\n",
      "Epoch [26/60], Loss: 0.1000\n",
      "Epoch [27/60], Loss: 0.0977\n",
      "Epoch [28/60], Loss: 0.0956\n",
      "Epoch [29/60], Loss: 0.0964\n",
      "Epoch [30/60], Loss: 0.0957\n",
      "Epoch [31/60], Loss: 0.0956\n",
      "Epoch [32/60], Loss: 0.0931\n",
      "Epoch [33/60], Loss: 0.0906\n",
      "Epoch [34/60], Loss: 0.0895\n",
      "Epoch [35/60], Loss: 0.0888\n",
      "Epoch [36/60], Loss: 0.0890\n",
      "Epoch [37/60], Loss: 0.0868\n",
      "Epoch [38/60], Loss: 0.0851\n",
      "Epoch [39/60], Loss: 0.0853\n",
      "Epoch [40/60], Loss: 0.0831\n",
      "Epoch [41/60], Loss: 0.0829\n",
      "Epoch [42/60], Loss: 0.0829\n",
      "Epoch [43/60], Loss: 0.0788\n",
      "Epoch [44/60], Loss: 0.0802\n",
      "Epoch [45/60], Loss: 0.0819\n",
      "Epoch [46/60], Loss: 0.0779\n",
      "Epoch [47/60], Loss: 0.0787\n",
      "Epoch [48/60], Loss: 0.0750\n",
      "Epoch [49/60], Loss: 0.0774\n",
      "Epoch [50/60], Loss: 0.0762\n",
      "Epoch [51/60], Loss: 0.0797\n",
      "Epoch [52/60], Loss: 0.0736\n",
      "Epoch [53/60], Loss: 0.0746\n",
      "Epoch [54/60], Loss: 0.0728\n",
      "Epoch [55/60], Loss: 0.0703\n",
      "Epoch [56/60], Loss: 0.0710\n",
      "Epoch [57/60], Loss: 0.0713\n",
      "Epoch [58/60], Loss: 0.0689\n",
      "Epoch [59/60], Loss: 0.0684\n",
      "Epoch [60/60], Loss: 0.0662\n",
      "test performance :  [99.90543365 93.78236389 89.25639343 86.07501984 80.33976746]\n",
      "individual errors:  [array(94.184395, dtype=float32), array(76.003914, dtype=float32), array(63.660618, dtype=float32), array(84.541794, dtype=float32), array(83.30812, dtype=float32)]\n",
      "EWC++  200 1e-05\n",
      "Epoch [1/60], Loss: 0.1002\n",
      "Epoch [2/60], Loss: 0.1472\n",
      "Epoch [3/60], Loss: 0.0607\n",
      "Epoch [4/60], Loss: 0.0343\n",
      "Epoch [5/60], Loss: 0.0280\n",
      "Epoch [6/60], Loss: 0.0228\n",
      "Epoch [7/60], Loss: 0.0192\n",
      "Epoch [8/60], Loss: 0.0141\n",
      "Epoch [9/60], Loss: 0.0114\n",
      "Epoch [10/60], Loss: 0.0109\n",
      "Epoch [11/60], Loss: 0.0076\n",
      "Epoch [12/60], Loss: 0.0074\n",
      "Epoch [13/60], Loss: 0.0065\n",
      "Epoch [14/60], Loss: 0.0057\n",
      "Epoch [15/60], Loss: 0.0048\n",
      "Epoch [16/60], Loss: 0.0045\n",
      "Epoch [17/60], Loss: 0.0048\n",
      "Epoch [18/60], Loss: 0.0052\n",
      "Epoch [19/60], Loss: 0.0039\n",
      "Epoch [20/60], Loss: 0.0042\n",
      "Epoch [21/60], Loss: 0.0044\n",
      "Epoch [22/60], Loss: 0.0038\n",
      "Epoch [23/60], Loss: 0.0038\n",
      "Epoch [24/60], Loss: 0.0042\n",
      "Epoch [25/60], Loss: 0.0052\n",
      "Epoch [26/60], Loss: 0.0032\n",
      "Epoch [27/60], Loss: 0.0041\n",
      "Epoch [28/60], Loss: 0.0037\n",
      "Epoch [29/60], Loss: 0.0039\n",
      "Epoch [30/60], Loss: 0.0034\n",
      "Epoch [31/60], Loss: 0.0038\n",
      "Epoch [32/60], Loss: 0.0037\n",
      "Epoch [33/60], Loss: 0.0033\n",
      "Epoch [34/60], Loss: 0.0035\n",
      "Epoch [35/60], Loss: 0.0027\n",
      "Epoch [36/60], Loss: 0.0043\n",
      "Epoch [37/60], Loss: 0.0030\n",
      "Epoch [38/60], Loss: 0.0031\n",
      "Epoch [39/60], Loss: 0.0026\n",
      "Epoch [40/60], Loss: 0.0027\n",
      "Epoch [41/60], Loss: 0.0033\n",
      "Epoch [42/60], Loss: 0.0032\n",
      "Epoch [43/60], Loss: 0.0026\n",
      "Epoch [44/60], Loss: 0.0030\n",
      "Epoch [45/60], Loss: 0.0030\n",
      "Epoch [46/60], Loss: 0.0026\n",
      "Epoch [47/60], Loss: 0.0027\n",
      "Epoch [48/60], Loss: 0.0025\n",
      "Epoch [49/60], Loss: 0.0029\n",
      "Epoch [50/60], Loss: 0.0027\n",
      "Epoch [51/60], Loss: 0.0022\n",
      "Epoch [52/60], Loss: 0.0040\n",
      "Epoch [53/60], Loss: 0.0022\n",
      "Epoch [54/60], Loss: 0.0026\n",
      "Epoch [55/60], Loss: 0.0021\n",
      "Epoch [56/60], Loss: 0.0031\n",
      "Epoch [57/60], Loss: 0.0024\n",
      "Epoch [58/60], Loss: 0.0026\n",
      "Epoch [59/60], Loss: 0.0020\n",
      "Epoch [60/60], Loss: 0.0027\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(460.4471, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.95272, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1583\n",
      "Epoch [2/60], Loss: 0.2678\n",
      "Epoch [3/60], Loss: 0.1835\n",
      "Epoch [4/60], Loss: 0.1126\n",
      "Epoch [5/60], Loss: 0.1045\n",
      "Epoch [6/60], Loss: 0.0999\n",
      "Epoch [7/60], Loss: 0.0966\n",
      "Epoch [8/60], Loss: 0.0931\n",
      "Epoch [9/60], Loss: 0.0903\n",
      "Epoch [10/60], Loss: 0.0859\n",
      "Epoch [11/60], Loss: 0.0828\n",
      "Epoch [12/60], Loss: 0.0778\n",
      "Epoch [13/60], Loss: 0.0751\n",
      "Epoch [14/60], Loss: 0.0710\n",
      "Epoch [15/60], Loss: 0.0682\n",
      "Epoch [16/60], Loss: 0.0675\n",
      "Epoch [17/60], Loss: 0.0644\n",
      "Epoch [18/60], Loss: 0.0601\n",
      "Epoch [19/60], Loss: 0.0586\n",
      "Epoch [20/60], Loss: 0.0571\n",
      "Epoch [21/60], Loss: 0.0531\n",
      "Epoch [22/60], Loss: 0.0517\n",
      "Epoch [23/60], Loss: 0.0509\n",
      "Epoch [24/60], Loss: 0.0495\n",
      "Epoch [25/60], Loss: 0.0498\n",
      "Epoch [26/60], Loss: 0.0477\n",
      "Epoch [27/60], Loss: 0.0446\n",
      "Epoch [28/60], Loss: 0.0442\n",
      "Epoch [29/60], Loss: 0.0423\n",
      "Epoch [30/60], Loss: 0.0401\n",
      "Epoch [31/60], Loss: 0.0381\n",
      "Epoch [32/60], Loss: 0.0389\n",
      "Epoch [33/60], Loss: 0.0375\n",
      "Epoch [34/60], Loss: 0.0356\n",
      "Epoch [35/60], Loss: 0.0358\n",
      "Epoch [36/60], Loss: 0.0356\n",
      "Epoch [37/60], Loss: 0.0337\n",
      "Epoch [38/60], Loss: 0.0331\n",
      "Epoch [39/60], Loss: 0.0344\n",
      "Epoch [40/60], Loss: 0.0334\n",
      "Epoch [41/60], Loss: 0.0334\n",
      "Epoch [42/60], Loss: 0.0325\n",
      "Epoch [43/60], Loss: 0.0305\n",
      "Epoch [44/60], Loss: 0.0311\n",
      "Epoch [45/60], Loss: 0.0327\n",
      "Epoch [46/60], Loss: 0.0319\n",
      "Epoch [47/60], Loss: 0.0303\n",
      "Epoch [48/60], Loss: 0.0294\n",
      "Epoch [49/60], Loss: 0.0301\n",
      "Epoch [50/60], Loss: 0.0297\n",
      "Epoch [51/60], Loss: 0.0281\n",
      "Epoch [52/60], Loss: 0.0304\n",
      "Epoch [53/60], Loss: 0.0284\n",
      "Epoch [54/60], Loss: 0.0280\n",
      "Epoch [55/60], Loss: 0.0260\n",
      "Epoch [56/60], Loss: 0.0266\n",
      "Epoch [57/60], Loss: 0.0286\n",
      "Epoch [58/60], Loss: 0.0269\n",
      "Epoch [59/60], Loss: 0.0278\n",
      "Epoch [60/60], Loss: 0.0290\n",
      "update data..\n",
      "task data norm and number entries: tensor(441.3173, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064 95.41950989  0.          0.          0.        ]\n",
      "individual errors:  [array(97.35224, dtype=float32), array(93.48678, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1414\n",
      "Epoch [2/60], Loss: 2.0613\n",
      "Epoch [3/60], Loss: 0.3369\n",
      "Epoch [4/60], Loss: 0.1207\n",
      "Epoch [5/60], Loss: 0.1158\n",
      "Epoch [6/60], Loss: 0.1130\n",
      "Epoch [7/60], Loss: 0.1126\n",
      "Epoch [8/60], Loss: 0.1103\n",
      "Epoch [9/60], Loss: 0.1066\n",
      "Epoch [10/60], Loss: 0.1047\n",
      "Epoch [11/60], Loss: 0.1038\n",
      "Epoch [12/60], Loss: 0.1001\n",
      "Epoch [13/60], Loss: 0.0979\n",
      "Epoch [14/60], Loss: 0.0943\n",
      "Epoch [15/60], Loss: 0.0947\n",
      "Epoch [16/60], Loss: 0.0932\n",
      "Epoch [17/60], Loss: 0.0899\n",
      "Epoch [18/60], Loss: 0.0878\n",
      "Epoch [19/60], Loss: 0.0844\n",
      "Epoch [20/60], Loss: 0.0855\n",
      "Epoch [21/60], Loss: 0.0828\n",
      "Epoch [22/60], Loss: 0.0777\n",
      "Epoch [23/60], Loss: 0.0789\n",
      "Epoch [24/60], Loss: 0.0760\n",
      "Epoch [25/60], Loss: 0.0755\n",
      "Epoch [26/60], Loss: 0.0730\n",
      "Epoch [27/60], Loss: 0.0755\n",
      "Epoch [28/60], Loss: 0.0713\n",
      "Epoch [29/60], Loss: 0.0718\n",
      "Epoch [30/60], Loss: 0.0692\n",
      "Epoch [31/60], Loss: 0.0677\n",
      "Epoch [32/60], Loss: 0.0667\n",
      "Epoch [33/60], Loss: 0.0645\n",
      "Epoch [34/60], Loss: 0.0648\n",
      "Epoch [35/60], Loss: 0.0613\n",
      "Epoch [36/60], Loss: 0.0617\n",
      "Epoch [37/60], Loss: 0.0597\n",
      "Epoch [38/60], Loss: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/60], Loss: 0.0569\n",
      "Epoch [40/60], Loss: 0.0571\n",
      "Epoch [41/60], Loss: 0.0571\n",
      "Epoch [42/60], Loss: 0.0567\n",
      "Epoch [43/60], Loss: 0.0557\n",
      "Epoch [44/60], Loss: 0.0564\n",
      "Epoch [45/60], Loss: 0.0548\n",
      "Epoch [46/60], Loss: 0.0529\n",
      "Epoch [47/60], Loss: 0.0522\n",
      "Epoch [48/60], Loss: 0.0510\n",
      "Epoch [49/60], Loss: 0.0517\n",
      "Epoch [50/60], Loss: 0.0515\n",
      "Epoch [51/60], Loss: 0.0506\n",
      "Epoch [52/60], Loss: 0.0497\n",
      "Epoch [53/60], Loss: 0.0510\n",
      "Epoch [54/60], Loss: 0.0477\n",
      "Epoch [55/60], Loss: 0.0474\n",
      "Epoch [56/60], Loss: 0.0460\n",
      "Epoch [57/60], Loss: 0.0474\n",
      "Epoch [58/60], Loss: 0.0462\n",
      "Epoch [59/60], Loss: 0.0441\n",
      "Epoch [60/60], Loss: 0.0458\n",
      "update data..\n",
      "task data norm and number entries: tensor(429.2043, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064 95.41950989 90.93862152  0.          0.        ]\n",
      "individual errors:  [array(97.16312, dtype=float32), array(87.65916, dtype=float32), array(87.99359, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1436\n",
      "Epoch [2/60], Loss: 0.1597\n",
      "Epoch [3/60], Loss: 0.2837\n",
      "Epoch [4/60], Loss: 0.1323\n",
      "Epoch [5/60], Loss: 0.1187\n",
      "Epoch [6/60], Loss: 0.1169\n",
      "Epoch [7/60], Loss: 0.1143\n",
      "Epoch [8/60], Loss: 0.1089\n",
      "Epoch [9/60], Loss: 0.1064\n",
      "Epoch [10/60], Loss: 0.1033\n",
      "Epoch [11/60], Loss: 0.1011\n",
      "Epoch [12/60], Loss: 0.0985\n",
      "Epoch [13/60], Loss: 0.0969\n",
      "Epoch [14/60], Loss: 0.0944\n",
      "Epoch [15/60], Loss: 0.0915\n",
      "Epoch [16/60], Loss: 0.0894\n",
      "Epoch [17/60], Loss: 0.0884\n",
      "Epoch [18/60], Loss: 0.0845\n",
      "Epoch [19/60], Loss: 0.0817\n",
      "Epoch [20/60], Loss: 0.0794\n",
      "Epoch [21/60], Loss: 0.0790\n",
      "Epoch [22/60], Loss: 0.0756\n",
      "Epoch [23/60], Loss: 0.0774\n",
      "Epoch [24/60], Loss: 0.0741\n",
      "Epoch [25/60], Loss: 0.0715\n",
      "Epoch [26/60], Loss: 0.0703\n",
      "Epoch [27/60], Loss: 0.0699\n",
      "Epoch [28/60], Loss: 0.0685\n",
      "Epoch [29/60], Loss: 0.0665\n",
      "Epoch [30/60], Loss: 0.0642\n",
      "Epoch [31/60], Loss: 0.0623\n",
      "Epoch [32/60], Loss: 0.0616\n",
      "Epoch [33/60], Loss: 0.0607\n",
      "Epoch [34/60], Loss: 0.0621\n",
      "Epoch [35/60], Loss: 0.0592\n",
      "Epoch [36/60], Loss: 0.0575\n",
      "Epoch [37/60], Loss: 0.0575\n",
      "Epoch [38/60], Loss: 0.0574\n",
      "Epoch [39/60], Loss: 0.0551\n",
      "Epoch [40/60], Loss: 0.0559\n",
      "Epoch [41/60], Loss: 0.0530\n",
      "Epoch [42/60], Loss: 0.0498\n",
      "Epoch [43/60], Loss: 0.0503\n",
      "Epoch [44/60], Loss: 0.0519\n",
      "Epoch [45/60], Loss: 0.0500\n",
      "Epoch [46/60], Loss: 0.0482\n",
      "Epoch [47/60], Loss: 0.0473\n",
      "Epoch [48/60], Loss: 0.0477\n",
      "Epoch [49/60], Loss: 0.0468\n",
      "Epoch [50/60], Loss: 0.0455\n",
      "Epoch [51/60], Loss: 0.0458\n",
      "Epoch [52/60], Loss: 0.0449\n",
      "Epoch [53/60], Loss: 0.0453\n",
      "Epoch [54/60], Loss: 0.0439\n",
      "Epoch [55/60], Loss: 0.0489\n",
      "Epoch [56/60], Loss: 0.0463\n",
      "Epoch [57/60], Loss: 0.0467\n",
      "Epoch [58/60], Loss: 0.0436\n",
      "Epoch [59/60], Loss: 0.0425\n",
      "Epoch [60/60], Loss: 0.0433\n",
      "update data..\n",
      "task data norm and number entries: tensor(448.8427, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064 95.41950989 90.93862152 85.02801514  0.        ]\n",
      "individual errors:  [array(96.40662, dtype=float32), array(79.38296, dtype=float32), array(71.824974, dtype=float32), array(92.49748, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1498\n",
      "Epoch [2/60], Loss: 0.1916\n",
      "Epoch [3/60], Loss: 0.3628\n",
      "Epoch [4/60], Loss: 0.1520\n",
      "Epoch [5/60], Loss: 0.1347\n",
      "Epoch [6/60], Loss: 0.1346\n",
      "Epoch [7/60], Loss: 0.1323\n",
      "Epoch [8/60], Loss: 0.1296\n",
      "Epoch [9/60], Loss: 0.1283\n",
      "Epoch [10/60], Loss: 0.1273\n",
      "Epoch [11/60], Loss: 0.1271\n",
      "Epoch [12/60], Loss: 0.1253\n",
      "Epoch [13/60], Loss: 0.1233\n",
      "Epoch [14/60], Loss: 0.1220\n",
      "Epoch [15/60], Loss: 0.1210\n",
      "Epoch [16/60], Loss: 0.1193\n",
      "Epoch [17/60], Loss: 0.1174\n",
      "Epoch [18/60], Loss: 0.1173\n",
      "Epoch [19/60], Loss: 0.1150\n",
      "Epoch [20/60], Loss: 0.1126\n",
      "Epoch [21/60], Loss: 0.1122\n",
      "Epoch [22/60], Loss: 0.1140\n",
      "Epoch [23/60], Loss: 0.1109\n",
      "Epoch [24/60], Loss: 0.1105\n",
      "Epoch [25/60], Loss: 0.1080\n",
      "Epoch [26/60], Loss: 0.1064\n",
      "Epoch [27/60], Loss: 0.1045\n",
      "Epoch [28/60], Loss: 0.1039\n",
      "Epoch [29/60], Loss: 0.1057\n",
      "Epoch [30/60], Loss: 0.1058\n",
      "Epoch [31/60], Loss: 0.1022\n",
      "Epoch [32/60], Loss: 0.1006\n",
      "Epoch [33/60], Loss: 0.1000\n",
      "Epoch [34/60], Loss: 0.1018\n",
      "Epoch [35/60], Loss: 0.0968\n",
      "Epoch [36/60], Loss: 0.0967\n",
      "Epoch [37/60], Loss: 0.0989\n",
      "Epoch [38/60], Loss: 0.0974\n",
      "Epoch [39/60], Loss: 0.0926\n",
      "Epoch [40/60], Loss: 0.0950\n",
      "Epoch [41/60], Loss: 0.0927\n",
      "Epoch [42/60], Loss: 0.0937\n",
      "Epoch [43/60], Loss: 0.0910\n",
      "Epoch [44/60], Loss: 0.0924\n",
      "Epoch [45/60], Loss: 0.0907\n",
      "Epoch [46/60], Loss: 0.0883\n",
      "Epoch [47/60], Loss: 0.0884\n",
      "Epoch [48/60], Loss: 0.0880\n",
      "Epoch [49/60], Loss: 0.0878\n",
      "Epoch [50/60], Loss: 0.0856\n",
      "Epoch [51/60], Loss: 0.0875\n",
      "Epoch [52/60], Loss: 0.0853\n",
      "Epoch [53/60], Loss: 0.0853\n",
      "Epoch [54/60], Loss: 0.0842\n",
      "Epoch [55/60], Loss: 0.0858\n",
      "Epoch [56/60], Loss: 0.0823\n",
      "Epoch [57/60], Loss: 0.0831\n",
      "Epoch [58/60], Loss: 0.0824\n",
      "Epoch [59/60], Loss: 0.0819\n",
      "Epoch [60/60], Loss: 0.0815\n",
      "test performance :  [99.95272064 95.41950989 90.93862152 85.02801514 81.78742218]\n",
      "individual errors:  [array(95.98109, dtype=float32), array(79.1381, dtype=float32), array(73.692635, dtype=float32), array(90.53374, dtype=float32), array(69.59153, dtype=float32)]\n",
      "EWC++  400 1e-05\n",
      "Epoch [1/60], Loss: 0.1002\n",
      "Epoch [2/60], Loss: 0.1424\n",
      "Epoch [3/60], Loss: 0.0587\n",
      "Epoch [4/60], Loss: 0.0331\n",
      "Epoch [5/60], Loss: 0.0265\n",
      "Epoch [6/60], Loss: 0.0216\n",
      "Epoch [7/60], Loss: 0.0167\n",
      "Epoch [8/60], Loss: 0.0128\n",
      "Epoch [9/60], Loss: 0.0108\n",
      "Epoch [10/60], Loss: 0.0089\n",
      "Epoch [11/60], Loss: 0.0073\n",
      "Epoch [12/60], Loss: 0.0069\n",
      "Epoch [13/60], Loss: 0.0060\n",
      "Epoch [14/60], Loss: 0.0044\n",
      "Epoch [15/60], Loss: 0.0050\n",
      "Epoch [16/60], Loss: 0.0046\n",
      "Epoch [17/60], Loss: 0.0052\n",
      "Epoch [18/60], Loss: 0.0045\n",
      "Epoch [19/60], Loss: 0.0040\n",
      "Epoch [20/60], Loss: 0.0040\n",
      "Epoch [21/60], Loss: 0.0044\n",
      "Epoch [22/60], Loss: 0.0039\n",
      "Epoch [23/60], Loss: 0.0046\n",
      "Epoch [24/60], Loss: 0.0041\n",
      "Epoch [25/60], Loss: 0.0040\n",
      "Epoch [26/60], Loss: 0.0039\n",
      "Epoch [27/60], Loss: 0.0036\n",
      "Epoch [28/60], Loss: 0.0036\n",
      "Epoch [29/60], Loss: 0.0035\n",
      "Epoch [30/60], Loss: 0.0030\n",
      "Epoch [31/60], Loss: 0.0034\n",
      "Epoch [32/60], Loss: 0.0036\n",
      "Epoch [33/60], Loss: 0.0033\n",
      "Epoch [34/60], Loss: 0.0040\n",
      "Epoch [35/60], Loss: 0.0033\n",
      "Epoch [36/60], Loss: 0.0036\n",
      "Epoch [37/60], Loss: 0.0033\n",
      "Epoch [38/60], Loss: 0.0028\n",
      "Epoch [39/60], Loss: 0.0028\n",
      "Epoch [40/60], Loss: 0.0030\n",
      "Epoch [41/60], Loss: 0.0033\n",
      "Epoch [42/60], Loss: 0.0029\n",
      "Epoch [43/60], Loss: 0.0029\n",
      "Epoch [44/60], Loss: 0.0028\n",
      "Epoch [45/60], Loss: 0.0028\n",
      "Epoch [46/60], Loss: 0.0027\n",
      "Epoch [47/60], Loss: 0.0031\n",
      "Epoch [48/60], Loss: 0.0030\n",
      "Epoch [49/60], Loss: 0.0023\n",
      "Epoch [50/60], Loss: 0.0033\n",
      "Epoch [51/60], Loss: 0.0039\n",
      "Epoch [52/60], Loss: 0.0028\n",
      "Epoch [53/60], Loss: 0.0033\n",
      "Epoch [54/60], Loss: 0.0032\n",
      "Epoch [55/60], Loss: 0.0022\n",
      "Epoch [56/60], Loss: 0.0028\n",
      "Epoch [57/60], Loss: 0.0030\n",
      "Epoch [58/60], Loss: 0.0033\n",
      "Epoch [59/60], Loss: 0.0036\n",
      "Epoch [60/60], Loss: 0.0040\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(442.9283, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.95272, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1608\n",
      "Epoch [2/60], Loss: 0.2073\n",
      "Epoch [3/60], Loss: 0.1735\n",
      "Epoch [4/60], Loss: 0.1078\n",
      "Epoch [5/60], Loss: 0.1009\n",
      "Epoch [6/60], Loss: 0.0962\n",
      "Epoch [7/60], Loss: 0.0935\n",
      "Epoch [8/60], Loss: 0.0889\n",
      "Epoch [9/60], Loss: 0.0852\n",
      "Epoch [10/60], Loss: 0.0827\n",
      "Epoch [11/60], Loss: 0.0778\n",
      "Epoch [12/60], Loss: 0.0756\n",
      "Epoch [13/60], Loss: 0.0722\n",
      "Epoch [14/60], Loss: 0.0680\n",
      "Epoch [15/60], Loss: 0.0651\n",
      "Epoch [16/60], Loss: 0.0627\n",
      "Epoch [17/60], Loss: 0.0594\n",
      "Epoch [18/60], Loss: 0.0563\n",
      "Epoch [19/60], Loss: 0.0546\n",
      "Epoch [20/60], Loss: 0.0511\n",
      "Epoch [21/60], Loss: 0.0508\n",
      "Epoch [22/60], Loss: 0.0516\n",
      "Epoch [23/60], Loss: 0.0477\n",
      "Epoch [24/60], Loss: 0.0478\n",
      "Epoch [25/60], Loss: 0.0476\n",
      "Epoch [26/60], Loss: 0.0445\n",
      "Epoch [27/60], Loss: 0.0439\n",
      "Epoch [28/60], Loss: 0.0420\n",
      "Epoch [29/60], Loss: 0.0415\n",
      "Epoch [30/60], Loss: 0.0425\n",
      "Epoch [31/60], Loss: 0.0402\n",
      "Epoch [32/60], Loss: 0.0389\n",
      "Epoch [33/60], Loss: 0.0380\n",
      "Epoch [34/60], Loss: 0.0357\n",
      "Epoch [35/60], Loss: 0.0376\n",
      "Epoch [36/60], Loss: 0.0360\n",
      "Epoch [37/60], Loss: 0.0355\n",
      "Epoch [38/60], Loss: 0.0339\n",
      "Epoch [39/60], Loss: 0.0352\n",
      "Epoch [40/60], Loss: 0.0342\n",
      "Epoch [41/60], Loss: 0.0355\n",
      "Epoch [42/60], Loss: 0.0326\n",
      "Epoch [43/60], Loss: 0.0337\n",
      "Epoch [44/60], Loss: 0.0319\n",
      "Epoch [45/60], Loss: 0.0327\n",
      "Epoch [46/60], Loss: 0.0331\n",
      "Epoch [47/60], Loss: 0.0312\n",
      "Epoch [48/60], Loss: 0.0338\n",
      "Epoch [49/60], Loss: 0.0305\n",
      "Epoch [50/60], Loss: 0.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/60], Loss: 0.0328\n",
      "Epoch [52/60], Loss: 0.0292\n",
      "Epoch [53/60], Loss: 0.0296\n",
      "Epoch [54/60], Loss: 0.0298\n",
      "Epoch [55/60], Loss: 0.0310\n",
      "Epoch [56/60], Loss: 0.0280\n",
      "Epoch [57/60], Loss: 0.0322\n",
      "Epoch [58/60], Loss: 0.0304\n",
      "Epoch [59/60], Loss: 0.0289\n",
      "Epoch [60/60], Loss: 0.0302\n",
      "update data..\n",
      "task data norm and number entries: tensor(448.5618, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064 95.04800415  0.          0.          0.        ]\n",
      "individual errors:  [array(97.58865, dtype=float32), array(92.50735, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1512\n",
      "Epoch [2/60], Loss: 1.7023\n",
      "Epoch [3/60], Loss: 0.2934\n",
      "Epoch [4/60], Loss: 0.1288\n",
      "Epoch [5/60], Loss: 0.1194\n",
      "Epoch [6/60], Loss: 0.1166\n",
      "Epoch [7/60], Loss: 0.1148\n",
      "Epoch [8/60], Loss: 0.1140\n",
      "Epoch [9/60], Loss: 0.1113\n",
      "Epoch [10/60], Loss: 0.1079\n",
      "Epoch [11/60], Loss: 0.1060\n",
      "Epoch [12/60], Loss: 0.1042\n",
      "Epoch [13/60], Loss: 0.1008\n",
      "Epoch [14/60], Loss: 0.0972\n",
      "Epoch [15/60], Loss: 0.0963\n",
      "Epoch [16/60], Loss: 0.0921\n",
      "Epoch [17/60], Loss: 0.0916\n",
      "Epoch [18/60], Loss: 0.0885\n",
      "Epoch [19/60], Loss: 0.0876\n",
      "Epoch [20/60], Loss: 0.0855\n",
      "Epoch [21/60], Loss: 0.0848\n",
      "Epoch [22/60], Loss: 0.0818\n",
      "Epoch [23/60], Loss: 0.0788\n",
      "Epoch [24/60], Loss: 0.0789\n",
      "Epoch [25/60], Loss: 0.0753\n",
      "Epoch [26/60], Loss: 0.0758\n",
      "Epoch [27/60], Loss: 0.0726\n",
      "Epoch [28/60], Loss: 0.0736\n",
      "Epoch [29/60], Loss: 0.0692\n",
      "Epoch [30/60], Loss: 0.0687\n",
      "Epoch [31/60], Loss: 0.0695\n",
      "Epoch [32/60], Loss: 0.0685\n",
      "Epoch [33/60], Loss: 0.0653\n",
      "Epoch [34/60], Loss: 0.0648\n",
      "Epoch [35/60], Loss: 0.0654\n",
      "Epoch [36/60], Loss: 0.0640\n",
      "Epoch [37/60], Loss: 0.0627\n",
      "Epoch [38/60], Loss: 0.0620\n",
      "Epoch [39/60], Loss: 0.0608\n",
      "Epoch [40/60], Loss: 0.0612\n",
      "Epoch [41/60], Loss: 0.0593\n",
      "Epoch [42/60], Loss: 0.0581\n",
      "Epoch [43/60], Loss: 0.0586\n",
      "Epoch [44/60], Loss: 0.0584\n",
      "Epoch [45/60], Loss: 0.0585\n",
      "Epoch [46/60], Loss: 0.0565\n",
      "Epoch [47/60], Loss: 0.0551\n",
      "Epoch [48/60], Loss: 0.0556\n",
      "Epoch [49/60], Loss: 0.0552\n",
      "Epoch [50/60], Loss: 0.0565\n",
      "Epoch [51/60], Loss: 0.0552\n",
      "Epoch [52/60], Loss: 0.0526\n",
      "Epoch [53/60], Loss: 0.0541\n",
      "Epoch [54/60], Loss: 0.0527\n",
      "Epoch [55/60], Loss: 0.0529\n",
      "Epoch [56/60], Loss: 0.0535\n",
      "Epoch [57/60], Loss: 0.0517\n",
      "Epoch [58/60], Loss: 0.0513\n",
      "Epoch [59/60], Loss: 0.0495\n",
      "Epoch [60/60], Loss: 0.0504\n",
      "update data..\n",
      "task data norm and number entries: tensor(430.9024, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064 95.04800415 91.29582977  0.          0.        ]\n",
      "individual errors:  [array(97.63593, dtype=float32), array(86.33692, dtype=float32), array(89.91462, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1415\n",
      "Epoch [2/60], Loss: 0.1688\n",
      "Epoch [3/60], Loss: 0.2901\n",
      "Epoch [4/60], Loss: 0.1332\n",
      "Epoch [5/60], Loss: 0.1194\n",
      "Epoch [6/60], Loss: 0.1168\n",
      "Epoch [7/60], Loss: 0.1134\n",
      "Epoch [8/60], Loss: 0.1099\n",
      "Epoch [9/60], Loss: 0.1087\n",
      "Epoch [10/60], Loss: 0.1053\n",
      "Epoch [11/60], Loss: 0.1020\n",
      "Epoch [12/60], Loss: 0.1003\n",
      "Epoch [13/60], Loss: 0.0981\n",
      "Epoch [14/60], Loss: 0.0956\n",
      "Epoch [15/60], Loss: 0.0926\n",
      "Epoch [16/60], Loss: 0.0901\n",
      "Epoch [17/60], Loss: 0.0886\n",
      "Epoch [18/60], Loss: 0.0844\n",
      "Epoch [19/60], Loss: 0.0837\n",
      "Epoch [20/60], Loss: 0.0828\n",
      "Epoch [21/60], Loss: 0.0813\n",
      "Epoch [22/60], Loss: 0.0798\n",
      "Epoch [23/60], Loss: 0.0770\n",
      "Epoch [24/60], Loss: 0.0735\n",
      "Epoch [25/60], Loss: 0.0749\n",
      "Epoch [26/60], Loss: 0.0722\n",
      "Epoch [27/60], Loss: 0.0702\n",
      "Epoch [28/60], Loss: 0.0691\n",
      "Epoch [29/60], Loss: 0.0685\n",
      "Epoch [30/60], Loss: 0.0677\n",
      "Epoch [31/60], Loss: 0.0668\n",
      "Epoch [32/60], Loss: 0.0640\n",
      "Epoch [33/60], Loss: 0.0640\n",
      "Epoch [34/60], Loss: 0.0617\n",
      "Epoch [35/60], Loss: 0.0587\n",
      "Epoch [36/60], Loss: 0.0609\n",
      "Epoch [37/60], Loss: 0.0584\n",
      "Epoch [38/60], Loss: 0.0570\n",
      "Epoch [39/60], Loss: 0.0596\n",
      "Epoch [40/60], Loss: 0.0592\n",
      "Epoch [41/60], Loss: 0.0566\n",
      "Epoch [42/60], Loss: 0.0574\n",
      "Epoch [43/60], Loss: 0.0570\n",
      "Epoch [44/60], Loss: 0.0544\n",
      "Epoch [45/60], Loss: 0.0546\n",
      "Epoch [46/60], Loss: 0.0529\n",
      "Epoch [47/60], Loss: 0.0523\n",
      "Epoch [48/60], Loss: 0.0520\n",
      "Epoch [49/60], Loss: 0.0517\n",
      "Epoch [50/60], Loss: 0.0534\n",
      "Epoch [51/60], Loss: 0.0494\n",
      "Epoch [52/60], Loss: 0.0505\n",
      "Epoch [53/60], Loss: 0.0496\n",
      "Epoch [54/60], Loss: 0.0487\n",
      "Epoch [55/60], Loss: 0.0495\n",
      "Epoch [56/60], Loss: 0.0475\n",
      "Epoch [57/60], Loss: 0.0465\n",
      "Epoch [58/60], Loss: 0.0486\n",
      "Epoch [59/60], Loss: 0.0471\n",
      "Epoch [60/60], Loss: 0.0455\n",
      "update data..\n",
      "task data norm and number entries: tensor(443.8177, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.95272064 95.04800415 91.29582977 88.48916626  0.        ]\n",
      "individual errors:  [array(96.35934, dtype=float32), array(83.54554, dtype=float32), array(84.52508, dtype=float32), array(89.52669, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1393\n",
      "Epoch [2/60], Loss: 0.1819\n",
      "Epoch [3/60], Loss: 0.3527\n",
      "Epoch [4/60], Loss: 0.1427\n",
      "Epoch [5/60], Loss: 0.1266\n",
      "Epoch [6/60], Loss: 0.1262\n",
      "Epoch [7/60], Loss: 0.1238\n",
      "Epoch [8/60], Loss: 0.1221\n",
      "Epoch [9/60], Loss: 0.1212\n",
      "Epoch [10/60], Loss: 0.1195\n",
      "Epoch [11/60], Loss: 0.1187\n",
      "Epoch [12/60], Loss: 0.1174\n",
      "Epoch [13/60], Loss: 0.1173\n",
      "Epoch [14/60], Loss: 0.1150\n",
      "Epoch [15/60], Loss: 0.1157\n",
      "Epoch [16/60], Loss: 0.1135\n",
      "Epoch [17/60], Loss: 0.1128\n",
      "Epoch [18/60], Loss: 0.1123\n",
      "Epoch [19/60], Loss: 0.1094\n",
      "Epoch [20/60], Loss: 0.1087\n",
      "Epoch [21/60], Loss: 0.1083\n",
      "Epoch [22/60], Loss: 0.1077\n",
      "Epoch [23/60], Loss: 0.1053\n",
      "Epoch [24/60], Loss: 0.1061\n",
      "Epoch [25/60], Loss: 0.1035\n",
      "Epoch [26/60], Loss: 0.1045\n",
      "Epoch [27/60], Loss: 0.1019\n",
      "Epoch [28/60], Loss: 0.1017\n",
      "Epoch [29/60], Loss: 0.1000\n",
      "Epoch [30/60], Loss: 0.1013\n",
      "Epoch [31/60], Loss: 0.1003\n",
      "Epoch [32/60], Loss: 0.1005\n",
      "Epoch [33/60], Loss: 0.0993\n",
      "Epoch [34/60], Loss: 0.0976\n",
      "Epoch [35/60], Loss: 0.0981\n",
      "Epoch [36/60], Loss: 0.0986\n",
      "Epoch [37/60], Loss: 0.0939\n",
      "Epoch [38/60], Loss: 0.0936\n",
      "Epoch [39/60], Loss: 0.0933\n",
      "Epoch [40/60], Loss: 0.0945\n",
      "Epoch [41/60], Loss: 0.0925\n",
      "Epoch [42/60], Loss: 0.0907\n",
      "Epoch [43/60], Loss: 0.0916\n",
      "Epoch [44/60], Loss: 0.0932\n",
      "Epoch [45/60], Loss: 0.0919\n",
      "Epoch [46/60], Loss: 0.0893\n",
      "Epoch [47/60], Loss: 0.0892\n",
      "Epoch [48/60], Loss: 0.0877\n",
      "Epoch [49/60], Loss: 0.0877\n",
      "Epoch [50/60], Loss: 0.0874\n",
      "Epoch [51/60], Loss: 0.0868\n",
      "Epoch [52/60], Loss: 0.0849\n",
      "Epoch [53/60], Loss: 0.0913\n",
      "Epoch [54/60], Loss: 0.0864\n",
      "Epoch [55/60], Loss: 0.0841\n",
      "Epoch [56/60], Loss: 0.0902\n",
      "Epoch [57/60], Loss: 0.0870\n",
      "Epoch [58/60], Loss: 0.0869\n",
      "Epoch [59/60], Loss: 0.0850\n",
      "Epoch [60/60], Loss: 0.0830\n",
      "test performance :  [99.95272064 95.04800415 91.29582977 88.48916626 82.46006012]\n",
      "individual errors:  [array(96.26478, dtype=float32), array(83.25171, dtype=float32), array(79.61579, dtype=float32), array(89.274925, dtype=float32), array(63.893093, dtype=float32)]\n",
      "EWC++  800 1e-05\n",
      "Epoch [1/60], Loss: 0.1004\n",
      "Epoch [2/60], Loss: 0.1536\n",
      "Epoch [3/60], Loss: 0.0622\n",
      "Epoch [4/60], Loss: 0.0340\n",
      "Epoch [5/60], Loss: 0.0277\n",
      "Epoch [6/60], Loss: 0.0223\n",
      "Epoch [7/60], Loss: 0.0177\n",
      "Epoch [8/60], Loss: 0.0144\n",
      "Epoch [9/60], Loss: 0.0115\n",
      "Epoch [10/60], Loss: 0.0093\n",
      "Epoch [11/60], Loss: 0.0090\n",
      "Epoch [12/60], Loss: 0.0078\n",
      "Epoch [13/60], Loss: 0.0068\n",
      "Epoch [14/60], Loss: 0.0052\n",
      "Epoch [15/60], Loss: 0.0045\n",
      "Epoch [16/60], Loss: 0.0050\n",
      "Epoch [17/60], Loss: 0.0051\n",
      "Epoch [18/60], Loss: 0.0038\n",
      "Epoch [19/60], Loss: 0.0047\n",
      "Epoch [20/60], Loss: 0.0043\n",
      "Epoch [21/60], Loss: 0.0048\n",
      "Epoch [22/60], Loss: 0.0042\n",
      "Epoch [23/60], Loss: 0.0043\n",
      "Epoch [24/60], Loss: 0.0037\n",
      "Epoch [25/60], Loss: 0.0039\n",
      "Epoch [26/60], Loss: 0.0042\n",
      "Epoch [27/60], Loss: 0.0041\n",
      "Epoch [28/60], Loss: 0.0041\n",
      "Epoch [29/60], Loss: 0.0037\n",
      "Epoch [30/60], Loss: 0.0036\n",
      "Epoch [31/60], Loss: 0.0038\n",
      "Epoch [32/60], Loss: 0.0033\n",
      "Epoch [33/60], Loss: 0.0032\n",
      "Epoch [34/60], Loss: 0.0030\n",
      "Epoch [35/60], Loss: 0.0033\n",
      "Epoch [36/60], Loss: 0.0034\n",
      "Epoch [37/60], Loss: 0.0031\n",
      "Epoch [38/60], Loss: 0.0030\n",
      "Epoch [39/60], Loss: 0.0042\n",
      "Epoch [40/60], Loss: 0.0040\n",
      "Epoch [41/60], Loss: 0.0031\n",
      "Epoch [42/60], Loss: 0.0031\n",
      "Epoch [43/60], Loss: 0.0029\n",
      "Epoch [44/60], Loss: 0.0035\n",
      "Epoch [45/60], Loss: 0.0044\n",
      "Epoch [46/60], Loss: 0.0024\n",
      "Epoch [47/60], Loss: 0.0041\n",
      "Epoch [48/60], Loss: 0.0030\n",
      "Epoch [49/60], Loss: 0.0037\n",
      "Epoch [50/60], Loss: 0.0031\n",
      "Epoch [51/60], Loss: 0.0029\n",
      "Epoch [52/60], Loss: 0.0031\n",
      "Epoch [53/60], Loss: 0.0025\n",
      "Epoch [54/60], Loss: 0.0035\n",
      "Epoch [55/60], Loss: 0.0038\n",
      "Epoch [56/60], Loss: 0.0023\n",
      "Epoch [57/60], Loss: 0.0049\n",
      "Epoch [58/60], Loss: 0.0024\n",
      "Epoch [59/60], Loss: 0.0030\n",
      "Epoch [60/60], Loss: 0.0048\n",
      "generate task data..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task data norm and number entries: tensor(459.0760, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.810875, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1563\n",
      "Epoch [2/60], Loss: 0.2859\n",
      "Epoch [3/60], Loss: 0.1873\n",
      "Epoch [4/60], Loss: 0.1099\n",
      "Epoch [5/60], Loss: 0.1041\n",
      "Epoch [6/60], Loss: 0.1001\n",
      "Epoch [7/60], Loss: 0.0962\n",
      "Epoch [8/60], Loss: 0.0925\n",
      "Epoch [9/60], Loss: 0.0887\n",
      "Epoch [10/60], Loss: 0.0858\n",
      "Epoch [11/60], Loss: 0.0833\n",
      "Epoch [12/60], Loss: 0.0794\n",
      "Epoch [13/60], Loss: 0.0739\n",
      "Epoch [14/60], Loss: 0.0714\n",
      "Epoch [15/60], Loss: 0.0691\n",
      "Epoch [16/60], Loss: 0.0651\n",
      "Epoch [17/60], Loss: 0.0640\n",
      "Epoch [18/60], Loss: 0.0611\n",
      "Epoch [19/60], Loss: 0.0576\n",
      "Epoch [20/60], Loss: 0.0577\n",
      "Epoch [21/60], Loss: 0.0543\n",
      "Epoch [22/60], Loss: 0.0522\n",
      "Epoch [23/60], Loss: 0.0523\n",
      "Epoch [24/60], Loss: 0.0484\n",
      "Epoch [25/60], Loss: 0.0468\n",
      "Epoch [26/60], Loss: 0.0482\n",
      "Epoch [27/60], Loss: 0.0492\n",
      "Epoch [28/60], Loss: 0.0471\n",
      "Epoch [29/60], Loss: 0.0433\n",
      "Epoch [30/60], Loss: 0.0432\n",
      "Epoch [31/60], Loss: 0.0438\n",
      "Epoch [32/60], Loss: 0.0392\n",
      "Epoch [33/60], Loss: 0.0397\n",
      "Epoch [34/60], Loss: 0.0399\n",
      "Epoch [35/60], Loss: 0.0395\n",
      "Epoch [36/60], Loss: 0.0382\n",
      "Epoch [37/60], Loss: 0.0373\n",
      "Epoch [38/60], Loss: 0.0375\n",
      "Epoch [39/60], Loss: 0.0361\n",
      "Epoch [40/60], Loss: 0.0371\n",
      "Epoch [41/60], Loss: 0.0351\n",
      "Epoch [42/60], Loss: 0.0358\n",
      "Epoch [43/60], Loss: 0.0349\n",
      "Epoch [44/60], Loss: 0.0340\n",
      "Epoch [45/60], Loss: 0.0363\n",
      "Epoch [46/60], Loss: 0.0362\n",
      "Epoch [47/60], Loss: 0.0319\n",
      "Epoch [48/60], Loss: 0.0377\n",
      "Epoch [49/60], Loss: 0.0336\n",
      "Epoch [50/60], Loss: 0.0330\n",
      "Epoch [51/60], Loss: 0.0334\n",
      "Epoch [52/60], Loss: 0.0332\n",
      "Epoch [53/60], Loss: 0.0326\n",
      "Epoch [54/60], Loss: 0.0336\n",
      "Epoch [55/60], Loss: 0.0338\n",
      "Epoch [56/60], Loss: 0.0311\n",
      "Epoch [57/60], Loss: 0.0328\n",
      "Epoch [58/60], Loss: 0.0316\n",
      "Epoch [59/60], Loss: 0.0304\n",
      "Epoch [60/60], Loss: 0.0316\n",
      "update data..\n",
      "task data norm and number entries: tensor(448.1887, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494 95.07752991  0.          0.          0.        ]\n",
      "individual errors:  [array(98.676125, dtype=float32), array(91.47894, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1493\n",
      "Epoch [2/60], Loss: 1.9426\n",
      "Epoch [3/60], Loss: 0.3254\n",
      "Epoch [4/60], Loss: 0.1261\n",
      "Epoch [5/60], Loss: 0.1215\n",
      "Epoch [6/60], Loss: 0.1182\n",
      "Epoch [7/60], Loss: 0.1166\n",
      "Epoch [8/60], Loss: 0.1150\n",
      "Epoch [9/60], Loss: 0.1120\n",
      "Epoch [10/60], Loss: 0.1114\n",
      "Epoch [11/60], Loss: 0.1086\n",
      "Epoch [12/60], Loss: 0.1050\n",
      "Epoch [13/60], Loss: 0.1034\n",
      "Epoch [14/60], Loss: 0.1014\n",
      "Epoch [15/60], Loss: 0.0983\n",
      "Epoch [16/60], Loss: 0.0964\n",
      "Epoch [17/60], Loss: 0.0953\n",
      "Epoch [18/60], Loss: 0.0930\n",
      "Epoch [19/60], Loss: 0.0898\n",
      "Epoch [20/60], Loss: 0.0883\n",
      "Epoch [21/60], Loss: 0.0881\n",
      "Epoch [22/60], Loss: 0.0854\n",
      "Epoch [23/60], Loss: 0.0837\n",
      "Epoch [24/60], Loss: 0.0820\n",
      "Epoch [25/60], Loss: 0.0805\n",
      "Epoch [26/60], Loss: 0.0778\n",
      "Epoch [27/60], Loss: 0.0766\n",
      "Epoch [28/60], Loss: 0.0770\n",
      "Epoch [29/60], Loss: 0.0745\n",
      "Epoch [30/60], Loss: 0.0731\n",
      "Epoch [31/60], Loss: 0.0734\n",
      "Epoch [32/60], Loss: 0.0729\n",
      "Epoch [33/60], Loss: 0.0720\n",
      "Epoch [34/60], Loss: 0.0717\n",
      "Epoch [35/60], Loss: 0.0692\n",
      "Epoch [36/60], Loss: 0.0680\n",
      "Epoch [37/60], Loss: 0.0672\n",
      "Epoch [38/60], Loss: 0.0676\n",
      "Epoch [39/60], Loss: 0.0672\n",
      "Epoch [40/60], Loss: 0.0652\n",
      "Epoch [41/60], Loss: 0.0624\n",
      "Epoch [42/60], Loss: 0.0648\n",
      "Epoch [43/60], Loss: 0.0645\n",
      "Epoch [44/60], Loss: 0.0626\n",
      "Epoch [45/60], Loss: 0.0620\n",
      "Epoch [46/60], Loss: 0.0587\n",
      "Epoch [47/60], Loss: 0.0589\n",
      "Epoch [48/60], Loss: 0.0608\n",
      "Epoch [49/60], Loss: 0.0594\n",
      "Epoch [50/60], Loss: 0.0579\n",
      "Epoch [51/60], Loss: 0.0590\n",
      "Epoch [52/60], Loss: 0.0573\n",
      "Epoch [53/60], Loss: 0.0565\n",
      "Epoch [54/60], Loss: 0.0595\n",
      "Epoch [55/60], Loss: 0.0568\n",
      "Epoch [56/60], Loss: 0.0563\n",
      "Epoch [57/60], Loss: 0.0575\n",
      "Epoch [58/60], Loss: 0.0584\n",
      "Epoch [59/60], Loss: 0.0556\n",
      "Epoch [60/60], Loss: 0.0567\n",
      "update data..\n",
      "task data norm and number entries: tensor(435.7700, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494 95.07752991 90.00602722  0.          0.        ]\n",
      "individual errors:  [array(98.39243, dtype=float32), array(89.1283, dtype=float32), array(82.49733, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1418\n",
      "Epoch [2/60], Loss: 0.1717\n",
      "Epoch [3/60], Loss: 0.3056\n",
      "Epoch [4/60], Loss: 0.1399\n",
      "Epoch [5/60], Loss: 0.1228\n",
      "Epoch [6/60], Loss: 0.1195\n",
      "Epoch [7/60], Loss: 0.1162\n",
      "Epoch [8/60], Loss: 0.1150\n",
      "Epoch [9/60], Loss: 0.1124\n",
      "Epoch [10/60], Loss: 0.1100\n",
      "Epoch [11/60], Loss: 0.1089\n",
      "Epoch [12/60], Loss: 0.1063\n",
      "Epoch [13/60], Loss: 0.1030\n",
      "Epoch [14/60], Loss: 0.0991\n",
      "Epoch [15/60], Loss: 0.1009\n",
      "Epoch [16/60], Loss: 0.0960\n",
      "Epoch [17/60], Loss: 0.0945\n",
      "Epoch [18/60], Loss: 0.0917\n",
      "Epoch [19/60], Loss: 0.0899\n",
      "Epoch [20/60], Loss: 0.0868\n",
      "Epoch [21/60], Loss: 0.0867\n",
      "Epoch [22/60], Loss: 0.0835\n",
      "Epoch [23/60], Loss: 0.0817\n",
      "Epoch [24/60], Loss: 0.0814\n",
      "Epoch [25/60], Loss: 0.0804\n",
      "Epoch [26/60], Loss: 0.0784\n",
      "Epoch [27/60], Loss: 0.0765\n",
      "Epoch [28/60], Loss: 0.0740\n",
      "Epoch [29/60], Loss: 0.0733\n",
      "Epoch [30/60], Loss: 0.0716\n",
      "Epoch [31/60], Loss: 0.0722\n",
      "Epoch [32/60], Loss: 0.0695\n",
      "Epoch [33/60], Loss: 0.0703\n",
      "Epoch [34/60], Loss: 0.0686\n",
      "Epoch [35/60], Loss: 0.0672\n",
      "Epoch [36/60], Loss: 0.0676\n",
      "Epoch [37/60], Loss: 0.0674\n",
      "Epoch [38/60], Loss: 0.0660\n",
      "Epoch [39/60], Loss: 0.0644\n",
      "Epoch [40/60], Loss: 0.0644\n",
      "Epoch [41/60], Loss: 0.0630\n",
      "Epoch [42/60], Loss: 0.0637\n",
      "Epoch [43/60], Loss: 0.0631\n",
      "Epoch [44/60], Loss: 0.0598\n",
      "Epoch [45/60], Loss: 0.0598\n",
      "Epoch [46/60], Loss: 0.0600\n",
      "Epoch [47/60], Loss: 0.0604\n",
      "Epoch [48/60], Loss: 0.0589\n",
      "Epoch [49/60], Loss: 0.0592\n",
      "Epoch [50/60], Loss: 0.0599\n",
      "Epoch [51/60], Loss: 0.0566\n",
      "Epoch [52/60], Loss: 0.0564\n",
      "Epoch [53/60], Loss: 0.0570\n",
      "Epoch [54/60], Loss: 0.0571\n",
      "Epoch [55/60], Loss: 0.0567\n",
      "Epoch [56/60], Loss: 0.0559\n",
      "Epoch [57/60], Loss: 0.0558\n",
      "Epoch [58/60], Loss: 0.0549\n",
      "Epoch [59/60], Loss: 0.0561\n",
      "Epoch [60/60], Loss: 0.0534\n",
      "update data..\n",
      "task data norm and number entries: tensor(448.8505, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.81087494 95.07752991 90.00602722 87.36628723  0.        ]\n",
      "individual errors:  [array(97.9669, dtype=float32), array(86.63075, dtype=float32), array(75.24013, dtype=float32), array(89.62739, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1344\n",
      "Epoch [2/60], Loss: 0.1877\n",
      "Epoch [3/60], Loss: 0.3495\n",
      "Epoch [4/60], Loss: 0.1388\n",
      "Epoch [5/60], Loss: 0.1220\n",
      "Epoch [6/60], Loss: 0.1202\n",
      "Epoch [7/60], Loss: 0.1200\n",
      "Epoch [8/60], Loss: 0.1180\n",
      "Epoch [9/60], Loss: 0.1164\n",
      "Epoch [10/60], Loss: 0.1155\n",
      "Epoch [11/60], Loss: 0.1147\n",
      "Epoch [12/60], Loss: 0.1124\n",
      "Epoch [13/60], Loss: 0.1119\n",
      "Epoch [14/60], Loss: 0.1109\n",
      "Epoch [15/60], Loss: 0.1092\n",
      "Epoch [16/60], Loss: 0.1085\n",
      "Epoch [17/60], Loss: 0.1068\n",
      "Epoch [18/60], Loss: 0.1065\n",
      "Epoch [19/60], Loss: 0.1041\n",
      "Epoch [20/60], Loss: 0.1042\n",
      "Epoch [21/60], Loss: 0.1030\n",
      "Epoch [22/60], Loss: 0.1030\n",
      "Epoch [23/60], Loss: 0.1001\n",
      "Epoch [24/60], Loss: 0.0995\n",
      "Epoch [25/60], Loss: 0.0998\n",
      "Epoch [26/60], Loss: 0.0989\n",
      "Epoch [27/60], Loss: 0.0995\n",
      "Epoch [28/60], Loss: 0.0964\n",
      "Epoch [29/60], Loss: 0.0979\n",
      "Epoch [30/60], Loss: 0.0941\n",
      "Epoch [31/60], Loss: 0.0950\n",
      "Epoch [32/60], Loss: 0.0940\n",
      "Epoch [33/60], Loss: 0.0943\n",
      "Epoch [34/60], Loss: 0.0929\n",
      "Epoch [35/60], Loss: 0.0936\n",
      "Epoch [36/60], Loss: 0.0951\n",
      "Epoch [37/60], Loss: 0.0915\n",
      "Epoch [38/60], Loss: 0.0895\n",
      "Epoch [39/60], Loss: 0.0909\n",
      "Epoch [40/60], Loss: 0.0904\n",
      "Epoch [41/60], Loss: 0.0902\n",
      "Epoch [42/60], Loss: 0.0884\n",
      "Epoch [43/60], Loss: 0.0911\n",
      "Epoch [44/60], Loss: 0.0921\n",
      "Epoch [45/60], Loss: 0.0921\n",
      "Epoch [46/60], Loss: 0.0898\n",
      "Epoch [47/60], Loss: 0.0859\n",
      "Epoch [48/60], Loss: 0.0866\n",
      "Epoch [49/60], Loss: 0.0876\n",
      "Epoch [50/60], Loss: 0.0856\n",
      "Epoch [51/60], Loss: 0.0861\n",
      "Epoch [52/60], Loss: 0.0876\n",
      "Epoch [53/60], Loss: 0.0880\n",
      "Epoch [54/60], Loss: 0.0899\n",
      "Epoch [55/60], Loss: 0.0837\n",
      "Epoch [56/60], Loss: 0.0880\n",
      "Epoch [57/60], Loss: 0.0915\n",
      "Epoch [58/60], Loss: 0.0858\n",
      "Epoch [59/60], Loss: 0.0814\n",
      "Epoch [60/60], Loss: 0.0827\n",
      "test performance :  [99.81087494 95.07752991 90.00602722 87.36628723 81.4644165 ]\n",
      "individual errors:  [array(97.16312, dtype=float32), array(84.182175, dtype=float32), array(69.58378, dtype=float32), array(90.8862, dtype=float32), array(65.506805, dtype=float32)]\n",
      "EWC++  1600 1e-05\n",
      "Epoch [1/60], Loss: 0.0975\n",
      "Epoch [2/60], Loss: 0.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/60], Loss: 0.0603\n",
      "Epoch [4/60], Loss: 0.0333\n",
      "Epoch [5/60], Loss: 0.0270\n",
      "Epoch [6/60], Loss: 0.0214\n",
      "Epoch [7/60], Loss: 0.0182\n",
      "Epoch [8/60], Loss: 0.0142\n",
      "Epoch [9/60], Loss: 0.0113\n",
      "Epoch [10/60], Loss: 0.0088\n",
      "Epoch [11/60], Loss: 0.0075\n",
      "Epoch [12/60], Loss: 0.0077\n",
      "Epoch [13/60], Loss: 0.0055\n",
      "Epoch [14/60], Loss: 0.0053\n",
      "Epoch [15/60], Loss: 0.0045\n",
      "Epoch [16/60], Loss: 0.0052\n",
      "Epoch [17/60], Loss: 0.0046\n",
      "Epoch [18/60], Loss: 0.0041\n",
      "Epoch [19/60], Loss: 0.0047\n",
      "Epoch [20/60], Loss: 0.0045\n",
      "Epoch [21/60], Loss: 0.0044\n",
      "Epoch [22/60], Loss: 0.0043\n",
      "Epoch [23/60], Loss: 0.0043\n",
      "Epoch [24/60], Loss: 0.0037\n",
      "Epoch [25/60], Loss: 0.0040\n",
      "Epoch [26/60], Loss: 0.0040\n",
      "Epoch [27/60], Loss: 0.0040\n",
      "Epoch [28/60], Loss: 0.0036\n",
      "Epoch [29/60], Loss: 0.0040\n",
      "Epoch [30/60], Loss: 0.0036\n",
      "Epoch [31/60], Loss: 0.0037\n",
      "Epoch [32/60], Loss: 0.0031\n",
      "Epoch [33/60], Loss: 0.0035\n",
      "Epoch [34/60], Loss: 0.0030\n",
      "Epoch [35/60], Loss: 0.0034\n",
      "Epoch [36/60], Loss: 0.0035\n",
      "Epoch [37/60], Loss: 0.0030\n",
      "Epoch [38/60], Loss: 0.0036\n",
      "Epoch [39/60], Loss: 0.0033\n",
      "Epoch [40/60], Loss: 0.0025\n",
      "Epoch [41/60], Loss: 0.0034\n",
      "Epoch [42/60], Loss: 0.0034\n",
      "Epoch [43/60], Loss: 0.0027\n",
      "Epoch [44/60], Loss: 0.0031\n",
      "Epoch [45/60], Loss: 0.0031\n",
      "Epoch [46/60], Loss: 0.0032\n",
      "Epoch [47/60], Loss: 0.0035\n",
      "Epoch [48/60], Loss: 0.0031\n",
      "Epoch [49/60], Loss: 0.0030\n",
      "Epoch [50/60], Loss: 0.0034\n",
      "Epoch [51/60], Loss: 0.0032\n",
      "Epoch [52/60], Loss: 0.0028\n",
      "Epoch [53/60], Loss: 0.0028\n",
      "Epoch [54/60], Loss: 0.0024\n",
      "Epoch [55/60], Loss: 0.0024\n",
      "Epoch [56/60], Loss: 0.0034\n",
      "Epoch [57/60], Loss: 0.0026\n",
      "Epoch [58/60], Loss: 0.0031\n",
      "Epoch [59/60], Loss: 0.0028\n",
      "Epoch [60/60], Loss: 0.0040\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(454.9820, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.763596, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1563\n",
      "Epoch [2/60], Loss: 0.2300\n",
      "Epoch [3/60], Loss: 0.1793\n",
      "Epoch [4/60], Loss: 0.1113\n",
      "Epoch [5/60], Loss: 0.1053\n",
      "Epoch [6/60], Loss: 0.1015\n",
      "Epoch [7/60], Loss: 0.0982\n",
      "Epoch [8/60], Loss: 0.0954\n",
      "Epoch [9/60], Loss: 0.0920\n",
      "Epoch [10/60], Loss: 0.0890\n",
      "Epoch [11/60], Loss: 0.0866\n",
      "Epoch [12/60], Loss: 0.0841\n",
      "Epoch [13/60], Loss: 0.0795\n",
      "Epoch [14/60], Loss: 0.0763\n",
      "Epoch [15/60], Loss: 0.0747\n",
      "Epoch [16/60], Loss: 0.0706\n",
      "Epoch [17/60], Loss: 0.0679\n",
      "Epoch [18/60], Loss: 0.0670\n",
      "Epoch [19/60], Loss: 0.0636\n",
      "Epoch [20/60], Loss: 0.0622\n",
      "Epoch [21/60], Loss: 0.0593\n",
      "Epoch [22/60], Loss: 0.0579\n",
      "Epoch [23/60], Loss: 0.0547\n",
      "Epoch [24/60], Loss: 0.0583\n",
      "Epoch [25/60], Loss: 0.0525\n",
      "Epoch [26/60], Loss: 0.0509\n",
      "Epoch [27/60], Loss: 0.0503\n",
      "Epoch [28/60], Loss: 0.0495\n",
      "Epoch [29/60], Loss: 0.0495\n",
      "Epoch [30/60], Loss: 0.0449\n",
      "Epoch [31/60], Loss: 0.0436\n",
      "Epoch [32/60], Loss: 0.0428\n",
      "Epoch [33/60], Loss: 0.0448\n",
      "Epoch [34/60], Loss: 0.0429\n",
      "Epoch [35/60], Loss: 0.0432\n",
      "Epoch [36/60], Loss: 0.0406\n",
      "Epoch [37/60], Loss: 0.0428\n",
      "Epoch [38/60], Loss: 0.0415\n",
      "Epoch [39/60], Loss: 0.0386\n",
      "Epoch [40/60], Loss: 0.0399\n",
      "Epoch [41/60], Loss: 0.0380\n",
      "Epoch [42/60], Loss: 0.0385\n",
      "Epoch [43/60], Loss: 0.0381\n",
      "Epoch [44/60], Loss: 0.0379\n",
      "Epoch [45/60], Loss: 0.0373\n",
      "Epoch [46/60], Loss: 0.0369\n",
      "Epoch [47/60], Loss: 0.0375\n",
      "Epoch [48/60], Loss: 0.0381\n",
      "Epoch [49/60], Loss: 0.0401\n",
      "Epoch [50/60], Loss: 0.0376\n",
      "Epoch [51/60], Loss: 0.0359\n",
      "Epoch [52/60], Loss: 0.0372\n",
      "Epoch [53/60], Loss: 0.0355\n",
      "Epoch [54/60], Loss: 0.0340\n",
      "Epoch [55/60], Loss: 0.0328\n",
      "Epoch [56/60], Loss: 0.0336\n",
      "Epoch [57/60], Loss: 0.0346\n",
      "Epoch [58/60], Loss: 0.0354\n",
      "Epoch [59/60], Loss: 0.0335\n",
      "Epoch [60/60], Loss: 0.0350\n",
      "update data..\n",
      "task data norm and number entries: tensor(445.2495, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 92.57998657  0.          0.          0.        ]\n",
      "individual errors:  [array(98.676125, dtype=float32), array(86.48384, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1463\n",
      "Epoch [2/60], Loss: 1.6250\n",
      "Epoch [3/60], Loss: 0.2882\n",
      "Epoch [4/60], Loss: 0.1260\n",
      "Epoch [5/60], Loss: 0.1205\n",
      "Epoch [6/60], Loss: 0.1174\n",
      "Epoch [7/60], Loss: 0.1144\n",
      "Epoch [8/60], Loss: 0.1127\n",
      "Epoch [9/60], Loss: 0.1106\n",
      "Epoch [10/60], Loss: 0.1062\n",
      "Epoch [11/60], Loss: 0.1045\n",
      "Epoch [12/60], Loss: 0.1033\n",
      "Epoch [13/60], Loss: 0.1005\n",
      "Epoch [14/60], Loss: 0.0979\n",
      "Epoch [15/60], Loss: 0.0969\n",
      "Epoch [16/60], Loss: 0.0929\n",
      "Epoch [17/60], Loss: 0.0914\n",
      "Epoch [18/60], Loss: 0.0910\n",
      "Epoch [19/60], Loss: 0.0879\n",
      "Epoch [20/60], Loss: 0.0877\n",
      "Epoch [21/60], Loss: 0.0827\n",
      "Epoch [22/60], Loss: 0.0836\n",
      "Epoch [23/60], Loss: 0.0808\n",
      "Epoch [24/60], Loss: 0.0810\n",
      "Epoch [25/60], Loss: 0.0786\n",
      "Epoch [26/60], Loss: 0.0777\n",
      "Epoch [27/60], Loss: 0.0772\n",
      "Epoch [28/60], Loss: 0.0730\n",
      "Epoch [29/60], Loss: 0.0760\n",
      "Epoch [30/60], Loss: 0.0711\n",
      "Epoch [31/60], Loss: 0.0728\n",
      "Epoch [32/60], Loss: 0.0690\n",
      "Epoch [33/60], Loss: 0.0695\n",
      "Epoch [34/60], Loss: 0.0693\n",
      "Epoch [35/60], Loss: 0.0684\n",
      "Epoch [36/60], Loss: 0.0656\n",
      "Epoch [37/60], Loss: 0.0639\n",
      "Epoch [38/60], Loss: 0.0650\n",
      "Epoch [39/60], Loss: 0.0652\n",
      "Epoch [40/60], Loss: 0.0643\n",
      "Epoch [41/60], Loss: 0.0648\n",
      "Epoch [42/60], Loss: 0.0632\n",
      "Epoch [43/60], Loss: 0.0623\n",
      "Epoch [44/60], Loss: 0.0614\n",
      "Epoch [45/60], Loss: 0.0626\n",
      "Epoch [46/60], Loss: 0.0597\n",
      "Epoch [47/60], Loss: 0.0583\n",
      "Epoch [48/60], Loss: 0.0619\n",
      "Epoch [49/60], Loss: 0.0609\n",
      "Epoch [50/60], Loss: 0.0613\n",
      "Epoch [51/60], Loss: 0.0646\n",
      "Epoch [52/60], Loss: 0.0599\n",
      "Epoch [53/60], Loss: 0.0568\n",
      "Epoch [54/60], Loss: 0.0570\n",
      "Epoch [55/60], Loss: 0.0563\n",
      "Epoch [56/60], Loss: 0.0580\n",
      "Epoch [57/60], Loss: 0.0621\n",
      "Epoch [58/60], Loss: 0.0591\n",
      "Epoch [59/60], Loss: 0.0578\n",
      "Epoch [60/60], Loss: 0.0544\n",
      "update data..\n",
      "task data norm and number entries: tensor(427.8029, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 92.57998657 89.01983643  0.          0.        ]\n",
      "individual errors:  [array(98.10875, dtype=float32), array(83.25171, dtype=float32), array(85.699036, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1375\n",
      "Epoch [2/60], Loss: 0.1681\n",
      "Epoch [3/60], Loss: 0.2871\n",
      "Epoch [4/60], Loss: 0.1305\n",
      "Epoch [5/60], Loss: 0.1171\n",
      "Epoch [6/60], Loss: 0.1139\n",
      "Epoch [7/60], Loss: 0.1120\n",
      "Epoch [8/60], Loss: 0.1078\n",
      "Epoch [9/60], Loss: 0.1061\n",
      "Epoch [10/60], Loss: 0.1027\n",
      "Epoch [11/60], Loss: 0.1001\n",
      "Epoch [12/60], Loss: 0.0972\n",
      "Epoch [13/60], Loss: 0.0970\n",
      "Epoch [14/60], Loss: 0.0923\n",
      "Epoch [15/60], Loss: 0.0909\n",
      "Epoch [16/60], Loss: 0.0880\n",
      "Epoch [17/60], Loss: 0.0876\n",
      "Epoch [18/60], Loss: 0.0846\n",
      "Epoch [19/60], Loss: 0.0824\n",
      "Epoch [20/60], Loss: 0.0792\n",
      "Epoch [21/60], Loss: 0.0784\n",
      "Epoch [22/60], Loss: 0.0779\n",
      "Epoch [23/60], Loss: 0.0772\n",
      "Epoch [24/60], Loss: 0.0746\n",
      "Epoch [25/60], Loss: 0.0749\n",
      "Epoch [26/60], Loss: 0.0716\n",
      "Epoch [27/60], Loss: 0.0695\n",
      "Epoch [28/60], Loss: 0.0690\n",
      "Epoch [29/60], Loss: 0.0682\n",
      "Epoch [30/60], Loss: 0.0677\n",
      "Epoch [31/60], Loss: 0.0648\n",
      "Epoch [32/60], Loss: 0.0661\n",
      "Epoch [33/60], Loss: 0.0646\n",
      "Epoch [34/60], Loss: 0.0629\n",
      "Epoch [35/60], Loss: 0.0626\n",
      "Epoch [36/60], Loss: 0.0629\n",
      "Epoch [37/60], Loss: 0.0611\n",
      "Epoch [38/60], Loss: 0.0606\n",
      "Epoch [39/60], Loss: 0.0586\n",
      "Epoch [40/60], Loss: 0.0601\n",
      "Epoch [41/60], Loss: 0.0599\n",
      "Epoch [42/60], Loss: 0.0589\n",
      "Epoch [43/60], Loss: 0.0577\n",
      "Epoch [44/60], Loss: 0.0591\n",
      "Epoch [45/60], Loss: 0.0592\n",
      "Epoch [46/60], Loss: 0.0588\n",
      "Epoch [47/60], Loss: 0.0582\n",
      "Epoch [48/60], Loss: 0.0553\n",
      "Epoch [49/60], Loss: 0.0596\n",
      "Epoch [50/60], Loss: 0.0564\n",
      "Epoch [51/60], Loss: 0.0551\n",
      "Epoch [52/60], Loss: 0.0538\n",
      "Epoch [53/60], Loss: 0.0566\n",
      "Epoch [54/60], Loss: 0.0541\n",
      "Epoch [55/60], Loss: 0.0548\n",
      "Epoch [56/60], Loss: 0.0544\n",
      "Epoch [57/60], Loss: 0.0533\n",
      "Epoch [58/60], Loss: 0.0518\n",
      "Epoch [59/60], Loss: 0.0547\n",
      "Epoch [60/60], Loss: 0.0519\n",
      "update data..\n",
      "task data norm and number entries: tensor(447.9527, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 92.57998657 89.01983643 87.26060486  0.        ]\n",
      "individual errors:  [array(97.73049, dtype=float32), array(79.87267, dtype=float32), array(81.056564, dtype=float32), array(90.382675, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1328\n",
      "Epoch [2/60], Loss: 0.1837\n",
      "Epoch [3/60], Loss: 0.3387\n",
      "Epoch [4/60], Loss: 0.1357\n",
      "Epoch [5/60], Loss: 0.1209\n",
      "Epoch [6/60], Loss: 0.1180\n",
      "Epoch [7/60], Loss: 0.1176\n",
      "Epoch [8/60], Loss: 0.1155\n",
      "Epoch [9/60], Loss: 0.1142\n",
      "Epoch [10/60], Loss: 0.1134\n",
      "Epoch [11/60], Loss: 0.1128\n",
      "Epoch [12/60], Loss: 0.1117\n",
      "Epoch [13/60], Loss: 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/60], Loss: 0.1101\n",
      "Epoch [15/60], Loss: 0.1091\n",
      "Epoch [16/60], Loss: 0.1086\n",
      "Epoch [17/60], Loss: 0.1061\n",
      "Epoch [18/60], Loss: 0.1063\n",
      "Epoch [19/60], Loss: 0.1040\n",
      "Epoch [20/60], Loss: 0.1030\n",
      "Epoch [21/60], Loss: 0.1031\n",
      "Epoch [22/60], Loss: 0.1016\n",
      "Epoch [23/60], Loss: 0.1028\n",
      "Epoch [24/60], Loss: 0.1007\n",
      "Epoch [25/60], Loss: 0.0999\n",
      "Epoch [26/60], Loss: 0.0982\n",
      "Epoch [27/60], Loss: 0.0974\n",
      "Epoch [28/60], Loss: 0.0982\n",
      "Epoch [29/60], Loss: 0.0954\n",
      "Epoch [30/60], Loss: 0.0957\n",
      "Epoch [31/60], Loss: 0.0964\n",
      "Epoch [32/60], Loss: 0.0946\n",
      "Epoch [33/60], Loss: 0.0946\n",
      "Epoch [34/60], Loss: 0.0929\n",
      "Epoch [35/60], Loss: 0.0920\n",
      "Epoch [36/60], Loss: 0.0928\n",
      "Epoch [37/60], Loss: 0.0966\n",
      "Epoch [38/60], Loss: 0.0927\n",
      "Epoch [39/60], Loss: 0.0907\n",
      "Epoch [40/60], Loss: 0.0898\n",
      "Epoch [41/60], Loss: 0.0905\n",
      "Epoch [42/60], Loss: 0.0886\n",
      "Epoch [43/60], Loss: 0.0890\n",
      "Epoch [44/60], Loss: 0.0894\n",
      "Epoch [45/60], Loss: 0.0876\n",
      "Epoch [46/60], Loss: 0.0872\n",
      "Epoch [47/60], Loss: 0.0863\n",
      "Epoch [48/60], Loss: 0.0878\n",
      "Epoch [49/60], Loss: 0.0868\n",
      "Epoch [50/60], Loss: 0.0866\n",
      "Epoch [51/60], Loss: 0.0858\n",
      "Epoch [52/60], Loss: 0.0873\n",
      "Epoch [53/60], Loss: 0.0855\n",
      "Epoch [54/60], Loss: 0.0841\n",
      "Epoch [55/60], Loss: 0.0847\n",
      "Epoch [56/60], Loss: 0.0856\n",
      "Epoch [57/60], Loss: 0.0843\n",
      "Epoch [58/60], Loss: 0.0821\n",
      "Epoch [59/60], Loss: 0.0838\n",
      "Epoch [60/60], Loss: 0.0833\n",
      "test performance :  [99.76359558 92.57998657 89.01983643 87.26060486 80.94598389]\n",
      "individual errors:  [array(97.30496, dtype=float32), array(78.30558, dtype=float32), array(77.214516, dtype=float32), array(90.8862, dtype=float32), array(61.018658, dtype=float32)]\n",
      "EWC++  3200 1e-05\n",
      "Epoch [1/60], Loss: 0.1015\n",
      "Epoch [2/60], Loss: 0.1607\n",
      "Epoch [3/60], Loss: 0.0636\n",
      "Epoch [4/60], Loss: 0.0336\n",
      "Epoch [5/60], Loss: 0.0266\n",
      "Epoch [6/60], Loss: 0.0216\n",
      "Epoch [7/60], Loss: 0.0170\n",
      "Epoch [8/60], Loss: 0.0137\n",
      "Epoch [9/60], Loss: 0.0111\n",
      "Epoch [10/60], Loss: 0.0093\n",
      "Epoch [11/60], Loss: 0.0076\n",
      "Epoch [12/60], Loss: 0.0061\n",
      "Epoch [13/60], Loss: 0.0052\n",
      "Epoch [14/60], Loss: 0.0048\n",
      "Epoch [15/60], Loss: 0.0046\n",
      "Epoch [16/60], Loss: 0.0047\n",
      "Epoch [17/60], Loss: 0.0040\n",
      "Epoch [18/60], Loss: 0.0043\n",
      "Epoch [19/60], Loss: 0.0044\n",
      "Epoch [20/60], Loss: 0.0041\n",
      "Epoch [21/60], Loss: 0.0036\n",
      "Epoch [22/60], Loss: 0.0032\n",
      "Epoch [23/60], Loss: 0.0041\n",
      "Epoch [24/60], Loss: 0.0029\n",
      "Epoch [25/60], Loss: 0.0031\n",
      "Epoch [26/60], Loss: 0.0032\n",
      "Epoch [27/60], Loss: 0.0040\n",
      "Epoch [28/60], Loss: 0.0034\n",
      "Epoch [29/60], Loss: 0.0032\n",
      "Epoch [30/60], Loss: 0.0033\n",
      "Epoch [31/60], Loss: 0.0037\n",
      "Epoch [32/60], Loss: 0.0032\n",
      "Epoch [33/60], Loss: 0.0029\n",
      "Epoch [34/60], Loss: 0.0036\n",
      "Epoch [35/60], Loss: 0.0029\n",
      "Epoch [36/60], Loss: 0.0029\n",
      "Epoch [37/60], Loss: 0.0022\n",
      "Epoch [38/60], Loss: 0.0028\n",
      "Epoch [39/60], Loss: 0.0032\n",
      "Epoch [40/60], Loss: 0.0032\n",
      "Epoch [41/60], Loss: 0.0029\n",
      "Epoch [42/60], Loss: 0.0030\n",
      "Epoch [43/60], Loss: 0.0028\n",
      "Epoch [44/60], Loss: 0.0025\n",
      "Epoch [45/60], Loss: 0.0028\n",
      "Epoch [46/60], Loss: 0.0032\n",
      "Epoch [47/60], Loss: 0.0028\n",
      "Epoch [48/60], Loss: 0.0027\n",
      "Epoch [49/60], Loss: 0.0022\n",
      "Epoch [50/60], Loss: 0.0023\n",
      "Epoch [51/60], Loss: 0.0027\n",
      "Epoch [52/60], Loss: 0.0027\n",
      "Epoch [53/60], Loss: 0.0027\n",
      "Epoch [54/60], Loss: 0.0023\n",
      "Epoch [55/60], Loss: 0.0024\n",
      "Epoch [56/60], Loss: 0.0020\n",
      "Epoch [57/60], Loss: 0.0023\n",
      "Epoch [58/60], Loss: 0.0024\n",
      "Epoch [59/60], Loss: 0.0025\n",
      "Epoch [60/60], Loss: 0.0021\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(461.9378, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.90543, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1534\n",
      "Epoch [2/60], Loss: 0.3405\n",
      "Epoch [3/60], Loss: 0.1680\n",
      "Epoch [4/60], Loss: 0.1087\n",
      "Epoch [5/60], Loss: 0.1022\n",
      "Epoch [6/60], Loss: 0.0984\n",
      "Epoch [7/60], Loss: 0.0955\n",
      "Epoch [8/60], Loss: 0.0919\n",
      "Epoch [9/60], Loss: 0.0883\n",
      "Epoch [10/60], Loss: 0.0843\n",
      "Epoch [11/60], Loss: 0.0817\n",
      "Epoch [12/60], Loss: 0.0775\n",
      "Epoch [13/60], Loss: 0.0743\n",
      "Epoch [14/60], Loss: 0.0729\n",
      "Epoch [15/60], Loss: 0.0687\n",
      "Epoch [16/60], Loss: 0.0678\n",
      "Epoch [17/60], Loss: 0.0648\n",
      "Epoch [18/60], Loss: 0.0612\n",
      "Epoch [19/60], Loss: 0.0601\n",
      "Epoch [20/60], Loss: 0.0559\n",
      "Epoch [21/60], Loss: 0.0550\n",
      "Epoch [22/60], Loss: 0.0522\n",
      "Epoch [23/60], Loss: 0.0519\n",
      "Epoch [24/60], Loss: 0.0496\n",
      "Epoch [25/60], Loss: 0.0489\n",
      "Epoch [26/60], Loss: 0.0468\n",
      "Epoch [27/60], Loss: 0.0461\n",
      "Epoch [28/60], Loss: 0.0431\n",
      "Epoch [29/60], Loss: 0.0434\n",
      "Epoch [30/60], Loss: 0.0430\n",
      "Epoch [31/60], Loss: 0.0415\n",
      "Epoch [32/60], Loss: 0.0403\n",
      "Epoch [33/60], Loss: 0.0412\n",
      "Epoch [34/60], Loss: 0.0408\n",
      "Epoch [35/60], Loss: 0.0402\n",
      "Epoch [36/60], Loss: 0.0389\n",
      "Epoch [37/60], Loss: 0.0414\n",
      "Epoch [38/60], Loss: 0.0383\n",
      "Epoch [39/60], Loss: 0.0366\n",
      "Epoch [40/60], Loss: 0.0380\n",
      "Epoch [41/60], Loss: 0.0360\n",
      "Epoch [42/60], Loss: 0.0362\n",
      "Epoch [43/60], Loss: 0.0351\n",
      "Epoch [44/60], Loss: 0.0361\n",
      "Epoch [45/60], Loss: 0.0334\n",
      "Epoch [46/60], Loss: 0.0346\n",
      "Epoch [47/60], Loss: 0.0347\n",
      "Epoch [48/60], Loss: 0.0348\n",
      "Epoch [49/60], Loss: 0.0346\n",
      "Epoch [50/60], Loss: 0.0342\n",
      "Epoch [51/60], Loss: 0.0337\n",
      "Epoch [52/60], Loss: 0.0333\n",
      "Epoch [53/60], Loss: 0.0338\n",
      "Epoch [54/60], Loss: 0.0344\n",
      "Epoch [55/60], Loss: 0.0327\n",
      "Epoch [56/60], Loss: 0.0350\n",
      "Epoch [57/60], Loss: 0.0320\n",
      "Epoch [58/60], Loss: 0.0326\n",
      "Epoch [59/60], Loss: 0.0347\n",
      "Epoch [60/60], Loss: 0.0328\n",
      "update data..\n",
      "task data norm and number entries: tensor(452.2037, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365 94.85293579  0.          0.          0.        ]\n",
      "individual errors:  [array(98.91253, dtype=float32), array(90.793335, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1432\n",
      "Epoch [2/60], Loss: 2.0402\n",
      "Epoch [3/60], Loss: 0.3308\n",
      "Epoch [4/60], Loss: 0.1247\n",
      "Epoch [5/60], Loss: 0.1182\n",
      "Epoch [6/60], Loss: 0.1129\n",
      "Epoch [7/60], Loss: 0.1104\n",
      "Epoch [8/60], Loss: 0.1101\n",
      "Epoch [9/60], Loss: 0.1072\n",
      "Epoch [10/60], Loss: 0.1053\n",
      "Epoch [11/60], Loss: 0.1016\n",
      "Epoch [12/60], Loss: 0.1027\n",
      "Epoch [13/60], Loss: 0.0974\n",
      "Epoch [14/60], Loss: 0.0960\n",
      "Epoch [15/60], Loss: 0.0949\n",
      "Epoch [16/60], Loss: 0.0917\n",
      "Epoch [17/60], Loss: 0.0904\n",
      "Epoch [18/60], Loss: 0.0877\n",
      "Epoch [19/60], Loss: 0.0873\n",
      "Epoch [20/60], Loss: 0.0843\n",
      "Epoch [21/60], Loss: 0.0825\n",
      "Epoch [22/60], Loss: 0.0825\n",
      "Epoch [23/60], Loss: 0.0797\n",
      "Epoch [24/60], Loss: 0.0767\n",
      "Epoch [25/60], Loss: 0.0775\n",
      "Epoch [26/60], Loss: 0.0772\n",
      "Epoch [27/60], Loss: 0.0751\n",
      "Epoch [28/60], Loss: 0.0734\n",
      "Epoch [29/60], Loss: 0.0710\n",
      "Epoch [30/60], Loss: 0.0720\n",
      "Epoch [31/60], Loss: 0.0703\n",
      "Epoch [32/60], Loss: 0.0704\n",
      "Epoch [33/60], Loss: 0.0666\n",
      "Epoch [34/60], Loss: 0.0674\n",
      "Epoch [35/60], Loss: 0.0640\n",
      "Epoch [36/60], Loss: 0.0652\n",
      "Epoch [37/60], Loss: 0.0651\n",
      "Epoch [38/60], Loss: 0.0641\n",
      "Epoch [39/60], Loss: 0.0637\n",
      "Epoch [40/60], Loss: 0.0655\n",
      "Epoch [41/60], Loss: 0.0645\n",
      "Epoch [42/60], Loss: 0.0653\n",
      "Epoch [43/60], Loss: 0.0620\n",
      "Epoch [44/60], Loss: 0.0634\n",
      "Epoch [45/60], Loss: 0.0598\n",
      "Epoch [46/60], Loss: 0.0612\n",
      "Epoch [47/60], Loss: 0.0613\n",
      "Epoch [48/60], Loss: 0.0602\n",
      "Epoch [49/60], Loss: 0.0585\n",
      "Epoch [50/60], Loss: 0.0585\n",
      "Epoch [51/60], Loss: 0.0576\n",
      "Epoch [52/60], Loss: 0.0568\n",
      "Epoch [53/60], Loss: 0.0577\n",
      "Epoch [54/60], Loss: 0.0592\n",
      "Epoch [55/60], Loss: 0.0572\n",
      "Epoch [56/60], Loss: 0.0568\n",
      "Epoch [57/60], Loss: 0.0575\n",
      "Epoch [58/60], Loss: 0.0554\n",
      "Epoch [59/60], Loss: 0.0571\n",
      "Epoch [60/60], Loss: 0.0568\n",
      "update data..\n",
      "task data norm and number entries: tensor(435.1509, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365 94.85293579 88.82789612  0.          0.        ]\n",
      "individual errors:  [array(98.58156, dtype=float32), array(87.80607, dtype=float32), array(80.09605, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1412\n",
      "Epoch [2/60], Loss: 0.1790\n",
      "Epoch [3/60], Loss: 0.3136\n",
      "Epoch [4/60], Loss: 0.1355\n",
      "Epoch [5/60], Loss: 0.1204\n",
      "Epoch [6/60], Loss: 0.1163\n",
      "Epoch [7/60], Loss: 0.1146\n",
      "Epoch [8/60], Loss: 0.1125\n",
      "Epoch [9/60], Loss: 0.1117\n",
      "Epoch [10/60], Loss: 0.1086\n",
      "Epoch [11/60], Loss: 0.1036\n",
      "Epoch [12/60], Loss: 0.1023\n",
      "Epoch [13/60], Loss: 0.1002\n",
      "Epoch [14/60], Loss: 0.0967\n",
      "Epoch [15/60], Loss: 0.0957\n",
      "Epoch [16/60], Loss: 0.0924\n",
      "Epoch [17/60], Loss: 0.0902\n",
      "Epoch [18/60], Loss: 0.0899\n",
      "Epoch [19/60], Loss: 0.0864\n",
      "Epoch [20/60], Loss: 0.0857\n",
      "Epoch [21/60], Loss: 0.0815\n",
      "Epoch [22/60], Loss: 0.0802\n",
      "Epoch [23/60], Loss: 0.0779\n",
      "Epoch [24/60], Loss: 0.0796\n",
      "Epoch [25/60], Loss: 0.0769\n",
      "Epoch [26/60], Loss: 0.0768\n",
      "Epoch [27/60], Loss: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/60], Loss: 0.0713\n",
      "Epoch [29/60], Loss: 0.0710\n",
      "Epoch [30/60], Loss: 0.0697\n",
      "Epoch [31/60], Loss: 0.0695\n",
      "Epoch [32/60], Loss: 0.0685\n",
      "Epoch [33/60], Loss: 0.0683\n",
      "Epoch [34/60], Loss: 0.0676\n",
      "Epoch [35/60], Loss: 0.0673\n",
      "Epoch [36/60], Loss: 0.0656\n",
      "Epoch [37/60], Loss: 0.0655\n",
      "Epoch [38/60], Loss: 0.0657\n",
      "Epoch [39/60], Loss: 0.0633\n",
      "Epoch [40/60], Loss: 0.0656\n",
      "Epoch [41/60], Loss: 0.0634\n",
      "Epoch [42/60], Loss: 0.0614\n",
      "Epoch [43/60], Loss: 0.0617\n",
      "Epoch [44/60], Loss: 0.0601\n",
      "Epoch [45/60], Loss: 0.0614\n",
      "Epoch [46/60], Loss: 0.0604\n",
      "Epoch [47/60], Loss: 0.0616\n",
      "Epoch [48/60], Loss: 0.0601\n",
      "Epoch [49/60], Loss: 0.0601\n",
      "Epoch [50/60], Loss: 0.0581\n",
      "Epoch [51/60], Loss: 0.0599\n",
      "Epoch [52/60], Loss: 0.0604\n",
      "Epoch [53/60], Loss: 0.0584\n",
      "Epoch [54/60], Loss: 0.0579\n",
      "Epoch [55/60], Loss: 0.0568\n",
      "Epoch [56/60], Loss: 0.0569\n",
      "Epoch [57/60], Loss: 0.0566\n",
      "Epoch [58/60], Loss: 0.0549\n",
      "Epoch [59/60], Loss: 0.0571\n",
      "Epoch [60/60], Loss: 0.0573\n",
      "update data..\n",
      "task data norm and number entries: tensor(454.0721, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.90543365 94.85293579 88.82789612 87.35305786  0.        ]\n",
      "individual errors:  [array(98.297874, dtype=float32), array(84.182175, dtype=float32), array(78.81537, dtype=float32), array(88.11682, dtype=float32)]\n",
      "Epoch [1/60], Loss: 0.1343\n",
      "Epoch [2/60], Loss: 0.1923\n",
      "Epoch [3/60], Loss: 0.3636\n",
      "Epoch [4/60], Loss: 0.1389\n",
      "Epoch [5/60], Loss: 0.1211\n",
      "Epoch [6/60], Loss: 0.1194\n",
      "Epoch [7/60], Loss: 0.1177\n",
      "Epoch [8/60], Loss: 0.1181\n",
      "Epoch [9/60], Loss: 0.1150\n",
      "Epoch [10/60], Loss: 0.1146\n",
      "Epoch [11/60], Loss: 0.1142\n",
      "Epoch [12/60], Loss: 0.1122\n",
      "Epoch [13/60], Loss: 0.1104\n",
      "Epoch [14/60], Loss: 0.1096\n",
      "Epoch [15/60], Loss: 0.1086\n",
      "Epoch [16/60], Loss: 0.1067\n",
      "Epoch [17/60], Loss: 0.1062\n",
      "Epoch [18/60], Loss: 0.1048\n",
      "Epoch [19/60], Loss: 0.1057\n",
      "Epoch [20/60], Loss: 0.1035\n",
      "Epoch [21/60], Loss: 0.1002\n",
      "Epoch [22/60], Loss: 0.1013\n",
      "Epoch [23/60], Loss: 0.1009\n",
      "Epoch [24/60], Loss: 0.0998\n",
      "Epoch [25/60], Loss: 0.0982\n",
      "Epoch [26/60], Loss: 0.0987\n",
      "Epoch [27/60], Loss: 0.0985\n",
      "Epoch [28/60], Loss: 0.0954\n",
      "Epoch [29/60], Loss: 0.1026\n",
      "Epoch [30/60], Loss: 0.0941\n",
      "Epoch [31/60], Loss: 0.0935\n",
      "Epoch [32/60], Loss: 0.0954\n",
      "Epoch [33/60], Loss: 0.0925\n",
      "Epoch [34/60], Loss: 0.0910\n",
      "Epoch [35/60], Loss: 0.0929\n",
      "Epoch [36/60], Loss: 0.0918\n",
      "Epoch [37/60], Loss: 0.0931\n",
      "Epoch [38/60], Loss: 0.0906\n",
      "Epoch [39/60], Loss: 0.0905\n",
      "Epoch [40/60], Loss: 0.0887\n",
      "Epoch [41/60], Loss: 0.0886\n",
      "Epoch [42/60], Loss: 0.0883\n",
      "Epoch [43/60], Loss: 0.0888\n",
      "Epoch [44/60], Loss: 0.0882\n",
      "Epoch [45/60], Loss: 0.0861\n",
      "Epoch [46/60], Loss: 0.0895\n",
      "Epoch [47/60], Loss: 0.0896\n",
      "Epoch [48/60], Loss: 0.0871\n",
      "Epoch [49/60], Loss: 0.0883\n",
      "Epoch [50/60], Loss: 0.0853\n",
      "Epoch [51/60], Loss: 0.0884\n",
      "Epoch [52/60], Loss: 0.0855\n",
      "Epoch [53/60], Loss: 0.0849\n",
      "Epoch [54/60], Loss: 0.0911\n",
      "Epoch [55/60], Loss: 0.0872\n",
      "Epoch [56/60], Loss: 0.0963\n",
      "Epoch [57/60], Loss: 0.0913\n",
      "Epoch [58/60], Loss: 0.0855\n",
      "Epoch [59/60], Loss: 0.0840\n",
      "Epoch [60/60], Loss: 0.0842\n",
      "test performance :  [99.90543365 94.85293579 88.82789612 87.35305786 83.73766327]\n",
      "individual errors:  [array(97.87234, dtype=float32), array(84.23114, dtype=float32), array(78.97545, dtype=float32), array(86.85801, dtype=float32), array(70.75139, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "inderrors = []\n",
    "ss = [50,100,200,400,800,1600,3200]\n",
    "for s in ss:\n",
    "    res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-5,s=s),num_epochs=num_epochs )\n",
    "    results += [res]\n",
    "    inderrors += [inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss = [50,100,200,400,800,1600,3200]\n",
    "for res,s in zip(results,ss):\n",
    "    plt.plot(res,label=str(s),marker='x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0978\n",
      "Epoch [2/50], Loss: 0.0493\n",
      "Epoch [3/50], Loss: 0.0458\n",
      "Epoch [4/50], Loss: 0.0428\n",
      "Epoch [5/50], Loss: 0.0411\n",
      "Epoch [6/50], Loss: 0.0372\n",
      "Epoch [7/50], Loss: 0.0337\n",
      "Epoch [8/50], Loss: 0.0311\n",
      "Epoch [9/50], Loss: 0.0298\n",
      "Epoch [10/50], Loss: 0.0269\n",
      "Epoch [11/50], Loss: 0.0244\n",
      "Epoch [12/50], Loss: 0.0221\n",
      "Epoch [13/50], Loss: 0.0206\n",
      "Epoch [14/50], Loss: 0.0182\n",
      "Epoch [15/50], Loss: 0.0171\n",
      "Epoch [16/50], Loss: 0.0147\n",
      "Epoch [17/50], Loss: 0.0141\n",
      "Epoch [18/50], Loss: 0.0133\n",
      "Epoch [19/50], Loss: 0.0118\n",
      "Epoch [20/50], Loss: 0.0107\n",
      "Epoch [21/50], Loss: 0.0104\n",
      "Epoch [22/50], Loss: 0.0090\n",
      "Epoch [23/50], Loss: 0.0082\n",
      "Epoch [24/50], Loss: 0.0075\n",
      "Epoch [25/50], Loss: 0.0076\n",
      "Epoch [26/50], Loss: 0.0071\n",
      "Epoch [27/50], Loss: 0.0075\n",
      "Epoch [28/50], Loss: 0.0063\n",
      "Epoch [29/50], Loss: 0.0063\n",
      "Epoch [30/50], Loss: 0.0062\n",
      "Epoch [31/50], Loss: 0.0057\n",
      "Epoch [32/50], Loss: 0.0057\n",
      "Epoch [33/50], Loss: 0.0048\n",
      "Epoch [34/50], Loss: 0.0049\n",
      "Epoch [35/50], Loss: 0.0044\n",
      "Epoch [36/50], Loss: 0.0055\n",
      "Epoch [37/50], Loss: 0.0041\n",
      "Epoch [38/50], Loss: 0.0042\n",
      "Epoch [39/50], Loss: 0.0048\n",
      "Epoch [40/50], Loss: 0.0040\n",
      "Epoch [41/50], Loss: 0.0050\n",
      "Epoch [42/50], Loss: 0.0040\n",
      "Epoch [43/50], Loss: 0.0045\n",
      "Epoch [44/50], Loss: 0.0044\n",
      "Epoch [45/50], Loss: 0.0040\n",
      "Epoch [46/50], Loss: 0.0043\n",
      "Epoch [47/50], Loss: 0.0038\n",
      "Epoch [48/50], Loss: 0.0041\n",
      "Epoch [49/50], Loss: 0.0045\n",
      "Epoch [50/50], Loss: 0.0032\n",
      "test performance :  [99.62174988  0.          0.          0.          0.        ]\n",
      "Epoch [1/50], Loss: 0.0993\n",
      "Epoch [2/50], Loss: 0.0722\n",
      "Epoch [3/50], Loss: 0.0671\n",
      "Epoch [4/50], Loss: 0.0628\n",
      "Epoch [5/50], Loss: 0.0581\n",
      "Epoch [6/50], Loss: 0.0534\n",
      "Epoch [7/50], Loss: 0.0510\n",
      "Epoch [8/50], Loss: 0.0473\n",
      "Epoch [9/50], Loss: 0.0438\n",
      "Epoch [10/50], Loss: 0.0409\n",
      "Epoch [11/50], Loss: 0.0390\n",
      "Epoch [12/50], Loss: 0.0372\n",
      "Epoch [13/50], Loss: 0.0349\n",
      "Epoch [14/50], Loss: 0.0331\n",
      "Epoch [15/50], Loss: 0.0337\n",
      "Epoch [16/50], Loss: 0.0316\n",
      "Epoch [17/50], Loss: 0.0300\n",
      "Epoch [18/50], Loss: 0.0291\n",
      "Epoch [19/50], Loss: 0.0276\n",
      "Epoch [20/50], Loss: 0.0267\n",
      "Epoch [21/50], Loss: 0.0257\n",
      "Epoch [22/50], Loss: 0.0264\n",
      "Epoch [23/50], Loss: 0.0256\n",
      "Epoch [24/50], Loss: 0.0263\n",
      "Epoch [25/50], Loss: 0.0242\n",
      "Epoch [26/50], Loss: 0.0228\n",
      "Epoch [27/50], Loss: 0.0236\n",
      "Epoch [28/50], Loss: 0.0227\n",
      "Epoch [29/50], Loss: 0.0233\n",
      "Epoch [30/50], Loss: 0.0215\n",
      "Epoch [31/50], Loss: 0.0226\n",
      "Epoch [32/50], Loss: 0.0211\n",
      "Epoch [33/50], Loss: 0.0212\n",
      "Epoch [34/50], Loss: 0.0211\n",
      "Epoch [35/50], Loss: 0.0203\n",
      "Epoch [36/50], Loss: 0.0211\n",
      "Epoch [37/50], Loss: 0.0206\n",
      "Epoch [38/50], Loss: 0.0193\n",
      "Epoch [39/50], Loss: 0.0189\n",
      "Epoch [40/50], Loss: 0.0199\n",
      "Epoch [41/50], Loss: 0.0193\n",
      "Epoch [42/50], Loss: 0.0190\n",
      "Epoch [43/50], Loss: 0.0178\n",
      "Epoch [44/50], Loss: 0.0178\n",
      "Epoch [45/50], Loss: 0.0209\n",
      "Epoch [46/50], Loss: 0.0185\n",
      "Epoch [47/50], Loss: 0.0183\n",
      "Epoch [48/50], Loss: 0.0193\n",
      "Epoch [49/50], Loss: 0.0192\n",
      "Epoch [50/50], Loss: 0.0191\n",
      "test performance :  [99.62174988 93.86576843  0.          0.          0.        ]\n",
      "Epoch [1/50], Loss: 0.1010\n",
      "Epoch [2/50], Loss: 0.0794\n",
      "Epoch [3/50], Loss: 0.0746\n",
      "Epoch [4/50], Loss: 0.0687\n",
      "Epoch [5/50], Loss: 0.0640\n",
      "Epoch [6/50], Loss: 0.0586\n",
      "Epoch [7/50], Loss: 0.0572\n",
      "Epoch [8/50], Loss: 0.0532\n",
      "Epoch [9/50], Loss: 0.0509\n",
      "Epoch [10/50], Loss: 0.0468\n",
      "Epoch [11/50], Loss: 0.0466\n",
      "Epoch [12/50], Loss: 0.0466\n",
      "Epoch [13/50], Loss: 0.0446\n",
      "Epoch [14/50], Loss: 0.0433\n",
      "Epoch [15/50], Loss: 0.0414\n",
      "Epoch [16/50], Loss: 0.0391\n",
      "Epoch [17/50], Loss: 0.0398\n",
      "Epoch [18/50], Loss: 0.0414\n",
      "Epoch [19/50], Loss: 0.0368\n",
      "Epoch [20/50], Loss: 0.0402\n",
      "Epoch [21/50], Loss: 0.0349\n",
      "Epoch [22/50], Loss: 0.0376\n",
      "Epoch [23/50], Loss: 0.0365\n",
      "Epoch [24/50], Loss: 0.0354\n",
      "Epoch [25/50], Loss: 0.0355\n",
      "Epoch [26/50], Loss: 0.0325\n",
      "Epoch [27/50], Loss: 0.0347\n",
      "Epoch [28/50], Loss: 0.0358\n",
      "Epoch [29/50], Loss: 0.0338\n",
      "Epoch [30/50], Loss: 0.0320\n",
      "Epoch [31/50], Loss: 0.0335\n",
      "Epoch [32/50], Loss: 0.0323\n",
      "Epoch [33/50], Loss: 0.0320\n",
      "Epoch [34/50], Loss: 0.0319\n",
      "Epoch [35/50], Loss: 0.0319\n",
      "Epoch [36/50], Loss: 0.0315\n",
      "Epoch [37/50], Loss: 0.0318\n",
      "Epoch [38/50], Loss: 0.0319\n",
      "Epoch [39/50], Loss: 0.0300\n",
      "Epoch [40/50], Loss: 0.0312\n",
      "Epoch [41/50], Loss: 0.0309\n",
      "Epoch [42/50], Loss: 0.0280\n",
      "Epoch [43/50], Loss: 0.0308\n",
      "Epoch [44/50], Loss: 0.0322\n",
      "Epoch [45/50], Loss: 0.0300\n",
      "Epoch [46/50], Loss: 0.0304\n",
      "Epoch [47/50], Loss: 0.0288\n",
      "Epoch [48/50], Loss: 0.0303\n",
      "Epoch [49/50], Loss: 0.0309\n",
      "Epoch [50/50], Loss: 0.0260\n",
      "test performance :  [99.62174988 93.86576843 89.55397034  0.          0.        ]\n",
      "Epoch [1/50], Loss: 0.1004\n",
      "Epoch [2/50], Loss: 0.0828\n",
      "Epoch [3/50], Loss: 0.0777\n",
      "Epoch [4/50], Loss: 0.0710\n",
      "Epoch [5/50], Loss: 0.0658\n",
      "Epoch [6/50], Loss: 0.0619\n",
      "Epoch [7/50], Loss: 0.0596\n",
      "Epoch [8/50], Loss: 0.0567\n",
      "Epoch [9/50], Loss: 0.0563\n",
      "Epoch [10/50], Loss: 0.0508\n",
      "Epoch [11/50], Loss: 0.0507\n",
      "Epoch [12/50], Loss: 0.0491\n",
      "Epoch [13/50], Loss: 0.0455\n",
      "Epoch [14/50], Loss: 0.0453\n",
      "Epoch [15/50], Loss: 0.0460\n",
      "Epoch [16/50], Loss: 0.0457\n",
      "Epoch [17/50], Loss: 0.0432\n",
      "Epoch [18/50], Loss: 0.0434\n",
      "Epoch [19/50], Loss: 0.0415\n",
      "Epoch [20/50], Loss: 0.0414\n",
      "Epoch [21/50], Loss: 0.0402\n",
      "Epoch [22/50], Loss: 0.0410\n",
      "Epoch [23/50], Loss: 0.0405\n",
      "Epoch [24/50], Loss: 0.0390\n",
      "Epoch [25/50], Loss: 0.0407\n",
      "Epoch [26/50], Loss: 0.0395\n",
      "Epoch [27/50], Loss: 0.0381\n",
      "Epoch [28/50], Loss: 0.0389\n",
      "Epoch [29/50], Loss: 0.0411\n",
      "Epoch [30/50], Loss: 0.0372\n",
      "Epoch [31/50], Loss: 0.0373\n",
      "Epoch [32/50], Loss: 0.0391\n",
      "Epoch [33/50], Loss: 0.0380\n",
      "Epoch [34/50], Loss: 0.0366\n",
      "Epoch [35/50], Loss: 0.0385\n",
      "Epoch [36/50], Loss: 0.0374\n",
      "Epoch [37/50], Loss: 0.0366\n",
      "Epoch [38/50], Loss: 0.0375\n",
      "Epoch [39/50], Loss: 0.0376\n",
      "Epoch [40/50], Loss: 0.0356\n",
      "Epoch [41/50], Loss: 0.0390\n",
      "Epoch [42/50], Loss: 0.0373\n",
      "Epoch [43/50], Loss: 0.0350\n",
      "Epoch [44/50], Loss: 0.0346\n",
      "Epoch [45/50], Loss: 0.0348\n",
      "Epoch [46/50], Loss: 0.0373\n",
      "Epoch [47/50], Loss: 0.0341\n",
      "Epoch [48/50], Loss: 0.0336\n",
      "Epoch [49/50], Loss: 0.0357\n",
      "Epoch [50/50], Loss: 0.0367\n",
      "test performance :  [99.62174988 93.86576843 89.55397034 89.57215881  0.        ]\n",
      "Epoch [1/50], Loss: 0.0987\n",
      "Epoch [2/50], Loss: 0.0859\n",
      "Epoch [3/50], Loss: 0.0791\n",
      "Epoch [4/50], Loss: 0.0741\n",
      "Epoch [5/50], Loss: 0.0702\n",
      "Epoch [6/50], Loss: 0.0653\n",
      "Epoch [7/50], Loss: 0.0629\n",
      "Epoch [8/50], Loss: 0.0617\n",
      "Epoch [9/50], Loss: 0.0585\n",
      "Epoch [10/50], Loss: 0.0564\n",
      "Epoch [11/50], Loss: 0.0552\n",
      "Epoch [12/50], Loss: 0.0538\n",
      "Epoch [13/50], Loss: 0.0527\n",
      "Epoch [14/50], Loss: 0.0544\n",
      "Epoch [15/50], Loss: 0.0505\n",
      "Epoch [16/50], Loss: 0.0516\n",
      "Epoch [17/50], Loss: 0.0523\n",
      "Epoch [18/50], Loss: 0.0500\n",
      "Epoch [19/50], Loss: 0.0504\n",
      "Epoch [20/50], Loss: 0.0495\n",
      "Epoch [21/50], Loss: 0.0478\n",
      "Epoch [22/50], Loss: 0.0467\n",
      "Epoch [23/50], Loss: 0.0489\n",
      "Epoch [24/50], Loss: 0.0472\n",
      "Epoch [25/50], Loss: 0.0466\n",
      "Epoch [26/50], Loss: 0.0487\n",
      "Epoch [27/50], Loss: 0.0497\n",
      "Epoch [28/50], Loss: 0.0477\n",
      "Epoch [29/50], Loss: 0.0456\n",
      "Epoch [30/50], Loss: 0.0458\n",
      "Epoch [31/50], Loss: 0.0484\n",
      "Epoch [32/50], Loss: 0.0484\n",
      "Epoch [33/50], Loss: 0.0453\n",
      "Epoch [34/50], Loss: 0.0449\n",
      "Epoch [35/50], Loss: 0.0437\n",
      "Epoch [36/50], Loss: 0.0453\n",
      "Epoch [37/50], Loss: 0.0442\n",
      "Epoch [38/50], Loss: 0.0483\n",
      "Epoch [39/50], Loss: 0.0456\n",
      "Epoch [40/50], Loss: 0.0450\n",
      "Epoch [41/50], Loss: 0.0458\n",
      "Epoch [42/50], Loss: 0.0442\n",
      "Epoch [43/50], Loss: 0.0461\n",
      "Epoch [44/50], Loss: 0.0420\n",
      "Epoch [45/50], Loss: 0.0433\n",
      "Epoch [46/50], Loss: 0.0441\n",
      "Epoch [47/50], Loss: 0.0428\n",
      "Epoch [48/50], Loss: 0.0441\n",
      "Epoch [49/50], Loss: 0.0439\n",
      "Epoch [50/50], Loss: 0.0426\n",
      "test performance :  [99.62174988 93.86576843 89.55397034 89.57215881 85.31999969]\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2 # size of step\n",
    "resall = train_on_all( get_random_feature_model(),train_loaders_all,test_loaders_all,num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC 0.01\n",
      "Epoch [1/50], Loss: 0.0967\n",
      "Epoch [2/50], Loss: 0.0494\n",
      "Epoch [3/50], Loss: 0.0461\n",
      "Epoch [4/50], Loss: 0.0428\n",
      "Epoch [5/50], Loss: 0.0393\n",
      "Epoch [6/50], Loss: 0.0377\n",
      "Epoch [7/50], Loss: 0.0339\n",
      "Epoch [8/50], Loss: 0.0314\n",
      "Epoch [9/50], Loss: 0.0288\n",
      "Epoch [10/50], Loss: 0.0264\n",
      "Epoch [11/50], Loss: 0.0234\n",
      "Epoch [12/50], Loss: 0.0221\n",
      "Epoch [13/50], Loss: 0.0207\n",
      "Epoch [14/50], Loss: 0.0179\n",
      "Epoch [15/50], Loss: 0.0163\n",
      "Epoch [16/50], Loss: 0.0154\n",
      "Epoch [17/50], Loss: 0.0138\n",
      "Epoch [18/50], Loss: 0.0127\n",
      "Epoch [19/50], Loss: 0.0121\n",
      "Epoch [20/50], Loss: 0.0103\n",
      "Epoch [21/50], Loss: 0.0098\n",
      "Epoch [22/50], Loss: 0.0089\n",
      "Epoch [23/50], Loss: 0.0086\n",
      "Epoch [24/50], Loss: 0.0080\n",
      "Epoch [25/50], Loss: 0.0071\n",
      "Epoch [26/50], Loss: 0.0069\n",
      "Epoch [27/50], Loss: 0.0062\n",
      "Epoch [28/50], Loss: 0.0063\n",
      "Epoch [29/50], Loss: 0.0056\n",
      "Epoch [30/50], Loss: 0.0052\n",
      "Epoch [31/50], Loss: 0.0056\n",
      "Epoch [32/50], Loss: 0.0051\n",
      "Epoch [33/50], Loss: 0.0048\n",
      "Epoch [34/50], Loss: 0.0049\n",
      "Epoch [35/50], Loss: 0.0040\n",
      "Epoch [36/50], Loss: 0.0044\n",
      "Epoch [37/50], Loss: 0.0043\n",
      "Epoch [38/50], Loss: 0.0041\n",
      "Epoch [39/50], Loss: 0.0034\n",
      "Epoch [40/50], Loss: 0.0043\n",
      "Epoch [41/50], Loss: 0.0040\n",
      "Epoch [42/50], Loss: 0.0044\n",
      "Epoch [43/50], Loss: 0.0040\n",
      "Epoch [44/50], Loss: 0.0042\n",
      "Epoch [45/50], Loss: 0.0041\n",
      "Epoch [46/50], Loss: 0.0044\n",
      "Epoch [47/50], Loss: 0.0044\n",
      "Epoch [48/50], Loss: 0.0035\n",
      "Epoch [49/50], Loss: 0.0035\n",
      "Epoch [50/50], Loss: 0.0040\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(40060.2812, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.66902924  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.66903, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1550\n",
      "Epoch [2/50], Loss: 0.1028\n",
      "Epoch [3/50], Loss: 0.1021\n",
      "Epoch [4/50], Loss: 0.1005\n",
      "Epoch [5/50], Loss: 0.1000\n",
      "Epoch [6/50], Loss: 0.0998\n",
      "Epoch [7/50], Loss: 0.0995\n",
      "Epoch [8/50], Loss: 0.1002\n",
      "Epoch [9/50], Loss: 0.1002\n",
      "Epoch [10/50], Loss: 0.1003\n",
      "Epoch [11/50], Loss: 0.0999\n",
      "Epoch [12/50], Loss: 0.0997\n",
      "Epoch [13/50], Loss: 0.1007\n",
      "Epoch [14/50], Loss: 0.1008\n",
      "Epoch [15/50], Loss: 0.0998\n",
      "Epoch [16/50], Loss: 0.1005\n",
      "Epoch [17/50], Loss: 0.1005\n",
      "Epoch [18/50], Loss: 0.0998\n",
      "Epoch [19/50], Loss: 0.0998\n",
      "Epoch [20/50], Loss: 0.1002\n",
      "Epoch [21/50], Loss: 0.1001\n",
      "Epoch [22/50], Loss: 0.0998\n",
      "Epoch [23/50], Loss: 0.0993\n",
      "Epoch [24/50], Loss: 0.1002\n",
      "Epoch [25/50], Loss: 0.1014\n",
      "Epoch [26/50], Loss: 0.0998\n",
      "Epoch [27/50], Loss: 0.1000\n",
      "Epoch [28/50], Loss: 0.1003\n",
      "Epoch [29/50], Loss: 0.0999\n",
      "Epoch [30/50], Loss: 0.1010\n",
      "Epoch [31/50], Loss: 0.1002\n",
      "Epoch [32/50], Loss: 0.1014\n",
      "Epoch [33/50], Loss: 0.1001\n",
      "Epoch [34/50], Loss: 0.1001\n",
      "Epoch [35/50], Loss: 0.1001\n",
      "Epoch [36/50], Loss: 0.1000\n",
      "Epoch [37/50], Loss: 0.0996\n",
      "Epoch [38/50], Loss: 0.1002\n",
      "Epoch [39/50], Loss: 0.0998\n",
      "Epoch [40/50], Loss: 0.1004\n",
      "Epoch [41/50], Loss: 0.0996\n",
      "Epoch [42/50], Loss: 0.0999\n",
      "Epoch [43/50], Loss: 0.0999\n",
      "Epoch [44/50], Loss: 0.0995\n",
      "Epoch [45/50], Loss: 0.0998\n",
      "Epoch [46/50], Loss: 0.1007\n",
      "Epoch [47/50], Loss: 0.0996\n",
      "Epoch [48/50], Loss: 0.1000\n",
      "Epoch [49/50], Loss: 0.1004\n",
      "Epoch [50/50], Loss: 0.0999\n",
      "update data..\n",
      "task data norm and number entries: tensor(38238.3711, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.66902924 57.33055115  0.          0.          0.        ]\n",
      "individual errors:  [array(99.479904, dtype=float32), array(15.181194, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1295\n",
      "Epoch [2/50], Loss: 0.1223\n",
      "Epoch [3/50], Loss: 0.1033\n",
      "Epoch [4/50], Loss: 0.1008\n",
      "Epoch [5/50], Loss: 0.1012\n",
      "Epoch [6/50], Loss: 0.1005\n",
      "Epoch [7/50], Loss: 0.1005\n",
      "Epoch [8/50], Loss: 0.1008\n",
      "Epoch [9/50], Loss: 0.1011\n",
      "Epoch [10/50], Loss: 0.1009\n",
      "Epoch [11/50], Loss: 0.1008\n",
      "Epoch [12/50], Loss: 0.1014\n",
      "Epoch [13/50], Loss: 0.1013\n",
      "Epoch [14/50], Loss: 0.1008\n",
      "Epoch [15/50], Loss: 0.1013\n",
      "Epoch [16/50], Loss: 0.1007\n",
      "Epoch [17/50], Loss: 0.1034\n",
      "Epoch [18/50], Loss: 0.1033\n",
      "Epoch [19/50], Loss: 0.1023\n",
      "Epoch [20/50], Loss: 0.1005\n",
      "Epoch [21/50], Loss: 0.1017\n",
      "Epoch [22/50], Loss: 0.1013\n",
      "Epoch [23/50], Loss: 0.1011\n",
      "Epoch [24/50], Loss: 0.1015\n",
      "Epoch [25/50], Loss: 0.1007\n",
      "Epoch [26/50], Loss: 0.1012\n",
      "Epoch [27/50], Loss: 0.1009\n",
      "Epoch [28/50], Loss: 0.1014\n",
      "Epoch [29/50], Loss: 0.1011\n",
      "Epoch [30/50], Loss: 0.1011\n",
      "Epoch [31/50], Loss: 0.1011\n",
      "Epoch [32/50], Loss: 0.1003\n",
      "Epoch [33/50], Loss: 0.1015\n",
      "Epoch [34/50], Loss: 0.1012\n",
      "Epoch [35/50], Loss: 0.1010\n",
      "Epoch [36/50], Loss: 0.1012\n",
      "Epoch [37/50], Loss: 0.1015\n",
      "Epoch [38/50], Loss: 0.1004\n",
      "Epoch [39/50], Loss: 0.1012\n",
      "Epoch [40/50], Loss: 0.1012\n",
      "Epoch [41/50], Loss: 0.1010\n",
      "Epoch [42/50], Loss: 0.1006\n",
      "Epoch [43/50], Loss: 0.1010\n",
      "Epoch [44/50], Loss: 0.1014\n",
      "Epoch [45/50], Loss: 0.1017\n",
      "Epoch [46/50], Loss: 0.1007\n",
      "Epoch [47/50], Loss: 0.1016\n",
      "Epoch [48/50], Loss: 0.1012\n",
      "Epoch [49/50], Loss: 0.1009\n",
      "Epoch [50/50], Loss: 0.1014\n",
      "update data..\n",
      "task data norm and number entries: tensor(35625.6562, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.66902924 57.33055115 39.31639099  0.          0.        ]\n",
      "individual errors:  [array(99.432625, dtype=float32), array(0., dtype=float32), array(18.516542, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1224\n",
      "Epoch [2/50], Loss: 0.1088\n",
      "Epoch [3/50], Loss: 0.1040\n",
      "Epoch [4/50], Loss: 0.1024\n",
      "Epoch [5/50], Loss: 0.1021\n",
      "Epoch [6/50], Loss: 0.1019\n",
      "Epoch [7/50], Loss: 0.1025\n",
      "Epoch [8/50], Loss: 0.1022\n",
      "Epoch [9/50], Loss: 0.1022\n",
      "Epoch [10/50], Loss: 0.1022\n",
      "Epoch [11/50], Loss: 0.1027\n",
      "Epoch [12/50], Loss: 0.1026\n",
      "Epoch [13/50], Loss: 0.1014\n",
      "Epoch [14/50], Loss: 0.1024\n",
      "Epoch [15/50], Loss: 0.1025\n",
      "Epoch [16/50], Loss: 0.1023\n",
      "Epoch [17/50], Loss: 0.1019\n",
      "Epoch [18/50], Loss: 0.1029\n",
      "Epoch [19/50], Loss: 0.1026\n",
      "Epoch [20/50], Loss: 0.1025\n",
      "Epoch [21/50], Loss: 0.1027\n",
      "Epoch [22/50], Loss: 0.1022\n",
      "Epoch [23/50], Loss: 0.1021\n",
      "Epoch [24/50], Loss: 0.1025\n",
      "Epoch [25/50], Loss: 0.1029\n",
      "Epoch [26/50], Loss: 0.1024\n",
      "Epoch [27/50], Loss: 0.1026\n",
      "Epoch [28/50], Loss: 0.1027\n",
      "Epoch [29/50], Loss: 0.1020\n",
      "Epoch [30/50], Loss: 0.1018\n",
      "Epoch [31/50], Loss: 0.1030\n",
      "Epoch [32/50], Loss: 0.1023\n",
      "Epoch [33/50], Loss: 0.1026\n",
      "Epoch [34/50], Loss: 0.1019\n",
      "Epoch [35/50], Loss: 0.1025\n",
      "Epoch [36/50], Loss: 0.1025\n",
      "Epoch [37/50], Loss: 0.1017\n",
      "Epoch [38/50], Loss: 0.1019\n",
      "Epoch [39/50], Loss: 0.1019\n",
      "Epoch [40/50], Loss: 0.1037\n",
      "Epoch [41/50], Loss: 0.1028\n",
      "Epoch [42/50], Loss: 0.1019\n",
      "Epoch [43/50], Loss: 0.1027\n",
      "Epoch [44/50], Loss: 0.1020\n",
      "Epoch [45/50], Loss: 0.1021\n",
      "Epoch [46/50], Loss: 0.1023\n",
      "Epoch [47/50], Loss: 0.1028\n",
      "Epoch [48/50], Loss: 0.1026\n",
      "Epoch [49/50], Loss: 0.1026\n",
      "Epoch [50/50], Loss: 0.1037\n",
      "update data..\n",
      "task data norm and number entries: tensor(38535.6602, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.66902924 57.33055115 39.31639099 28.17988205  0.        ]\n",
      "individual errors:  [array(99.52718, dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(13.192347, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1183\n",
      "Epoch [2/50], Loss: 0.1092\n",
      "Epoch [3/50], Loss: 0.1057\n",
      "Epoch [4/50], Loss: 0.1035\n",
      "Epoch [5/50], Loss: 0.1041\n",
      "Epoch [6/50], Loss: 0.1030\n",
      "Epoch [7/50], Loss: 0.1029\n",
      "Epoch [8/50], Loss: 0.1025\n",
      "Epoch [9/50], Loss: 0.1046\n",
      "Epoch [10/50], Loss: 0.1035\n",
      "Epoch [11/50], Loss: 0.1032\n",
      "Epoch [12/50], Loss: 0.1032\n",
      "Epoch [13/50], Loss: 0.1034\n",
      "Epoch [14/50], Loss: 0.1036\n",
      "Epoch [15/50], Loss: 0.1033\n",
      "Epoch [16/50], Loss: 0.1037\n",
      "Epoch [17/50], Loss: 0.1072\n",
      "Epoch [18/50], Loss: 0.1027\n",
      "Epoch [19/50], Loss: 0.1032\n",
      "Epoch [20/50], Loss: 0.1042\n",
      "Epoch [21/50], Loss: 0.1043\n",
      "Epoch [22/50], Loss: 0.1038\n",
      "Epoch [23/50], Loss: 0.1036\n",
      "Epoch [24/50], Loss: 0.1032\n",
      "Epoch [25/50], Loss: 0.1078\n",
      "Epoch [26/50], Loss: 0.1031\n",
      "Epoch [27/50], Loss: 0.1028\n",
      "Epoch [28/50], Loss: 0.1046\n",
      "Epoch [29/50], Loss: 0.1050\n",
      "Epoch [30/50], Loss: 0.1028\n",
      "Epoch [31/50], Loss: 0.1030\n",
      "Epoch [32/50], Loss: 0.1055\n",
      "Epoch [33/50], Loss: 0.1031\n",
      "Epoch [34/50], Loss: 0.1034\n",
      "Epoch [35/50], Loss: 0.1040\n",
      "Epoch [36/50], Loss: 0.1033\n",
      "Epoch [37/50], Loss: 0.1032\n",
      "Epoch [38/50], Loss: 0.1039\n",
      "Epoch [39/50], Loss: 0.1044\n",
      "Epoch [40/50], Loss: 0.1035\n",
      "Epoch [41/50], Loss: 0.1030\n",
      "Epoch [42/50], Loss: 0.1032\n",
      "Epoch [43/50], Loss: 0.1032\n",
      "Epoch [44/50], Loss: 0.1045\n",
      "Epoch [45/50], Loss: 0.1028\n",
      "Epoch [46/50], Loss: 0.1049\n",
      "Epoch [47/50], Loss: 0.1031\n",
      "Epoch [48/50], Loss: 0.1054\n",
      "Epoch [49/50], Loss: 0.1032\n",
      "Epoch [50/50], Loss: 0.1026\n",
      "test performance :  [99.66902924 57.33055115 39.31639099 28.17988205 22.83155823]\n",
      "individual errors:  [array(99.432625, dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(14.725163, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "resewc,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWC(lam=0.01),num_epochs=num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC 0.001\n",
      "Epoch [1/50], Loss: 0.0967\n",
      "Epoch [2/50], Loss: 0.0504\n",
      "Epoch [3/50], Loss: 0.0469\n",
      "Epoch [4/50], Loss: 0.0430\n",
      "Epoch [5/50], Loss: 0.0398\n",
      "Epoch [6/50], Loss: 0.0375\n",
      "Epoch [7/50], Loss: 0.0339\n",
      "Epoch [8/50], Loss: 0.0314\n",
      "Epoch [9/50], Loss: 0.0283\n",
      "Epoch [10/50], Loss: 0.0266\n",
      "Epoch [11/50], Loss: 0.0237\n",
      "Epoch [12/50], Loss: 0.0216\n",
      "Epoch [13/50], Loss: 0.0203\n",
      "Epoch [14/50], Loss: 0.0179\n",
      "Epoch [15/50], Loss: 0.0160\n",
      "Epoch [16/50], Loss: 0.0146\n",
      "Epoch [17/50], Loss: 0.0136\n",
      "Epoch [18/50], Loss: 0.0122\n",
      "Epoch [19/50], Loss: 0.0117\n",
      "Epoch [20/50], Loss: 0.0109\n",
      "Epoch [21/50], Loss: 0.0100\n",
      "Epoch [22/50], Loss: 0.0086\n",
      "Epoch [23/50], Loss: 0.0082\n",
      "Epoch [24/50], Loss: 0.0074\n",
      "Epoch [25/50], Loss: 0.0073\n",
      "Epoch [26/50], Loss: 0.0067\n",
      "Epoch [27/50], Loss: 0.0067\n",
      "Epoch [28/50], Loss: 0.0067\n",
      "Epoch [29/50], Loss: 0.0057\n",
      "Epoch [30/50], Loss: 0.0057\n",
      "Epoch [31/50], Loss: 0.0058\n",
      "Epoch [32/50], Loss: 0.0049\n",
      "Epoch [33/50], Loss: 0.0047\n",
      "Epoch [34/50], Loss: 0.0055\n",
      "Epoch [35/50], Loss: 0.0046\n",
      "Epoch [36/50], Loss: 0.0046\n",
      "Epoch [37/50], Loss: 0.0049\n",
      "Epoch [38/50], Loss: 0.0042\n",
      "Epoch [39/50], Loss: 0.0045\n",
      "Epoch [40/50], Loss: 0.0044\n",
      "Epoch [41/50], Loss: 0.0046\n",
      "Epoch [42/50], Loss: 0.0042\n",
      "Epoch [43/50], Loss: 0.0041\n",
      "Epoch [44/50], Loss: 0.0038\n",
      "Epoch [45/50], Loss: 0.0042\n",
      "Epoch [46/50], Loss: 0.0043\n",
      "Epoch [47/50], Loss: 0.0038\n",
      "Epoch [48/50], Loss: 0.0035\n",
      "Epoch [49/50], Loss: 0.0041\n",
      "Epoch [50/50], Loss: 0.0040\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(40059.6406, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.71630859  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.71631, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1544\n",
      "Epoch [2/50], Loss: 0.0662\n",
      "Epoch [3/50], Loss: 0.0633\n",
      "Epoch [4/50], Loss: 0.0626\n",
      "Epoch [5/50], Loss: 0.0620\n",
      "Epoch [6/50], Loss: 0.0619\n",
      "Epoch [7/50], Loss: 0.0631\n",
      "Epoch [8/50], Loss: 0.0624\n",
      "Epoch [9/50], Loss: 0.0626\n",
      "Epoch [10/50], Loss: 0.0624\n",
      "Epoch [11/50], Loss: 0.0624\n",
      "Epoch [12/50], Loss: 0.0624\n",
      "Epoch [13/50], Loss: 0.0625\n",
      "Epoch [14/50], Loss: 0.0617\n",
      "Epoch [15/50], Loss: 0.0619\n",
      "Epoch [16/50], Loss: 0.0628\n",
      "Epoch [17/50], Loss: 0.0612\n",
      "Epoch [18/50], Loss: 0.0637\n",
      "Epoch [19/50], Loss: 0.0613\n",
      "Epoch [20/50], Loss: 0.0611\n",
      "Epoch [21/50], Loss: 0.0618\n",
      "Epoch [22/50], Loss: 0.0614\n",
      "Epoch [23/50], Loss: 0.0631\n",
      "Epoch [24/50], Loss: 0.0612\n",
      "Epoch [25/50], Loss: 0.0613\n",
      "Epoch [26/50], Loss: 0.0612\n",
      "Epoch [27/50], Loss: 0.0616\n",
      "Epoch [28/50], Loss: 0.0619\n",
      "Epoch [29/50], Loss: 0.0617\n",
      "Epoch [30/50], Loss: 0.0616\n",
      "Epoch [31/50], Loss: 0.0614\n",
      "Epoch [32/50], Loss: 0.0620\n",
      "Epoch [33/50], Loss: 0.0622\n",
      "Epoch [34/50], Loss: 0.0612\n",
      "Epoch [35/50], Loss: 0.0610\n",
      "Epoch [36/50], Loss: 0.0606\n",
      "Epoch [37/50], Loss: 0.0610\n",
      "Epoch [38/50], Loss: 0.0615\n",
      "Epoch [39/50], Loss: 0.0632\n",
      "Epoch [40/50], Loss: 0.0627\n",
      "Epoch [41/50], Loss: 0.0608\n",
      "Epoch [42/50], Loss: 0.0625\n",
      "Epoch [43/50], Loss: 0.0600\n",
      "Epoch [44/50], Loss: 0.0611\n",
      "Epoch [45/50], Loss: 0.0614\n",
      "Epoch [46/50], Loss: 0.0609\n",
      "Epoch [47/50], Loss: 0.0612\n",
      "Epoch [48/50], Loss: 0.0610\n",
      "Epoch [49/50], Loss: 0.0617\n",
      "Epoch [50/50], Loss: 0.0613\n",
      "update data..\n",
      "task data norm and number entries: tensor(38237.7578, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.71630859 69.20845795  0.          0.          0.        ]\n",
      "individual errors:  [array(63.735226, dtype=float32), array(74.68169, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1478\n",
      "Epoch [2/50], Loss: 0.0723\n",
      "Epoch [3/50], Loss: 0.0682\n",
      "Epoch [4/50], Loss: 0.0673\n",
      "Epoch [5/50], Loss: 0.0670\n",
      "Epoch [6/50], Loss: 0.0672\n",
      "Epoch [7/50], Loss: 0.0672\n",
      "Epoch [8/50], Loss: 0.0669\n",
      "Epoch [9/50], Loss: 0.0670\n",
      "Epoch [10/50], Loss: 0.0665\n",
      "Epoch [11/50], Loss: 0.0666\n",
      "Epoch [12/50], Loss: 0.0671\n",
      "Epoch [13/50], Loss: 0.0668\n",
      "Epoch [14/50], Loss: 0.0666\n",
      "Epoch [15/50], Loss: 0.0667\n",
      "Epoch [16/50], Loss: 0.0669\n",
      "Epoch [17/50], Loss: 0.0664\n",
      "Epoch [18/50], Loss: 0.0671\n",
      "Epoch [19/50], Loss: 0.0683\n",
      "Epoch [20/50], Loss: 0.0666\n",
      "Epoch [21/50], Loss: 0.0667\n",
      "Epoch [22/50], Loss: 0.0668\n",
      "Epoch [23/50], Loss: 0.0675\n",
      "Epoch [24/50], Loss: 0.0672\n",
      "Epoch [25/50], Loss: 0.0672\n",
      "Epoch [26/50], Loss: 0.0670\n",
      "Epoch [27/50], Loss: 0.0673\n",
      "Epoch [28/50], Loss: 0.0677\n",
      "Epoch [29/50], Loss: 0.0673\n",
      "Epoch [30/50], Loss: 0.0668\n",
      "Epoch [31/50], Loss: 0.0672\n",
      "Epoch [32/50], Loss: 0.0676\n",
      "Epoch [33/50], Loss: 0.0665\n",
      "Epoch [34/50], Loss: 0.0676\n",
      "Epoch [35/50], Loss: 0.0675\n",
      "Epoch [36/50], Loss: 0.0665\n",
      "Epoch [37/50], Loss: 0.0664\n",
      "Epoch [38/50], Loss: 0.0667\n",
      "Epoch [39/50], Loss: 0.0674\n",
      "Epoch [40/50], Loss: 0.0666\n",
      "Epoch [41/50], Loss: 0.0701\n",
      "Epoch [42/50], Loss: 0.0667\n",
      "Epoch [43/50], Loss: 0.0665\n",
      "Epoch [44/50], Loss: 0.0665\n",
      "Epoch [45/50], Loss: 0.0670\n",
      "Epoch [46/50], Loss: 0.0666\n",
      "Epoch [47/50], Loss: 0.0669\n",
      "Epoch [48/50], Loss: 0.0670\n",
      "Epoch [49/50], Loss: 0.0669\n",
      "Epoch [50/50], Loss: 0.0662\n",
      "update data..\n",
      "task data norm and number entries: tensor(35625.1094, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.71630859 69.20845795 35.35316849  0.          0.        ]\n",
      "individual errors:  [array(53.711582, dtype=float32), array(0., dtype=float32), array(52.34792, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1441\n",
      "Epoch [2/50], Loss: 0.0760\n",
      "Epoch [3/50], Loss: 0.0724\n",
      "Epoch [4/50], Loss: 0.0723\n",
      "Epoch [5/50], Loss: 0.0726\n",
      "Epoch [6/50], Loss: 0.0718\n",
      "Epoch [7/50], Loss: 0.0725\n",
      "Epoch [8/50], Loss: 0.0716\n",
      "Epoch [9/50], Loss: 0.0723\n",
      "Epoch [10/50], Loss: 0.0719\n",
      "Epoch [11/50], Loss: 0.0724\n",
      "Epoch [12/50], Loss: 0.0724\n",
      "Epoch [13/50], Loss: 0.0713\n",
      "Epoch [14/50], Loss: 0.0714\n",
      "Epoch [15/50], Loss: 0.0722\n",
      "Epoch [16/50], Loss: 0.0712\n",
      "Epoch [17/50], Loss: 0.0717\n",
      "Epoch [18/50], Loss: 0.0720\n",
      "Epoch [19/50], Loss: 0.0713\n",
      "Epoch [20/50], Loss: 0.0713\n",
      "Epoch [21/50], Loss: 0.0726\n",
      "Epoch [22/50], Loss: 0.0714\n",
      "Epoch [23/50], Loss: 0.0718\n",
      "Epoch [24/50], Loss: 0.0717\n",
      "Epoch [25/50], Loss: 0.0718\n",
      "Epoch [26/50], Loss: 0.0722\n",
      "Epoch [27/50], Loss: 0.0715\n",
      "Epoch [28/50], Loss: 0.0718\n",
      "Epoch [29/50], Loss: 0.0730\n",
      "Epoch [30/50], Loss: 0.0715\n",
      "Epoch [31/50], Loss: 0.0717\n",
      "Epoch [32/50], Loss: 0.0715\n",
      "Epoch [33/50], Loss: 0.0712\n",
      "Epoch [34/50], Loss: 0.0716\n",
      "Epoch [35/50], Loss: 0.0720\n",
      "Epoch [36/50], Loss: 0.0717\n",
      "Epoch [37/50], Loss: 0.0713\n",
      "Epoch [38/50], Loss: 0.0716\n",
      "Epoch [39/50], Loss: 0.0717\n",
      "Epoch [40/50], Loss: 0.0719\n",
      "Epoch [41/50], Loss: 0.0728\n",
      "Epoch [42/50], Loss: 0.0716\n",
      "Epoch [43/50], Loss: 0.0711\n",
      "Epoch [44/50], Loss: 0.0714\n",
      "Epoch [45/50], Loss: 0.0722\n",
      "Epoch [46/50], Loss: 0.0713\n",
      "Epoch [47/50], Loss: 0.0718\n",
      "Epoch [48/50], Loss: 0.0721\n",
      "Epoch [49/50], Loss: 0.0727\n",
      "Epoch [50/50], Loss: 0.0715\n",
      "update data..\n",
      "task data norm and number entries: tensor(38535.0898, device='cuda:0') torch.Size([31370])\n",
      "..done\n",
      "test performance :  [99.71630859 69.20845795 35.35316849 22.62295151  0.        ]\n",
      "individual errors:  [array(42.50591, dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(47.9859, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1398\n",
      "Epoch [2/50], Loss: 0.0777\n",
      "Epoch [3/50], Loss: 0.0755\n",
      "Epoch [4/50], Loss: 0.0750\n",
      "Epoch [5/50], Loss: 0.0749\n",
      "Epoch [6/50], Loss: 0.0757\n",
      "Epoch [7/50], Loss: 0.0744\n",
      "Epoch [8/50], Loss: 0.0756\n",
      "Epoch [9/50], Loss: 0.0748\n",
      "Epoch [10/50], Loss: 0.0755\n",
      "Epoch [11/50], Loss: 0.0749\n",
      "Epoch [12/50], Loss: 0.0804\n",
      "Epoch [13/50], Loss: 0.0764\n",
      "Epoch [14/50], Loss: 0.0757\n",
      "Epoch [15/50], Loss: 0.0743\n",
      "Epoch [16/50], Loss: 0.0744\n",
      "Epoch [17/50], Loss: 0.0759\n",
      "Epoch [18/50], Loss: 0.0757\n",
      "Epoch [19/50], Loss: 0.0747\n",
      "Epoch [20/50], Loss: 0.0752\n",
      "Epoch [21/50], Loss: 0.0763\n",
      "Epoch [22/50], Loss: 0.0747\n",
      "Epoch [23/50], Loss: 0.0755\n",
      "Epoch [24/50], Loss: 0.0746\n",
      "Epoch [25/50], Loss: 0.0756\n",
      "Epoch [26/50], Loss: 0.0755\n",
      "Epoch [27/50], Loss: 0.0762\n",
      "Epoch [28/50], Loss: 0.0757\n",
      "Epoch [29/50], Loss: 0.0755\n",
      "Epoch [30/50], Loss: 0.0753\n",
      "Epoch [31/50], Loss: 0.0751\n",
      "Epoch [32/50], Loss: 0.0754\n",
      "Epoch [33/50], Loss: 0.0757\n",
      "Epoch [34/50], Loss: 0.0767\n",
      "Epoch [35/50], Loss: 0.0771\n",
      "Epoch [36/50], Loss: 0.0762\n",
      "Epoch [37/50], Loss: 0.0763\n",
      "Epoch [38/50], Loss: 0.0756\n",
      "Epoch [39/50], Loss: 0.0755\n",
      "Epoch [40/50], Loss: 0.0752\n",
      "Epoch [41/50], Loss: 0.0777\n",
      "Epoch [42/50], Loss: 0.0758\n",
      "Epoch [43/50], Loss: 0.0841\n",
      "Epoch [44/50], Loss: 0.0759\n",
      "Epoch [45/50], Loss: 0.0749\n",
      "Epoch [46/50], Loss: 0.0769\n",
      "Epoch [47/50], Loss: 0.0752\n",
      "Epoch [48/50], Loss: 0.0755\n",
      "Epoch [49/50], Loss: 0.0761\n",
      "Epoch [50/50], Loss: 0.0759\n",
      "test performance :  [99.71630859 69.20845795 35.35316849 22.62295151 18.67264557]\n",
      "individual errors:  [array(42.88416, dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(50.479073, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "resewc2 = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWC(lam=0.001),num_epochs=num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resewc3 = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWC(lam=0.001),num_epochs=num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(resall,label=\"all\")\n",
    "plt.plot(resewc,label=\"ewc\")\n",
    "plt.plot(results[0],label=\"50\")\n",
    "plt.plot(results[1],label=\"100\")\n",
    "plt.plot(results[4],label=\"800\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [resewc,resall,respp,resppbig,l2new]\n",
    "\n",
    "def res_to_mtx(losses,filename):\n",
    "    ks = [i for i in range(len(losses[0]))]\n",
    "    A = [np.array(ks)]\n",
    "    A += losses\n",
    "    A = np.vstack( A ).T\n",
    "    print(A.shape)\n",
    "    np.savetxt(filename, A, delimiter=' ')\n",
    "\n",
    "res_to_mtx(results,\"MNIST_permutation_rand_feat.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  50 1e-05\n",
      "Epoch [1/100], Loss: 0.1052\n",
      "Epoch [2/100], Loss: 0.0498\n",
      "Epoch [3/100], Loss: 0.0478\n",
      "Epoch [4/100], Loss: 0.0465\n",
      "Epoch [5/100], Loss: 0.0441\n",
      "Epoch [6/100], Loss: 0.0428\n",
      "Epoch [7/100], Loss: 0.0412\n",
      "Epoch [8/100], Loss: 0.0390\n",
      "Epoch [9/100], Loss: 0.0375\n",
      "Epoch [10/100], Loss: 0.0360\n",
      "Epoch [11/100], Loss: 0.0334\n",
      "Epoch [12/100], Loss: 0.0322\n",
      "Epoch [13/100], Loss: 0.0305\n",
      "Epoch [14/100], Loss: 0.0287\n",
      "Epoch [15/100], Loss: 0.0273\n",
      "Epoch [16/100], Loss: 0.0254\n",
      "Epoch [17/100], Loss: 0.0241\n",
      "Epoch [18/100], Loss: 0.0233\n",
      "Epoch [19/100], Loss: 0.0217\n",
      "Epoch [20/100], Loss: 0.0198\n",
      "Epoch [21/100], Loss: 0.0189\n",
      "Epoch [22/100], Loss: 0.0182\n",
      "Epoch [23/100], Loss: 0.0168\n",
      "Epoch [24/100], Loss: 0.0161\n",
      "Epoch [25/100], Loss: 0.0148\n",
      "Epoch [26/100], Loss: 0.0149\n",
      "Epoch [27/100], Loss: 0.0135\n",
      "Epoch [28/100], Loss: 0.0123\n",
      "Epoch [29/100], Loss: 0.0122\n",
      "Epoch [30/100], Loss: 0.0117\n",
      "Epoch [31/100], Loss: 0.0109\n",
      "Epoch [32/100], Loss: 0.0096\n",
      "Epoch [33/100], Loss: 0.0100\n",
      "Epoch [34/100], Loss: 0.0098\n",
      "Epoch [35/100], Loss: 0.0094\n",
      "Epoch [36/100], Loss: 0.0080\n",
      "Epoch [37/100], Loss: 0.0082\n",
      "Epoch [38/100], Loss: 0.0074\n",
      "Epoch [39/100], Loss: 0.0070\n",
      "Epoch [40/100], Loss: 0.0072\n",
      "Epoch [41/100], Loss: 0.0069\n",
      "Epoch [42/100], Loss: 0.0063\n",
      "Epoch [43/100], Loss: 0.0062\n",
      "Epoch [44/100], Loss: 0.0062\n",
      "Epoch [45/100], Loss: 0.0063\n",
      "Epoch [46/100], Loss: 0.0067\n",
      "Epoch [47/100], Loss: 0.0061\n",
      "Epoch [48/100], Loss: 0.0056\n",
      "Epoch [49/100], Loss: 0.0055\n",
      "Epoch [50/100], Loss: 0.0054\n",
      "Epoch [51/100], Loss: 0.0047\n",
      "Epoch [52/100], Loss: 0.0059\n",
      "Epoch [53/100], Loss: 0.0049\n",
      "Epoch [54/100], Loss: 0.0051\n",
      "Epoch [55/100], Loss: 0.0053\n",
      "Epoch [56/100], Loss: 0.0054\n",
      "Epoch [57/100], Loss: 0.0046\n",
      "Epoch [58/100], Loss: 0.0050\n",
      "Epoch [59/100], Loss: 0.0051\n",
      "Epoch [60/100], Loss: 0.0041\n",
      "Epoch [61/100], Loss: 0.0052\n",
      "Epoch [62/100], Loss: 0.0048\n",
      "Epoch [63/100], Loss: 0.0042\n",
      "Epoch [64/100], Loss: 0.0043\n",
      "Epoch [65/100], Loss: 0.0041\n",
      "Epoch [66/100], Loss: 0.0040\n",
      "Epoch [67/100], Loss: 0.0042\n",
      "Epoch [68/100], Loss: 0.0045\n",
      "Epoch [69/100], Loss: 0.0043\n",
      "Epoch [70/100], Loss: 0.0048\n",
      "Epoch [71/100], Loss: 0.0045\n",
      "Epoch [72/100], Loss: 0.0038\n",
      "Epoch [73/100], Loss: 0.0041\n",
      "Epoch [74/100], Loss: 0.0034\n",
      "Epoch [75/100], Loss: 0.0049\n",
      "Epoch [76/100], Loss: 0.0044\n",
      "Epoch [77/100], Loss: 0.0040\n",
      "Epoch [78/100], Loss: 0.0043\n",
      "Epoch [79/100], Loss: 0.0034\n",
      "Epoch [80/100], Loss: 0.0038\n",
      "Epoch [81/100], Loss: 0.0039\n",
      "Epoch [82/100], Loss: 0.0044\n",
      "Epoch [83/100], Loss: 0.0042\n",
      "Epoch [84/100], Loss: 0.0036\n",
      "Epoch [85/100], Loss: 0.0038\n",
      "Epoch [86/100], Loss: 0.0039\n",
      "Epoch [87/100], Loss: 0.0037\n",
      "Epoch [88/100], Loss: 0.0040\n",
      "Epoch [89/100], Loss: 0.0035\n",
      "Epoch [90/100], Loss: 0.0039\n",
      "Epoch [91/100], Loss: 0.0040\n",
      "Epoch [92/100], Loss: 0.0041\n",
      "Epoch [93/100], Loss: 0.0046\n",
      "Epoch [94/100], Loss: 0.0035\n",
      "Epoch [95/100], Loss: 0.0037\n",
      "Epoch [96/100], Loss: 0.0038\n",
      "Epoch [97/100], Loss: 0.0033\n",
      "Epoch [98/100], Loss: 0.0041\n",
      "Epoch [99/100], Loss: 0.0041\n",
      "Epoch [100/100], Loss: 0.0040\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(468.5607, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.763596, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1559\n",
      "Epoch [2/100], Loss: 0.1050\n",
      "Epoch [3/100], Loss: 0.1020\n",
      "Epoch [4/100], Loss: 0.1003\n",
      "Epoch [5/100], Loss: 0.0986\n",
      "Epoch [6/100], Loss: 0.0950\n",
      "Epoch [7/100], Loss: 0.0930\n",
      "Epoch [8/100], Loss: 0.0908\n",
      "Epoch [9/100], Loss: 0.0888\n",
      "Epoch [10/100], Loss: 0.0862\n",
      "Epoch [11/100], Loss: 0.0841\n",
      "Epoch [12/100], Loss: 0.0811\n",
      "Epoch [13/100], Loss: 0.0784\n",
      "Epoch [14/100], Loss: 0.0768\n",
      "Epoch [15/100], Loss: 0.0754\n",
      "Epoch [16/100], Loss: 0.0734\n",
      "Epoch [17/100], Loss: 0.0716\n",
      "Epoch [18/100], Loss: 0.0694\n",
      "Epoch [19/100], Loss: 0.0671\n",
      "Epoch [20/100], Loss: 0.0668\n",
      "Epoch [21/100], Loss: 0.0641\n",
      "Epoch [22/100], Loss: 0.0623\n",
      "Epoch [23/100], Loss: 0.0610\n",
      "Epoch [24/100], Loss: 0.0582\n",
      "Epoch [25/100], Loss: 0.0571\n",
      "Epoch [26/100], Loss: 0.0566\n",
      "Epoch [27/100], Loss: 0.0557\n",
      "Epoch [28/100], Loss: 0.0533\n",
      "Epoch [29/100], Loss: 0.0528\n",
      "Epoch [30/100], Loss: 0.0527\n",
      "Epoch [31/100], Loss: 0.0497\n",
      "Epoch [32/100], Loss: 0.0498\n",
      "Epoch [33/100], Loss: 0.0478\n",
      "Epoch [34/100], Loss: 0.0483\n",
      "Epoch [35/100], Loss: 0.0471\n",
      "Epoch [36/100], Loss: 0.0441\n",
      "Epoch [37/100], Loss: 0.0438\n",
      "Epoch [38/100], Loss: 0.0417\n",
      "Epoch [39/100], Loss: 0.0412\n",
      "Epoch [40/100], Loss: 0.0416\n",
      "Epoch [41/100], Loss: 0.0403\n",
      "Epoch [42/100], Loss: 0.0408\n",
      "Epoch [43/100], Loss: 0.0385\n",
      "Epoch [44/100], Loss: 0.0389\n",
      "Epoch [45/100], Loss: 0.0370\n",
      "Epoch [46/100], Loss: 0.0389\n",
      "Epoch [47/100], Loss: 0.0355\n",
      "Epoch [48/100], Loss: 0.0366\n",
      "Epoch [49/100], Loss: 0.0354\n",
      "Epoch [50/100], Loss: 0.0345\n",
      "Epoch [51/100], Loss: 0.0339\n",
      "Epoch [52/100], Loss: 0.0336\n",
      "Epoch [53/100], Loss: 0.0339\n",
      "Epoch [54/100], Loss: 0.0328\n",
      "Epoch [55/100], Loss: 0.0320\n",
      "Epoch [56/100], Loss: 0.0314\n",
      "Epoch [57/100], Loss: 0.0319\n",
      "Epoch [58/100], Loss: 0.0310\n",
      "Epoch [59/100], Loss: 0.0302\n",
      "Epoch [60/100], Loss: 0.0301\n",
      "Epoch [61/100], Loss: 0.0306\n",
      "Epoch [62/100], Loss: 0.0297\n",
      "Epoch [63/100], Loss: 0.0286\n",
      "Epoch [64/100], Loss: 0.0289\n",
      "Epoch [65/100], Loss: 0.0279\n",
      "Epoch [66/100], Loss: 0.0283\n",
      "Epoch [67/100], Loss: 0.0283\n",
      "Epoch [68/100], Loss: 0.0286\n",
      "Epoch [69/100], Loss: 0.0283\n",
      "Epoch [70/100], Loss: 0.0272\n",
      "Epoch [71/100], Loss: 0.0272\n",
      "Epoch [72/100], Loss: 0.0271\n",
      "Epoch [73/100], Loss: 0.0269\n",
      "Epoch [74/100], Loss: 0.0266\n",
      "Epoch [75/100], Loss: 0.0262\n",
      "Epoch [76/100], Loss: 0.0238\n",
      "Epoch [77/100], Loss: 0.0257\n",
      "Epoch [78/100], Loss: 0.0255\n",
      "Epoch [79/100], Loss: 0.0244\n",
      "Epoch [80/100], Loss: 0.0235\n",
      "Epoch [81/100], Loss: 0.0244\n",
      "Epoch [82/100], Loss: 0.0236\n",
      "Epoch [83/100], Loss: 0.0242\n",
      "Epoch [84/100], Loss: 0.0250\n",
      "Epoch [85/100], Loss: 0.0232\n",
      "Epoch [86/100], Loss: 0.0234\n",
      "Epoch [87/100], Loss: 0.0240\n",
      "Epoch [88/100], Loss: 0.0219\n",
      "Epoch [89/100], Loss: 0.0241\n",
      "Epoch [90/100], Loss: 0.0225\n",
      "Epoch [91/100], Loss: 0.0240\n",
      "Epoch [92/100], Loss: 0.0204\n",
      "Epoch [93/100], Loss: 0.0231\n",
      "Epoch [94/100], Loss: 0.0211\n",
      "Epoch [95/100], Loss: 0.0219\n",
      "Epoch [96/100], Loss: 0.0221\n",
      "Epoch [97/100], Loss: 0.0213\n",
      "Epoch [98/100], Loss: 0.0230\n",
      "Epoch [99/100], Loss: 0.0205\n",
      "Epoch [100/100], Loss: 0.0211\n",
      "update data..\n",
      "task data norm and number entries: tensor(443.6446, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 90.89994049  0.          0.          0.        ]\n",
      "individual errors:  [array(87.18676, dtype=float32), array(94.61312, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1411\n",
      "Epoch [2/100], Loss: 0.1189\n",
      "Epoch [3/100], Loss: 0.1171\n",
      "Epoch [4/100], Loss: 0.1152\n",
      "Epoch [5/100], Loss: 0.1139\n",
      "Epoch [6/100], Loss: 0.1108\n",
      "Epoch [7/100], Loss: 0.1083\n",
      "Epoch [8/100], Loss: 0.1066\n",
      "Epoch [9/100], Loss: 0.1047\n",
      "Epoch [10/100], Loss: 0.1039\n",
      "Epoch [11/100], Loss: 0.1011\n",
      "Epoch [12/100], Loss: 0.0990\n",
      "Epoch [13/100], Loss: 0.0968\n",
      "Epoch [14/100], Loss: 0.0945\n",
      "Epoch [15/100], Loss: 0.0929\n",
      "Epoch [16/100], Loss: 0.0913\n",
      "Epoch [17/100], Loss: 0.0890\n",
      "Epoch [18/100], Loss: 0.0863\n",
      "Epoch [19/100], Loss: 0.0860\n",
      "Epoch [20/100], Loss: 0.0834\n",
      "Epoch [21/100], Loss: 0.0839\n",
      "Epoch [22/100], Loss: 0.0807\n",
      "Epoch [23/100], Loss: 0.0784\n",
      "Epoch [24/100], Loss: 0.0779\n",
      "Epoch [25/100], Loss: 0.0763\n",
      "Epoch [26/100], Loss: 0.0744\n",
      "Epoch [27/100], Loss: 0.0730\n",
      "Epoch [28/100], Loss: 0.0732\n",
      "Epoch [29/100], Loss: 0.0723\n",
      "Epoch [30/100], Loss: 0.0705\n",
      "Epoch [31/100], Loss: 0.0695\n",
      "Epoch [32/100], Loss: 0.0676\n",
      "Epoch [33/100], Loss: 0.0663\n",
      "Epoch [34/100], Loss: 0.0642\n",
      "Epoch [35/100], Loss: 0.0651\n",
      "Epoch [36/100], Loss: 0.0643\n",
      "Epoch [37/100], Loss: 0.0599\n",
      "Epoch [38/100], Loss: 0.0604\n",
      "Epoch [39/100], Loss: 0.0597\n",
      "Epoch [40/100], Loss: 0.0615\n",
      "Epoch [41/100], Loss: 0.0588\n",
      "Epoch [42/100], Loss: 0.0566\n",
      "Epoch [43/100], Loss: 0.0554\n",
      "Epoch [44/100], Loss: 0.0551\n",
      "Epoch [45/100], Loss: 0.0546\n",
      "Epoch [46/100], Loss: 0.0543\n",
      "Epoch [47/100], Loss: 0.0555\n",
      "Epoch [48/100], Loss: 0.0534\n",
      "Epoch [49/100], Loss: 0.0510\n",
      "Epoch [50/100], Loss: 0.0524\n",
      "Epoch [51/100], Loss: 0.0501\n",
      "Epoch [52/100], Loss: 0.0480\n",
      "Epoch [53/100], Loss: 0.0500\n",
      "Epoch [54/100], Loss: 0.0493\n",
      "Epoch [55/100], Loss: 0.0474\n",
      "Epoch [56/100], Loss: 0.0461\n",
      "Epoch [57/100], Loss: 0.0474\n",
      "Epoch [58/100], Loss: 0.0472\n",
      "Epoch [59/100], Loss: 0.0440\n",
      "Epoch [60/100], Loss: 0.0456\n",
      "Epoch [61/100], Loss: 0.0450\n",
      "Epoch [62/100], Loss: 0.0437\n",
      "Epoch [63/100], Loss: 0.0432\n",
      "Epoch [64/100], Loss: 0.0430\n",
      "Epoch [65/100], Loss: 0.0428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Loss: 0.0420\n",
      "Epoch [67/100], Loss: 0.0416\n",
      "Epoch [68/100], Loss: 0.0413\n",
      "Epoch [69/100], Loss: 0.0389\n",
      "Epoch [70/100], Loss: 0.0408\n",
      "Epoch [71/100], Loss: 0.0415\n",
      "Epoch [72/100], Loss: 0.0379\n",
      "Epoch [73/100], Loss: 0.0393\n",
      "Epoch [74/100], Loss: 0.0379\n",
      "Epoch [75/100], Loss: 0.0378\n",
      "Epoch [76/100], Loss: 0.0377\n",
      "Epoch [77/100], Loss: 0.0362\n",
      "Epoch [78/100], Loss: 0.0381\n",
      "Epoch [79/100], Loss: 0.0370\n",
      "Epoch [80/100], Loss: 0.0379\n",
      "Epoch [81/100], Loss: 0.0360\n",
      "Epoch [82/100], Loss: 0.0339\n",
      "Epoch [83/100], Loss: 0.0357\n",
      "Epoch [84/100], Loss: 0.0345\n",
      "Epoch [85/100], Loss: 0.0354\n",
      "Epoch [86/100], Loss: 0.0351\n",
      "Epoch [87/100], Loss: 0.0340\n",
      "Epoch [88/100], Loss: 0.0334\n",
      "Epoch [89/100], Loss: 0.0328\n",
      "Epoch [90/100], Loss: 0.0345\n",
      "Epoch [91/100], Loss: 0.0336\n",
      "Epoch [92/100], Loss: 0.0331\n",
      "Epoch [93/100], Loss: 0.0324\n",
      "Epoch [94/100], Loss: 0.0324\n",
      "Epoch [95/100], Loss: 0.0319\n",
      "Epoch [96/100], Loss: 0.0305\n",
      "Epoch [97/100], Loss: 0.0294\n",
      "Epoch [98/100], Loss: 0.0314\n",
      "Epoch [99/100], Loss: 0.0302\n",
      "Epoch [100/100], Loss: 0.0294\n",
      "update data..\n",
      "task data norm and number entries: tensor(422.7807, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 90.89994049 77.71824646  0.          0.        ]\n",
      "individual errors:  [array(72.43499, dtype=float32), array(67.9236, dtype=float32), array(92.79616, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1497\n",
      "Epoch [2/100], Loss: 0.1330\n",
      "Epoch [3/100], Loss: 0.1302\n",
      "Epoch [4/100], Loss: 0.1291\n",
      "Epoch [5/100], Loss: 0.1255\n",
      "Epoch [6/100], Loss: 0.1233\n",
      "Epoch [7/100], Loss: 0.1209\n",
      "Epoch [8/100], Loss: 0.1184\n",
      "Epoch [9/100], Loss: 0.1154\n",
      "Epoch [10/100], Loss: 0.1126\n",
      "Epoch [11/100], Loss: 0.1109\n",
      "Epoch [12/100], Loss: 0.1069\n",
      "Epoch [13/100], Loss: 0.1051\n",
      "Epoch [14/100], Loss: 0.1037\n",
      "Epoch [15/100], Loss: 0.1021\n",
      "Epoch [16/100], Loss: 0.0978\n",
      "Epoch [17/100], Loss: 0.0961\n",
      "Epoch [18/100], Loss: 0.0942\n",
      "Epoch [19/100], Loss: 0.0924\n",
      "Epoch [20/100], Loss: 0.0895\n",
      "Epoch [21/100], Loss: 0.0877\n",
      "Epoch [22/100], Loss: 0.0851\n",
      "Epoch [23/100], Loss: 0.0850\n",
      "Epoch [24/100], Loss: 0.0810\n",
      "Epoch [25/100], Loss: 0.0807\n",
      "Epoch [26/100], Loss: 0.0780\n",
      "Epoch [27/100], Loss: 0.0776\n",
      "Epoch [28/100], Loss: 0.0757\n",
      "Epoch [29/100], Loss: 0.0730\n",
      "Epoch [30/100], Loss: 0.0718\n",
      "Epoch [31/100], Loss: 0.0702\n",
      "Epoch [32/100], Loss: 0.0692\n",
      "Epoch [33/100], Loss: 0.0666\n",
      "Epoch [34/100], Loss: 0.0673\n",
      "Epoch [35/100], Loss: 0.0650\n",
      "Epoch [36/100], Loss: 0.0646\n",
      "Epoch [37/100], Loss: 0.0640\n",
      "Epoch [38/100], Loss: 0.0618\n",
      "Epoch [39/100], Loss: 0.0607\n",
      "Epoch [40/100], Loss: 0.0578\n",
      "Epoch [41/100], Loss: 0.0576\n",
      "Epoch [42/100], Loss: 0.0566\n",
      "Epoch [43/100], Loss: 0.0563\n",
      "Epoch [44/100], Loss: 0.0545\n",
      "Epoch [45/100], Loss: 0.0547\n",
      "Epoch [46/100], Loss: 0.0540\n",
      "Epoch [47/100], Loss: 0.0523\n",
      "Epoch [48/100], Loss: 0.0499\n",
      "Epoch [49/100], Loss: 0.0499\n",
      "Epoch [50/100], Loss: 0.0496\n",
      "Epoch [51/100], Loss: 0.0476\n",
      "Epoch [52/100], Loss: 0.0474\n",
      "Epoch [53/100], Loss: 0.0481\n",
      "Epoch [54/100], Loss: 0.0455\n",
      "Epoch [55/100], Loss: 0.0451\n",
      "Epoch [56/100], Loss: 0.0444\n",
      "Epoch [57/100], Loss: 0.0439\n",
      "Epoch [58/100], Loss: 0.0442\n",
      "Epoch [59/100], Loss: 0.0433\n",
      "Epoch [60/100], Loss: 0.0425\n",
      "Epoch [61/100], Loss: 0.0408\n",
      "Epoch [62/100], Loss: 0.0412\n",
      "Epoch [63/100], Loss: 0.0397\n",
      "Epoch [64/100], Loss: 0.0408\n",
      "Epoch [65/100], Loss: 0.0380\n",
      "Epoch [66/100], Loss: 0.0393\n",
      "Epoch [67/100], Loss: 0.0375\n",
      "Epoch [68/100], Loss: 0.0371\n",
      "Epoch [69/100], Loss: 0.0361\n",
      "Epoch [70/100], Loss: 0.0361\n",
      "Epoch [71/100], Loss: 0.0348\n",
      "Epoch [72/100], Loss: 0.0348\n",
      "Epoch [73/100], Loss: 0.0343\n",
      "Epoch [74/100], Loss: 0.0341\n",
      "Epoch [75/100], Loss: 0.0362\n",
      "Epoch [76/100], Loss: 0.0315\n",
      "Epoch [77/100], Loss: 0.0338\n",
      "Epoch [78/100], Loss: 0.0318\n",
      "Epoch [79/100], Loss: 0.0313\n",
      "Epoch [80/100], Loss: 0.0315\n",
      "Epoch [81/100], Loss: 0.0309\n",
      "Epoch [82/100], Loss: 0.0330\n",
      "Epoch [83/100], Loss: 0.0306\n",
      "Epoch [84/100], Loss: 0.0293\n",
      "Epoch [85/100], Loss: 0.0296\n",
      "Epoch [86/100], Loss: 0.0283\n",
      "Epoch [87/100], Loss: 0.0290\n",
      "Epoch [88/100], Loss: 0.0286\n",
      "Epoch [89/100], Loss: 0.0279\n",
      "Epoch [90/100], Loss: 0.0283\n",
      "Epoch [91/100], Loss: 0.0288\n",
      "Epoch [92/100], Loss: 0.0286\n",
      "Epoch [93/100], Loss: 0.0277\n",
      "Epoch [94/100], Loss: 0.0268\n",
      "Epoch [95/100], Loss: 0.0257\n",
      "Epoch [96/100], Loss: 0.0269\n",
      "Epoch [97/100], Loss: 0.0267\n",
      "Epoch [98/100], Loss: 0.0257\n",
      "Epoch [99/100], Loss: 0.0249\n",
      "Epoch [100/100], Loss: 0.0262\n",
      "update data..\n",
      "task data norm and number entries: tensor(428.4087, device='cuda:0') torch.Size([50, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 90.89994049 77.71824646 76.27329254  0.        ]\n",
      "individual errors:  [array(77.02128, dtype=float32), array(57.541626, dtype=float32), array(74.75987, dtype=float32), array(95.77039, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1447\n",
      "Epoch [2/100], Loss: 0.1348\n",
      "Epoch [3/100], Loss: 0.1297\n",
      "Epoch [4/100], Loss: 0.1288\n",
      "Epoch [5/100], Loss: 0.1279\n",
      "Epoch [6/100], Loss: 0.1260\n",
      "Epoch [7/100], Loss: 0.1245\n",
      "Epoch [8/100], Loss: 0.1232\n",
      "Epoch [9/100], Loss: 0.1224\n",
      "Epoch [10/100], Loss: 0.1196\n",
      "Epoch [11/100], Loss: 0.1192\n",
      "Epoch [12/100], Loss: 0.1190\n",
      "Epoch [13/100], Loss: 0.1156\n",
      "Epoch [14/100], Loss: 0.1150\n",
      "Epoch [15/100], Loss: 0.1124\n",
      "Epoch [16/100], Loss: 0.1131\n",
      "Epoch [17/100], Loss: 0.1096\n",
      "Epoch [18/100], Loss: 0.1111\n",
      "Epoch [19/100], Loss: 0.1089\n",
      "Epoch [20/100], Loss: 0.1059\n",
      "Epoch [21/100], Loss: 0.1054\n",
      "Epoch [22/100], Loss: 0.1052\n",
      "Epoch [23/100], Loss: 0.1051\n",
      "Epoch [24/100], Loss: 0.1020\n",
      "Epoch [25/100], Loss: 0.1001\n",
      "Epoch [26/100], Loss: 0.1004\n",
      "Epoch [27/100], Loss: 0.0998\n",
      "Epoch [28/100], Loss: 0.0973\n",
      "Epoch [29/100], Loss: 0.0977\n",
      "Epoch [30/100], Loss: 0.0956\n",
      "Epoch [31/100], Loss: 0.0938\n",
      "Epoch [32/100], Loss: 0.0934\n",
      "Epoch [33/100], Loss: 0.0934\n",
      "Epoch [34/100], Loss: 0.0917\n",
      "Epoch [35/100], Loss: 0.0903\n",
      "Epoch [36/100], Loss: 0.0941\n",
      "Epoch [37/100], Loss: 0.0891\n",
      "Epoch [38/100], Loss: 0.0908\n",
      "Epoch [39/100], Loss: 0.0879\n",
      "Epoch [40/100], Loss: 0.0861\n",
      "Epoch [41/100], Loss: 0.0855\n",
      "Epoch [42/100], Loss: 0.0861\n",
      "Epoch [43/100], Loss: 0.0840\n",
      "Epoch [44/100], Loss: 0.0838\n",
      "Epoch [45/100], Loss: 0.0843\n",
      "Epoch [46/100], Loss: 0.0823\n",
      "Epoch [47/100], Loss: 0.0808\n",
      "Epoch [48/100], Loss: 0.0794\n",
      "Epoch [49/100], Loss: 0.0800\n",
      "Epoch [50/100], Loss: 0.0775\n",
      "Epoch [51/100], Loss: 0.0788\n",
      "Epoch [52/100], Loss: 0.0775\n",
      "Epoch [53/100], Loss: 0.0787\n",
      "Epoch [54/100], Loss: 0.0754\n",
      "Epoch [55/100], Loss: 0.0763\n",
      "Epoch [56/100], Loss: 0.0766\n",
      "Epoch [57/100], Loss: 0.0740\n",
      "Epoch [58/100], Loss: 0.0741\n",
      "Epoch [59/100], Loss: 0.0738\n",
      "Epoch [60/100], Loss: 0.0707\n",
      "Epoch [61/100], Loss: 0.0730\n",
      "Epoch [62/100], Loss: 0.0717\n",
      "Epoch [63/100], Loss: 0.0710\n",
      "Epoch [64/100], Loss: 0.0686\n",
      "Epoch [65/100], Loss: 0.0688\n",
      "Epoch [66/100], Loss: 0.0678\n",
      "Epoch [67/100], Loss: 0.0674\n",
      "Epoch [68/100], Loss: 0.0677\n",
      "Epoch [69/100], Loss: 0.0674\n",
      "Epoch [70/100], Loss: 0.0672\n",
      "Epoch [71/100], Loss: 0.0673\n",
      "Epoch [72/100], Loss: 0.0655\n",
      "Epoch [73/100], Loss: 0.0629\n",
      "Epoch [74/100], Loss: 0.0657\n",
      "Epoch [75/100], Loss: 0.0654\n",
      "Epoch [76/100], Loss: 0.0639\n",
      "Epoch [77/100], Loss: 0.0626\n",
      "Epoch [78/100], Loss: 0.0649\n",
      "Epoch [79/100], Loss: 0.0641\n",
      "Epoch [80/100], Loss: 0.0631\n",
      "Epoch [81/100], Loss: 0.0635\n",
      "Epoch [82/100], Loss: 0.0644\n",
      "Epoch [83/100], Loss: 0.0620\n",
      "Epoch [84/100], Loss: 0.0611\n",
      "Epoch [85/100], Loss: 0.0591\n",
      "Epoch [86/100], Loss: 0.0592\n",
      "Epoch [87/100], Loss: 0.0602\n",
      "Epoch [88/100], Loss: 0.0630\n",
      "Epoch [89/100], Loss: 0.0596\n",
      "Epoch [90/100], Loss: 0.0563\n",
      "Epoch [91/100], Loss: 0.0577\n",
      "Epoch [92/100], Loss: 0.0599\n",
      "Epoch [93/100], Loss: 0.0569\n",
      "Epoch [94/100], Loss: 0.0571\n",
      "Epoch [95/100], Loss: 0.0557\n",
      "Epoch [96/100], Loss: 0.0556\n",
      "Epoch [97/100], Loss: 0.0576\n",
      "Epoch [98/100], Loss: 0.0540\n",
      "Epoch [99/100], Loss: 0.0533\n",
      "Epoch [100/100], Loss: 0.0528\n",
      "test performance :  [99.76359558 90.89994049 77.71824646 76.27329254 68.71746826]\n",
      "individual errors:  [array(77.39953, dtype=float32), array(51.077374, dtype=float32), array(45.090714, dtype=float32), array(83.635445, dtype=float32), array(86.38427, dtype=float32)]\n",
      "EWC++  100 1e-05\n",
      "Epoch [1/100], Loss: 0.0974\n",
      "Epoch [2/100], Loss: 0.0499\n",
      "Epoch [3/100], Loss: 0.0478\n",
      "Epoch [4/100], Loss: 0.0465\n",
      "Epoch [5/100], Loss: 0.0445\n",
      "Epoch [6/100], Loss: 0.0432\n",
      "Epoch [7/100], Loss: 0.0414\n",
      "Epoch [8/100], Loss: 0.0399\n",
      "Epoch [9/100], Loss: 0.0384\n",
      "Epoch [10/100], Loss: 0.0364\n",
      "Epoch [11/100], Loss: 0.0346\n",
      "Epoch [12/100], Loss: 0.0332\n",
      "Epoch [13/100], Loss: 0.0314\n",
      "Epoch [14/100], Loss: 0.0291\n",
      "Epoch [15/100], Loss: 0.0279\n",
      "Epoch [16/100], Loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 0.0257\n",
      "Epoch [18/100], Loss: 0.0235\n",
      "Epoch [19/100], Loss: 0.0229\n",
      "Epoch [20/100], Loss: 0.0212\n",
      "Epoch [21/100], Loss: 0.0204\n",
      "Epoch [22/100], Loss: 0.0188\n",
      "Epoch [23/100], Loss: 0.0181\n",
      "Epoch [24/100], Loss: 0.0169\n",
      "Epoch [25/100], Loss: 0.0161\n",
      "Epoch [26/100], Loss: 0.0152\n",
      "Epoch [27/100], Loss: 0.0149\n",
      "Epoch [28/100], Loss: 0.0143\n",
      "Epoch [29/100], Loss: 0.0128\n",
      "Epoch [30/100], Loss: 0.0131\n",
      "Epoch [31/100], Loss: 0.0114\n",
      "Epoch [32/100], Loss: 0.0115\n",
      "Epoch [33/100], Loss: 0.0108\n",
      "Epoch [34/100], Loss: 0.0094\n",
      "Epoch [35/100], Loss: 0.0090\n",
      "Epoch [36/100], Loss: 0.0087\n",
      "Epoch [37/100], Loss: 0.0088\n",
      "Epoch [38/100], Loss: 0.0085\n",
      "Epoch [39/100], Loss: 0.0073\n",
      "Epoch [40/100], Loss: 0.0069\n",
      "Epoch [41/100], Loss: 0.0077\n",
      "Epoch [42/100], Loss: 0.0060\n",
      "Epoch [43/100], Loss: 0.0071\n",
      "Epoch [44/100], Loss: 0.0075\n",
      "Epoch [45/100], Loss: 0.0063\n",
      "Epoch [46/100], Loss: 0.0061\n",
      "Epoch [47/100], Loss: 0.0059\n",
      "Epoch [48/100], Loss: 0.0063\n",
      "Epoch [49/100], Loss: 0.0054\n",
      "Epoch [50/100], Loss: 0.0057\n",
      "Epoch [51/100], Loss: 0.0061\n",
      "Epoch [52/100], Loss: 0.0060\n",
      "Epoch [53/100], Loss: 0.0059\n",
      "Epoch [54/100], Loss: 0.0053\n",
      "Epoch [55/100], Loss: 0.0053\n",
      "Epoch [56/100], Loss: 0.0050\n",
      "Epoch [57/100], Loss: 0.0047\n",
      "Epoch [58/100], Loss: 0.0047\n",
      "Epoch [59/100], Loss: 0.0047\n",
      "Epoch [60/100], Loss: 0.0050\n",
      "Epoch [61/100], Loss: 0.0047\n",
      "Epoch [62/100], Loss: 0.0045\n",
      "Epoch [63/100], Loss: 0.0047\n",
      "Epoch [64/100], Loss: 0.0040\n",
      "Epoch [65/100], Loss: 0.0047\n",
      "Epoch [66/100], Loss: 0.0043\n",
      "Epoch [67/100], Loss: 0.0045\n",
      "Epoch [68/100], Loss: 0.0037\n",
      "Epoch [69/100], Loss: 0.0042\n",
      "Epoch [70/100], Loss: 0.0042\n",
      "Epoch [71/100], Loss: 0.0051\n",
      "Epoch [72/100], Loss: 0.0048\n",
      "Epoch [73/100], Loss: 0.0041\n",
      "Epoch [74/100], Loss: 0.0039\n",
      "Epoch [75/100], Loss: 0.0036\n",
      "Epoch [76/100], Loss: 0.0045\n",
      "Epoch [77/100], Loss: 0.0043\n",
      "Epoch [78/100], Loss: 0.0043\n",
      "Epoch [79/100], Loss: 0.0048\n",
      "Epoch [80/100], Loss: 0.0045\n",
      "Epoch [81/100], Loss: 0.0037\n",
      "Epoch [82/100], Loss: 0.0038\n",
      "Epoch [83/100], Loss: 0.0052\n",
      "Epoch [84/100], Loss: 0.0043\n",
      "Epoch [85/100], Loss: 0.0046\n",
      "Epoch [86/100], Loss: 0.0036\n",
      "Epoch [87/100], Loss: 0.0044\n",
      "Epoch [88/100], Loss: 0.0047\n",
      "Epoch [89/100], Loss: 0.0037\n",
      "Epoch [90/100], Loss: 0.0042\n",
      "Epoch [91/100], Loss: 0.0039\n",
      "Epoch [92/100], Loss: 0.0042\n",
      "Epoch [93/100], Loss: 0.0038\n",
      "Epoch [94/100], Loss: 0.0038\n",
      "Epoch [95/100], Loss: 0.0037\n",
      "Epoch [96/100], Loss: 0.0041\n",
      "Epoch [97/100], Loss: 0.0043\n",
      "Epoch [98/100], Loss: 0.0036\n",
      "Epoch [99/100], Loss: 0.0041\n",
      "Epoch [100/100], Loss: 0.0039\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(459.1970, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.71631, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1543\n",
      "Epoch [2/100], Loss: 0.1103\n",
      "Epoch [3/100], Loss: 0.1070\n",
      "Epoch [4/100], Loss: 0.1055\n",
      "Epoch [5/100], Loss: 0.1044\n",
      "Epoch [6/100], Loss: 0.1019\n",
      "Epoch [7/100], Loss: 0.1000\n",
      "Epoch [8/100], Loss: 0.0983\n",
      "Epoch [9/100], Loss: 0.0969\n",
      "Epoch [10/100], Loss: 0.0947\n",
      "Epoch [11/100], Loss: 0.0919\n",
      "Epoch [12/100], Loss: 0.0911\n",
      "Epoch [13/100], Loss: 0.0885\n",
      "Epoch [14/100], Loss: 0.0860\n",
      "Epoch [15/100], Loss: 0.0843\n",
      "Epoch [16/100], Loss: 0.0828\n",
      "Epoch [17/100], Loss: 0.0816\n",
      "Epoch [18/100], Loss: 0.0782\n",
      "Epoch [19/100], Loss: 0.0764\n",
      "Epoch [20/100], Loss: 0.0755\n",
      "Epoch [21/100], Loss: 0.0727\n",
      "Epoch [22/100], Loss: 0.0719\n",
      "Epoch [23/100], Loss: 0.0705\n",
      "Epoch [24/100], Loss: 0.0690\n",
      "Epoch [25/100], Loss: 0.0674\n",
      "Epoch [26/100], Loss: 0.0680\n",
      "Epoch [27/100], Loss: 0.0642\n",
      "Epoch [28/100], Loss: 0.0643\n",
      "Epoch [29/100], Loss: 0.0638\n",
      "Epoch [30/100], Loss: 0.0608\n",
      "Epoch [31/100], Loss: 0.0596\n",
      "Epoch [32/100], Loss: 0.0583\n",
      "Epoch [33/100], Loss: 0.0565\n",
      "Epoch [34/100], Loss: 0.0559\n",
      "Epoch [35/100], Loss: 0.0549\n",
      "Epoch [36/100], Loss: 0.0543\n",
      "Epoch [37/100], Loss: 0.0530\n",
      "Epoch [38/100], Loss: 0.0526\n",
      "Epoch [39/100], Loss: 0.0522\n",
      "Epoch [40/100], Loss: 0.0500\n",
      "Epoch [41/100], Loss: 0.0489\n",
      "Epoch [42/100], Loss: 0.0488\n",
      "Epoch [43/100], Loss: 0.0469\n",
      "Epoch [44/100], Loss: 0.0458\n",
      "Epoch [45/100], Loss: 0.0458\n",
      "Epoch [46/100], Loss: 0.0451\n",
      "Epoch [47/100], Loss: 0.0459\n",
      "Epoch [48/100], Loss: 0.0451\n",
      "Epoch [49/100], Loss: 0.0436\n",
      "Epoch [50/100], Loss: 0.0425\n",
      "Epoch [51/100], Loss: 0.0417\n",
      "Epoch [52/100], Loss: 0.0410\n",
      "Epoch [53/100], Loss: 0.0406\n",
      "Epoch [54/100], Loss: 0.0410\n",
      "Epoch [55/100], Loss: 0.0388\n",
      "Epoch [56/100], Loss: 0.0391\n",
      "Epoch [57/100], Loss: 0.0387\n",
      "Epoch [58/100], Loss: 0.0378\n",
      "Epoch [59/100], Loss: 0.0387\n",
      "Epoch [60/100], Loss: 0.0351\n",
      "Epoch [61/100], Loss: 0.0364\n",
      "Epoch [62/100], Loss: 0.0366\n",
      "Epoch [63/100], Loss: 0.0374\n",
      "Epoch [64/100], Loss: 0.0343\n",
      "Epoch [65/100], Loss: 0.0355\n",
      "Epoch [66/100], Loss: 0.0348\n",
      "Epoch [67/100], Loss: 0.0334\n",
      "Epoch [68/100], Loss: 0.0344\n",
      "Epoch [69/100], Loss: 0.0330\n",
      "Epoch [70/100], Loss: 0.0336\n",
      "Epoch [71/100], Loss: 0.0324\n",
      "Epoch [72/100], Loss: 0.0324\n",
      "Epoch [73/100], Loss: 0.0318\n",
      "Epoch [74/100], Loss: 0.0312\n",
      "Epoch [75/100], Loss: 0.0310\n",
      "Epoch [76/100], Loss: 0.0299\n",
      "Epoch [77/100], Loss: 0.0311\n",
      "Epoch [78/100], Loss: 0.0312\n",
      "Epoch [79/100], Loss: 0.0320\n",
      "Epoch [80/100], Loss: 0.0307\n",
      "Epoch [81/100], Loss: 0.0302\n",
      "Epoch [82/100], Loss: 0.0321\n",
      "Epoch [83/100], Loss: 0.0282\n",
      "Epoch [84/100], Loss: 0.0292\n",
      "Epoch [85/100], Loss: 0.0298\n",
      "Epoch [86/100], Loss: 0.0298\n",
      "Epoch [87/100], Loss: 0.0276\n",
      "Epoch [88/100], Loss: 0.0282\n",
      "Epoch [89/100], Loss: 0.0272\n",
      "Epoch [90/100], Loss: 0.0262\n",
      "Epoch [91/100], Loss: 0.0270\n",
      "Epoch [92/100], Loss: 0.0268\n",
      "Epoch [93/100], Loss: 0.0286\n",
      "Epoch [94/100], Loss: 0.0255\n",
      "Epoch [95/100], Loss: 0.0271\n",
      "Epoch [96/100], Loss: 0.0262\n",
      "Epoch [97/100], Loss: 0.0259\n",
      "Epoch [98/100], Loss: 0.0274\n",
      "Epoch [99/100], Loss: 0.0270\n",
      "Epoch [100/100], Loss: 0.0261\n",
      "update data..\n",
      "task data norm and number entries: tensor(448.1503, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859 94.41054535  0.          0.          0.        ]\n",
      "individual errors:  [array(96.26478, dtype=float32), array(92.55631, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1548\n",
      "Epoch [2/100], Loss: 0.1309\n",
      "Epoch [3/100], Loss: 0.1262\n",
      "Epoch [4/100], Loss: 0.1248\n",
      "Epoch [5/100], Loss: 0.1236\n",
      "Epoch [6/100], Loss: 0.1204\n",
      "Epoch [7/100], Loss: 0.1203\n",
      "Epoch [8/100], Loss: 0.1167\n",
      "Epoch [9/100], Loss: 0.1157\n",
      "Epoch [10/100], Loss: 0.1132\n",
      "Epoch [11/100], Loss: 0.1117\n",
      "Epoch [12/100], Loss: 0.1091\n",
      "Epoch [13/100], Loss: 0.1081\n",
      "Epoch [14/100], Loss: 0.1048\n",
      "Epoch [15/100], Loss: 0.1028\n",
      "Epoch [16/100], Loss: 0.1010\n",
      "Epoch [17/100], Loss: 0.0991\n",
      "Epoch [18/100], Loss: 0.0976\n",
      "Epoch [19/100], Loss: 0.0962\n",
      "Epoch [20/100], Loss: 0.0933\n",
      "Epoch [21/100], Loss: 0.0919\n",
      "Epoch [22/100], Loss: 0.0898\n",
      "Epoch [23/100], Loss: 0.0902\n",
      "Epoch [24/100], Loss: 0.0877\n",
      "Epoch [25/100], Loss: 0.0873\n",
      "Epoch [26/100], Loss: 0.0840\n",
      "Epoch [27/100], Loss: 0.0856\n",
      "Epoch [28/100], Loss: 0.0827\n",
      "Epoch [29/100], Loss: 0.0810\n",
      "Epoch [30/100], Loss: 0.0810\n",
      "Epoch [31/100], Loss: 0.0780\n",
      "Epoch [32/100], Loss: 0.0776\n",
      "Epoch [33/100], Loss: 0.0760\n",
      "Epoch [34/100], Loss: 0.0744\n",
      "Epoch [35/100], Loss: 0.0747\n",
      "Epoch [36/100], Loss: 0.0733\n",
      "Epoch [37/100], Loss: 0.0731\n",
      "Epoch [38/100], Loss: 0.0723\n",
      "Epoch [39/100], Loss: 0.0711\n",
      "Epoch [40/100], Loss: 0.0692\n",
      "Epoch [41/100], Loss: 0.0669\n",
      "Epoch [42/100], Loss: 0.0688\n",
      "Epoch [43/100], Loss: 0.0656\n",
      "Epoch [44/100], Loss: 0.0645\n",
      "Epoch [45/100], Loss: 0.0657\n",
      "Epoch [46/100], Loss: 0.0647\n",
      "Epoch [47/100], Loss: 0.0638\n",
      "Epoch [48/100], Loss: 0.0615\n",
      "Epoch [49/100], Loss: 0.0639\n",
      "Epoch [50/100], Loss: 0.0622\n",
      "Epoch [51/100], Loss: 0.0605\n",
      "Epoch [52/100], Loss: 0.0600\n",
      "Epoch [53/100], Loss: 0.0589\n",
      "Epoch [54/100], Loss: 0.0571\n",
      "Epoch [55/100], Loss: 0.0580\n",
      "Epoch [56/100], Loss: 0.0571\n",
      "Epoch [57/100], Loss: 0.0566\n",
      "Epoch [58/100], Loss: 0.0574\n",
      "Epoch [59/100], Loss: 0.0540\n",
      "Epoch [60/100], Loss: 0.0550\n",
      "Epoch [61/100], Loss: 0.0529\n",
      "Epoch [62/100], Loss: 0.0534\n",
      "Epoch [63/100], Loss: 0.0531\n",
      "Epoch [64/100], Loss: 0.0508\n",
      "Epoch [65/100], Loss: 0.0517\n",
      "Epoch [66/100], Loss: 0.0521\n",
      "Epoch [67/100], Loss: 0.0503\n",
      "Epoch [68/100], Loss: 0.0512\n",
      "Epoch [69/100], Loss: 0.0507\n",
      "Epoch [70/100], Loss: 0.0488\n",
      "Epoch [71/100], Loss: 0.0486\n",
      "Epoch [72/100], Loss: 0.0468\n",
      "Epoch [73/100], Loss: 0.0480\n",
      "Epoch [74/100], Loss: 0.0482\n",
      "Epoch [75/100], Loss: 0.0469\n",
      "Epoch [76/100], Loss: 0.0485\n",
      "Epoch [77/100], Loss: 0.0456\n",
      "Epoch [78/100], Loss: 0.0477\n",
      "Epoch [79/100], Loss: 0.0450\n",
      "Epoch [80/100], Loss: 0.0448\n",
      "Epoch [81/100], Loss: 0.0450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Loss: 0.0430\n",
      "Epoch [83/100], Loss: 0.0447\n",
      "Epoch [84/100], Loss: 0.0460\n",
      "Epoch [85/100], Loss: 0.0429\n",
      "Epoch [86/100], Loss: 0.0438\n",
      "Epoch [87/100], Loss: 0.0422\n",
      "Epoch [88/100], Loss: 0.0425\n",
      "Epoch [89/100], Loss: 0.0416\n",
      "Epoch [90/100], Loss: 0.0422\n",
      "Epoch [91/100], Loss: 0.0409\n",
      "Epoch [92/100], Loss: 0.0403\n",
      "Epoch [93/100], Loss: 0.0420\n",
      "Epoch [94/100], Loss: 0.0394\n",
      "Epoch [95/100], Loss: 0.0416\n",
      "Epoch [96/100], Loss: 0.0399\n",
      "Epoch [97/100], Loss: 0.0402\n",
      "Epoch [98/100], Loss: 0.0377\n",
      "Epoch [99/100], Loss: 0.0403\n",
      "Epoch [100/100], Loss: 0.0384\n",
      "update data..\n",
      "task data norm and number entries: tensor(425.4097, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859 94.41054535 89.43772125  0.          0.        ]\n",
      "individual errors:  [array(96.97399, dtype=float32), array(79.8237, dtype=float32), array(91.51547, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1529\n",
      "Epoch [2/100], Loss: 0.1362\n",
      "Epoch [3/100], Loss: 0.1296\n",
      "Epoch [4/100], Loss: 0.1290\n",
      "Epoch [5/100], Loss: 0.1281\n",
      "Epoch [6/100], Loss: 0.1257\n",
      "Epoch [7/100], Loss: 0.1236\n",
      "Epoch [8/100], Loss: 0.1204\n",
      "Epoch [9/100], Loss: 0.1198\n",
      "Epoch [10/100], Loss: 0.1156\n",
      "Epoch [11/100], Loss: 0.1147\n",
      "Epoch [12/100], Loss: 0.1128\n",
      "Epoch [13/100], Loss: 0.1095\n",
      "Epoch [14/100], Loss: 0.1067\n",
      "Epoch [15/100], Loss: 0.1065\n",
      "Epoch [16/100], Loss: 0.1052\n",
      "Epoch [17/100], Loss: 0.1016\n",
      "Epoch [18/100], Loss: 0.1000\n",
      "Epoch [19/100], Loss: 0.0980\n",
      "Epoch [20/100], Loss: 0.0973\n",
      "Epoch [21/100], Loss: 0.0949\n",
      "Epoch [22/100], Loss: 0.0927\n",
      "Epoch [23/100], Loss: 0.0913\n",
      "Epoch [24/100], Loss: 0.0897\n",
      "Epoch [25/100], Loss: 0.0888\n",
      "Epoch [26/100], Loss: 0.0864\n",
      "Epoch [27/100], Loss: 0.0844\n",
      "Epoch [28/100], Loss: 0.0823\n",
      "Epoch [29/100], Loss: 0.0810\n",
      "Epoch [30/100], Loss: 0.0807\n",
      "Epoch [31/100], Loss: 0.0798\n",
      "Epoch [32/100], Loss: 0.0777\n",
      "Epoch [33/100], Loss: 0.0764\n",
      "Epoch [34/100], Loss: 0.0740\n",
      "Epoch [35/100], Loss: 0.0731\n",
      "Epoch [36/100], Loss: 0.0734\n",
      "Epoch [37/100], Loss: 0.0722\n",
      "Epoch [38/100], Loss: 0.0706\n",
      "Epoch [39/100], Loss: 0.0693\n",
      "Epoch [40/100], Loss: 0.0684\n",
      "Epoch [41/100], Loss: 0.0678\n",
      "Epoch [42/100], Loss: 0.0656\n",
      "Epoch [43/100], Loss: 0.0651\n",
      "Epoch [44/100], Loss: 0.0649\n",
      "Epoch [45/100], Loss: 0.0621\n",
      "Epoch [46/100], Loss: 0.0608\n",
      "Epoch [47/100], Loss: 0.0614\n",
      "Epoch [48/100], Loss: 0.0598\n",
      "Epoch [49/100], Loss: 0.0598\n",
      "Epoch [50/100], Loss: 0.0591\n",
      "Epoch [51/100], Loss: 0.0584\n",
      "Epoch [52/100], Loss: 0.0562\n",
      "Epoch [53/100], Loss: 0.0554\n",
      "Epoch [54/100], Loss: 0.0537\n",
      "Epoch [55/100], Loss: 0.0539\n",
      "Epoch [56/100], Loss: 0.0522\n",
      "Epoch [57/100], Loss: 0.0530\n",
      "Epoch [58/100], Loss: 0.0524\n",
      "Epoch [59/100], Loss: 0.0513\n",
      "Epoch [60/100], Loss: 0.0488\n",
      "Epoch [61/100], Loss: 0.0507\n",
      "Epoch [62/100], Loss: 0.0488\n",
      "Epoch [63/100], Loss: 0.0497\n",
      "Epoch [64/100], Loss: 0.0492\n",
      "Epoch [65/100], Loss: 0.0478\n",
      "Epoch [66/100], Loss: 0.0492\n",
      "Epoch [67/100], Loss: 0.0478\n",
      "Epoch [68/100], Loss: 0.0452\n",
      "Epoch [69/100], Loss: 0.0453\n",
      "Epoch [70/100], Loss: 0.0456\n",
      "Epoch [71/100], Loss: 0.0434\n",
      "Epoch [72/100], Loss: 0.0452\n",
      "Epoch [73/100], Loss: 0.0440\n",
      "Epoch [74/100], Loss: 0.0430\n",
      "Epoch [75/100], Loss: 0.0441\n",
      "Epoch [76/100], Loss: 0.0408\n",
      "Epoch [77/100], Loss: 0.0414\n",
      "Epoch [78/100], Loss: 0.0414\n",
      "Epoch [79/100], Loss: 0.0427\n",
      "Epoch [80/100], Loss: 0.0411\n",
      "Epoch [81/100], Loss: 0.0405\n",
      "Epoch [82/100], Loss: 0.0395\n",
      "Epoch [83/100], Loss: 0.0390\n",
      "Epoch [84/100], Loss: 0.0384\n",
      "Epoch [85/100], Loss: 0.0373\n",
      "Epoch [86/100], Loss: 0.0385\n",
      "Epoch [87/100], Loss: 0.0378\n",
      "Epoch [88/100], Loss: 0.0358\n",
      "Epoch [89/100], Loss: 0.0373\n",
      "Epoch [90/100], Loss: 0.0364\n",
      "Epoch [91/100], Loss: 0.0366\n",
      "Epoch [92/100], Loss: 0.0355\n",
      "Epoch [93/100], Loss: 0.0350\n",
      "Epoch [94/100], Loss: 0.0338\n",
      "Epoch [95/100], Loss: 0.0362\n",
      "Epoch [96/100], Loss: 0.0347\n",
      "Epoch [97/100], Loss: 0.0346\n",
      "Epoch [98/100], Loss: 0.0338\n",
      "Epoch [99/100], Loss: 0.0347\n",
      "Epoch [100/100], Loss: 0.0326\n",
      "update data..\n",
      "task data norm and number entries: tensor(453.6877, device='cuda:0') torch.Size([100, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859 94.41054535 89.43772125 84.59539795  0.        ]\n",
      "individual errors:  [array(94.184395, dtype=float32), array(69.04995, dtype=float32), array(80.73639, dtype=float32), array(94.41087, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1330\n",
      "Epoch [2/100], Loss: 0.1254\n",
      "Epoch [3/100], Loss: 0.1221\n",
      "Epoch [4/100], Loss: 0.1208\n",
      "Epoch [5/100], Loss: 0.1198\n",
      "Epoch [6/100], Loss: 0.1184\n",
      "Epoch [7/100], Loss: 0.1175\n",
      "Epoch [8/100], Loss: 0.1163\n",
      "Epoch [9/100], Loss: 0.1158\n",
      "Epoch [10/100], Loss: 0.1136\n",
      "Epoch [11/100], Loss: 0.1129\n",
      "Epoch [12/100], Loss: 0.1110\n",
      "Epoch [13/100], Loss: 0.1110\n",
      "Epoch [14/100], Loss: 0.1085\n",
      "Epoch [15/100], Loss: 0.1079\n",
      "Epoch [16/100], Loss: 0.1061\n",
      "Epoch [17/100], Loss: 0.1072\n",
      "Epoch [18/100], Loss: 0.1049\n",
      "Epoch [19/100], Loss: 0.1053\n",
      "Epoch [20/100], Loss: 0.1018\n",
      "Epoch [21/100], Loss: 0.1014\n",
      "Epoch [22/100], Loss: 0.1028\n",
      "Epoch [23/100], Loss: 0.1004\n",
      "Epoch [24/100], Loss: 0.0982\n",
      "Epoch [25/100], Loss: 0.0974\n",
      "Epoch [26/100], Loss: 0.0983\n",
      "Epoch [27/100], Loss: 0.0979\n",
      "Epoch [28/100], Loss: 0.0946\n",
      "Epoch [29/100], Loss: 0.0942\n",
      "Epoch [30/100], Loss: 0.0935\n",
      "Epoch [31/100], Loss: 0.0935\n",
      "Epoch [32/100], Loss: 0.0926\n",
      "Epoch [33/100], Loss: 0.0920\n",
      "Epoch [34/100], Loss: 0.0916\n",
      "Epoch [35/100], Loss: 0.0908\n",
      "Epoch [36/100], Loss: 0.0906\n",
      "Epoch [37/100], Loss: 0.0923\n",
      "Epoch [38/100], Loss: 0.0879\n",
      "Epoch [39/100], Loss: 0.0874\n",
      "Epoch [40/100], Loss: 0.0882\n",
      "Epoch [41/100], Loss: 0.0872\n",
      "Epoch [42/100], Loss: 0.0859\n",
      "Epoch [43/100], Loss: 0.0861\n",
      "Epoch [44/100], Loss: 0.0849\n",
      "Epoch [45/100], Loss: 0.0839\n",
      "Epoch [46/100], Loss: 0.0837\n",
      "Epoch [47/100], Loss: 0.0839\n",
      "Epoch [48/100], Loss: 0.0819\n",
      "Epoch [49/100], Loss: 0.0829\n",
      "Epoch [50/100], Loss: 0.0822\n",
      "Epoch [51/100], Loss: 0.0820\n",
      "Epoch [52/100], Loss: 0.0816\n",
      "Epoch [53/100], Loss: 0.0811\n",
      "Epoch [54/100], Loss: 0.0803\n",
      "Epoch [55/100], Loss: 0.0790\n",
      "Epoch [56/100], Loss: 0.0778\n",
      "Epoch [57/100], Loss: 0.0781\n",
      "Epoch [58/100], Loss: 0.0777\n",
      "Epoch [59/100], Loss: 0.0772\n",
      "Epoch [60/100], Loss: 0.0781\n",
      "Epoch [61/100], Loss: 0.0763\n",
      "Epoch [62/100], Loss: 0.0752\n",
      "Epoch [63/100], Loss: 0.0773\n",
      "Epoch [64/100], Loss: 0.0756\n",
      "Epoch [65/100], Loss: 0.0754\n",
      "Epoch [66/100], Loss: 0.0750\n",
      "Epoch [67/100], Loss: 0.0748\n",
      "Epoch [68/100], Loss: 0.0766\n",
      "Epoch [69/100], Loss: 0.0764\n",
      "Epoch [70/100], Loss: 0.0736\n",
      "Epoch [71/100], Loss: 0.0735\n",
      "Epoch [72/100], Loss: 0.0726\n",
      "Epoch [73/100], Loss: 0.0730\n",
      "Epoch [74/100], Loss: 0.0750\n",
      "Epoch [75/100], Loss: 0.0733\n",
      "Epoch [76/100], Loss: 0.0707\n",
      "Epoch [77/100], Loss: 0.0715\n",
      "Epoch [78/100], Loss: 0.0701\n",
      "Epoch [79/100], Loss: 0.0703\n",
      "Epoch [80/100], Loss: 0.0715\n",
      "Epoch [81/100], Loss: 0.0698\n",
      "Epoch [82/100], Loss: 0.0701\n",
      "Epoch [83/100], Loss: 0.0702\n",
      "Epoch [84/100], Loss: 0.0703\n",
      "Epoch [85/100], Loss: 0.0673\n",
      "Epoch [86/100], Loss: 0.0679\n",
      "Epoch [87/100], Loss: 0.0675\n",
      "Epoch [88/100], Loss: 0.0660\n",
      "Epoch [89/100], Loss: 0.0671\n",
      "Epoch [90/100], Loss: 0.0660\n",
      "Epoch [91/100], Loss: 0.0669\n",
      "Epoch [92/100], Loss: 0.0663\n",
      "Epoch [93/100], Loss: 0.0669\n",
      "Epoch [94/100], Loss: 0.0651\n",
      "Epoch [95/100], Loss: 0.0668\n",
      "Epoch [96/100], Loss: 0.0651\n",
      "Epoch [97/100], Loss: 0.0658\n",
      "Epoch [98/100], Loss: 0.0646\n",
      "Epoch [99/100], Loss: 0.0632\n",
      "Epoch [100/100], Loss: 0.0627\n",
      "test performance :  [99.71630859 94.41054535 89.43772125 84.59539795 77.90509033]\n",
      "individual errors:  [array(93.711586, dtype=float32), array(53.819782, dtype=float32), array(67.39594, dtype=float32), array(90.63444, dtype=float32), array(83.96369, dtype=float32)]\n",
      "EWC++  200 1e-05\n",
      "Epoch [1/100], Loss: 0.1026\n",
      "Epoch [2/100], Loss: 0.0505\n",
      "Epoch [3/100], Loss: 0.0473\n",
      "Epoch [4/100], Loss: 0.0461\n",
      "Epoch [5/100], Loss: 0.0450\n",
      "Epoch [6/100], Loss: 0.0427\n",
      "Epoch [7/100], Loss: 0.0414\n",
      "Epoch [8/100], Loss: 0.0393\n",
      "Epoch [9/100], Loss: 0.0372\n",
      "Epoch [10/100], Loss: 0.0358\n",
      "Epoch [11/100], Loss: 0.0333\n",
      "Epoch [12/100], Loss: 0.0320\n",
      "Epoch [13/100], Loss: 0.0307\n",
      "Epoch [14/100], Loss: 0.0288\n",
      "Epoch [15/100], Loss: 0.0272\n",
      "Epoch [16/100], Loss: 0.0260\n",
      "Epoch [17/100], Loss: 0.0244\n",
      "Epoch [18/100], Loss: 0.0236\n",
      "Epoch [19/100], Loss: 0.0215\n",
      "Epoch [20/100], Loss: 0.0202\n",
      "Epoch [21/100], Loss: 0.0193\n",
      "Epoch [22/100], Loss: 0.0186\n",
      "Epoch [23/100], Loss: 0.0180\n",
      "Epoch [24/100], Loss: 0.0165\n",
      "Epoch [25/100], Loss: 0.0153\n",
      "Epoch [26/100], Loss: 0.0141\n",
      "Epoch [27/100], Loss: 0.0142\n",
      "Epoch [28/100], Loss: 0.0123\n",
      "Epoch [29/100], Loss: 0.0126\n",
      "Epoch [30/100], Loss: 0.0117\n",
      "Epoch [31/100], Loss: 0.0113\n",
      "Epoch [32/100], Loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Loss: 0.0096\n",
      "Epoch [34/100], Loss: 0.0093\n",
      "Epoch [35/100], Loss: 0.0087\n",
      "Epoch [36/100], Loss: 0.0088\n",
      "Epoch [37/100], Loss: 0.0083\n",
      "Epoch [38/100], Loss: 0.0078\n",
      "Epoch [39/100], Loss: 0.0079\n",
      "Epoch [40/100], Loss: 0.0077\n",
      "Epoch [41/100], Loss: 0.0070\n",
      "Epoch [42/100], Loss: 0.0065\n",
      "Epoch [43/100], Loss: 0.0059\n",
      "Epoch [44/100], Loss: 0.0058\n",
      "Epoch [45/100], Loss: 0.0062\n",
      "Epoch [46/100], Loss: 0.0057\n",
      "Epoch [47/100], Loss: 0.0064\n",
      "Epoch [48/100], Loss: 0.0058\n",
      "Epoch [49/100], Loss: 0.0058\n",
      "Epoch [50/100], Loss: 0.0059\n",
      "Epoch [51/100], Loss: 0.0053\n",
      "Epoch [52/100], Loss: 0.0049\n",
      "Epoch [53/100], Loss: 0.0049\n",
      "Epoch [54/100], Loss: 0.0045\n",
      "Epoch [55/100], Loss: 0.0045\n",
      "Epoch [56/100], Loss: 0.0051\n",
      "Epoch [57/100], Loss: 0.0052\n",
      "Epoch [58/100], Loss: 0.0044\n",
      "Epoch [59/100], Loss: 0.0045\n",
      "Epoch [60/100], Loss: 0.0042\n",
      "Epoch [61/100], Loss: 0.0047\n",
      "Epoch [62/100], Loss: 0.0045\n",
      "Epoch [63/100], Loss: 0.0035\n",
      "Epoch [64/100], Loss: 0.0042\n",
      "Epoch [65/100], Loss: 0.0045\n",
      "Epoch [66/100], Loss: 0.0043\n",
      "Epoch [67/100], Loss: 0.0043\n",
      "Epoch [68/100], Loss: 0.0044\n",
      "Epoch [69/100], Loss: 0.0043\n",
      "Epoch [70/100], Loss: 0.0038\n",
      "Epoch [71/100], Loss: 0.0044\n",
      "Epoch [72/100], Loss: 0.0040\n",
      "Epoch [73/100], Loss: 0.0036\n",
      "Epoch [74/100], Loss: 0.0041\n",
      "Epoch [75/100], Loss: 0.0048\n",
      "Epoch [76/100], Loss: 0.0037\n",
      "Epoch [77/100], Loss: 0.0035\n",
      "Epoch [78/100], Loss: 0.0034\n",
      "Epoch [79/100], Loss: 0.0038\n",
      "Epoch [80/100], Loss: 0.0040\n",
      "Epoch [81/100], Loss: 0.0036\n",
      "Epoch [82/100], Loss: 0.0032\n",
      "Epoch [83/100], Loss: 0.0037\n",
      "Epoch [84/100], Loss: 0.0041\n",
      "Epoch [85/100], Loss: 0.0041\n",
      "Epoch [86/100], Loss: 0.0041\n",
      "Epoch [87/100], Loss: 0.0037\n",
      "Epoch [88/100], Loss: 0.0035\n",
      "Epoch [89/100], Loss: 0.0045\n",
      "Epoch [90/100], Loss: 0.0039\n",
      "Epoch [91/100], Loss: 0.0040\n",
      "Epoch [92/100], Loss: 0.0036\n",
      "Epoch [93/100], Loss: 0.0045\n",
      "Epoch [94/100], Loss: 0.0035\n",
      "Epoch [95/100], Loss: 0.0042\n",
      "Epoch [96/100], Loss: 0.0038\n",
      "Epoch [97/100], Loss: 0.0033\n",
      "Epoch [98/100], Loss: 0.0041\n",
      "Epoch [99/100], Loss: 0.0041\n",
      "Epoch [100/100], Loss: 0.0034\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(465.6977, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.57447052  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.57447, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1575\n",
      "Epoch [2/100], Loss: 0.1132\n",
      "Epoch [3/100], Loss: 0.1097\n",
      "Epoch [4/100], Loss: 0.1088\n",
      "Epoch [5/100], Loss: 0.1066\n",
      "Epoch [6/100], Loss: 0.1046\n",
      "Epoch [7/100], Loss: 0.1025\n",
      "Epoch [8/100], Loss: 0.1007\n",
      "Epoch [9/100], Loss: 0.0992\n",
      "Epoch [10/100], Loss: 0.0974\n",
      "Epoch [11/100], Loss: 0.0948\n",
      "Epoch [12/100], Loss: 0.0938\n",
      "Epoch [13/100], Loss: 0.0907\n",
      "Epoch [14/100], Loss: 0.0884\n",
      "Epoch [15/100], Loss: 0.0872\n",
      "Epoch [16/100], Loss: 0.0842\n",
      "Epoch [17/100], Loss: 0.0839\n",
      "Epoch [18/100], Loss: 0.0819\n",
      "Epoch [19/100], Loss: 0.0795\n",
      "Epoch [20/100], Loss: 0.0775\n",
      "Epoch [21/100], Loss: 0.0757\n",
      "Epoch [22/100], Loss: 0.0739\n",
      "Epoch [23/100], Loss: 0.0727\n",
      "Epoch [24/100], Loss: 0.0700\n",
      "Epoch [25/100], Loss: 0.0702\n",
      "Epoch [26/100], Loss: 0.0684\n",
      "Epoch [27/100], Loss: 0.0670\n",
      "Epoch [28/100], Loss: 0.0655\n",
      "Epoch [29/100], Loss: 0.0638\n",
      "Epoch [30/100], Loss: 0.0630\n",
      "Epoch [31/100], Loss: 0.0618\n",
      "Epoch [32/100], Loss: 0.0602\n",
      "Epoch [33/100], Loss: 0.0601\n",
      "Epoch [34/100], Loss: 0.0581\n",
      "Epoch [35/100], Loss: 0.0585\n",
      "Epoch [36/100], Loss: 0.0564\n",
      "Epoch [37/100], Loss: 0.0555\n",
      "Epoch [38/100], Loss: 0.0531\n",
      "Epoch [39/100], Loss: 0.0529\n",
      "Epoch [40/100], Loss: 0.0535\n",
      "Epoch [41/100], Loss: 0.0536\n",
      "Epoch [42/100], Loss: 0.0505\n",
      "Epoch [43/100], Loss: 0.0495\n",
      "Epoch [44/100], Loss: 0.0512\n",
      "Epoch [45/100], Loss: 0.0474\n",
      "Epoch [46/100], Loss: 0.0498\n",
      "Epoch [47/100], Loss: 0.0486\n",
      "Epoch [48/100], Loss: 0.0477\n",
      "Epoch [49/100], Loss: 0.0457\n",
      "Epoch [50/100], Loss: 0.0465\n",
      "Epoch [51/100], Loss: 0.0451\n",
      "Epoch [52/100], Loss: 0.0450\n",
      "Epoch [53/100], Loss: 0.0442\n",
      "Epoch [54/100], Loss: 0.0418\n",
      "Epoch [55/100], Loss: 0.0424\n",
      "Epoch [56/100], Loss: 0.0409\n",
      "Epoch [57/100], Loss: 0.0416\n",
      "Epoch [58/100], Loss: 0.0420\n",
      "Epoch [59/100], Loss: 0.0416\n",
      "Epoch [60/100], Loss: 0.0405\n",
      "Epoch [61/100], Loss: 0.0415\n",
      "Epoch [62/100], Loss: 0.0400\n",
      "Epoch [63/100], Loss: 0.0374\n",
      "Epoch [64/100], Loss: 0.0376\n",
      "Epoch [65/100], Loss: 0.0378\n",
      "Epoch [66/100], Loss: 0.0377\n",
      "Epoch [67/100], Loss: 0.0368\n",
      "Epoch [68/100], Loss: 0.0375\n",
      "Epoch [69/100], Loss: 0.0368\n",
      "Epoch [70/100], Loss: 0.0357\n",
      "Epoch [71/100], Loss: 0.0356\n",
      "Epoch [72/100], Loss: 0.0374\n",
      "Epoch [73/100], Loss: 0.0355\n",
      "Epoch [74/100], Loss: 0.0336\n",
      "Epoch [75/100], Loss: 0.0355\n",
      "Epoch [76/100], Loss: 0.0348\n",
      "Epoch [77/100], Loss: 0.0339\n",
      "Epoch [78/100], Loss: 0.0328\n",
      "Epoch [79/100], Loss: 0.0328\n",
      "Epoch [80/100], Loss: 0.0319\n",
      "Epoch [81/100], Loss: 0.0325\n",
      "Epoch [82/100], Loss: 0.0324\n",
      "Epoch [83/100], Loss: 0.0332\n",
      "Epoch [84/100], Loss: 0.0328\n",
      "Epoch [85/100], Loss: 0.0316\n",
      "Epoch [86/100], Loss: 0.0326\n",
      "Epoch [87/100], Loss: 0.0328\n",
      "Epoch [88/100], Loss: 0.0318\n",
      "Epoch [89/100], Loss: 0.0320\n",
      "Epoch [90/100], Loss: 0.0324\n",
      "Epoch [91/100], Loss: 0.0321\n",
      "Epoch [92/100], Loss: 0.0308\n",
      "Epoch [93/100], Loss: 0.0298\n",
      "Epoch [94/100], Loss: 0.0299\n",
      "Epoch [95/100], Loss: 0.0294\n",
      "Epoch [96/100], Loss: 0.0295\n",
      "Epoch [97/100], Loss: 0.0306\n",
      "Epoch [98/100], Loss: 0.0274\n",
      "Epoch [99/100], Loss: 0.0309\n",
      "Epoch [100/100], Loss: 0.0284\n",
      "update data..\n",
      "task data norm and number entries: tensor(443.6553, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.57447052 93.77053833  0.          0.          0.        ]\n",
      "individual errors:  [array(96.4539, dtype=float32), array(91.087166, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1434\n",
      "Epoch [2/100], Loss: 0.1258\n",
      "Epoch [3/100], Loss: 0.1204\n",
      "Epoch [4/100], Loss: 0.1175\n",
      "Epoch [5/100], Loss: 0.1162\n",
      "Epoch [6/100], Loss: 0.1149\n",
      "Epoch [7/100], Loss: 0.1127\n",
      "Epoch [8/100], Loss: 0.1117\n",
      "Epoch [9/100], Loss: 0.1105\n",
      "Epoch [10/100], Loss: 0.1075\n",
      "Epoch [11/100], Loss: 0.1060\n",
      "Epoch [12/100], Loss: 0.1050\n",
      "Epoch [13/100], Loss: 0.1042\n",
      "Epoch [14/100], Loss: 0.1034\n",
      "Epoch [15/100], Loss: 0.1012\n",
      "Epoch [16/100], Loss: 0.0980\n",
      "Epoch [17/100], Loss: 0.0989\n",
      "Epoch [18/100], Loss: 0.0957\n",
      "Epoch [19/100], Loss: 0.0937\n",
      "Epoch [20/100], Loss: 0.0932\n",
      "Epoch [21/100], Loss: 0.0900\n",
      "Epoch [22/100], Loss: 0.0898\n",
      "Epoch [23/100], Loss: 0.0887\n",
      "Epoch [24/100], Loss: 0.0870\n",
      "Epoch [25/100], Loss: 0.0849\n",
      "Epoch [26/100], Loss: 0.0863\n",
      "Epoch [27/100], Loss: 0.0839\n",
      "Epoch [28/100], Loss: 0.0823\n",
      "Epoch [29/100], Loss: 0.0816\n",
      "Epoch [30/100], Loss: 0.0807\n",
      "Epoch [31/100], Loss: 0.0781\n",
      "Epoch [32/100], Loss: 0.0805\n",
      "Epoch [33/100], Loss: 0.0774\n",
      "Epoch [34/100], Loss: 0.0771\n",
      "Epoch [35/100], Loss: 0.0769\n",
      "Epoch [36/100], Loss: 0.0787\n",
      "Epoch [37/100], Loss: 0.0746\n",
      "Epoch [38/100], Loss: 0.0742\n",
      "Epoch [39/100], Loss: 0.0723\n",
      "Epoch [40/100], Loss: 0.0718\n",
      "Epoch [41/100], Loss: 0.0718\n",
      "Epoch [42/100], Loss: 0.0705\n",
      "Epoch [43/100], Loss: 0.0701\n",
      "Epoch [44/100], Loss: 0.0686\n",
      "Epoch [45/100], Loss: 0.0670\n",
      "Epoch [46/100], Loss: 0.0673\n",
      "Epoch [47/100], Loss: 0.0681\n",
      "Epoch [48/100], Loss: 0.0665\n",
      "Epoch [49/100], Loss: 0.0655\n",
      "Epoch [50/100], Loss: 0.0642\n",
      "Epoch [51/100], Loss: 0.0643\n",
      "Epoch [52/100], Loss: 0.0636\n",
      "Epoch [53/100], Loss: 0.0609\n",
      "Epoch [54/100], Loss: 0.0632\n",
      "Epoch [55/100], Loss: 0.0650\n",
      "Epoch [56/100], Loss: 0.0606\n",
      "Epoch [57/100], Loss: 0.0634\n",
      "Epoch [58/100], Loss: 0.0583\n",
      "Epoch [59/100], Loss: 0.0618\n",
      "Epoch [60/100], Loss: 0.0595\n",
      "Epoch [61/100], Loss: 0.0587\n",
      "Epoch [62/100], Loss: 0.0601\n",
      "Epoch [63/100], Loss: 0.0583\n",
      "Epoch [64/100], Loss: 0.0594\n",
      "Epoch [65/100], Loss: 0.0572\n",
      "Epoch [66/100], Loss: 0.0567\n",
      "Epoch [67/100], Loss: 0.0588\n",
      "Epoch [68/100], Loss: 0.0557\n",
      "Epoch [69/100], Loss: 0.0541\n",
      "Epoch [70/100], Loss: 0.0544\n",
      "Epoch [71/100], Loss: 0.0564\n",
      "Epoch [72/100], Loss: 0.0536\n",
      "Epoch [73/100], Loss: 0.0541\n",
      "Epoch [74/100], Loss: 0.0553\n",
      "Epoch [75/100], Loss: 0.0546\n",
      "Epoch [76/100], Loss: 0.0551\n",
      "Epoch [77/100], Loss: 0.0531\n",
      "Epoch [78/100], Loss: 0.0516\n",
      "Epoch [79/100], Loss: 0.0544\n",
      "Epoch [80/100], Loss: 0.0541\n",
      "Epoch [81/100], Loss: 0.0527\n",
      "Epoch [82/100], Loss: 0.0524\n",
      "Epoch [83/100], Loss: 0.0513\n",
      "Epoch [84/100], Loss: 0.0494\n",
      "Epoch [85/100], Loss: 0.0505\n",
      "Epoch [86/100], Loss: 0.0515\n",
      "Epoch [87/100], Loss: 0.0511\n",
      "Epoch [88/100], Loss: 0.0512\n",
      "Epoch [89/100], Loss: 0.0516\n",
      "Epoch [90/100], Loss: 0.0500\n",
      "Epoch [91/100], Loss: 0.0500\n",
      "Epoch [92/100], Loss: 0.0491\n",
      "Epoch [93/100], Loss: 0.0478\n",
      "Epoch [94/100], Loss: 0.0469\n",
      "Epoch [95/100], Loss: 0.0478\n",
      "Epoch [96/100], Loss: 0.0498\n",
      "Epoch [97/100], Loss: 0.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Loss: 0.0462\n",
      "Epoch [99/100], Loss: 0.0464\n",
      "Epoch [100/100], Loss: 0.0466\n",
      "update data..\n",
      "task data norm and number entries: tensor(439.1483, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.57447052 93.77053833 88.57010651  0.          0.        ]\n",
      "individual errors:  [array(96.26478, dtype=float32), array(84.28011, dtype=float32), array(85.16542, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1443\n",
      "Epoch [2/100], Loss: 0.1264\n",
      "Epoch [3/100], Loss: 0.1240\n",
      "Epoch [4/100], Loss: 0.1218\n",
      "Epoch [5/100], Loss: 0.1200\n",
      "Epoch [6/100], Loss: 0.1193\n",
      "Epoch [7/100], Loss: 0.1176\n",
      "Epoch [8/100], Loss: 0.1147\n",
      "Epoch [9/100], Loss: 0.1136\n",
      "Epoch [10/100], Loss: 0.1122\n",
      "Epoch [11/100], Loss: 0.1100\n",
      "Epoch [12/100], Loss: 0.1079\n",
      "Epoch [13/100], Loss: 0.1067\n",
      "Epoch [14/100], Loss: 0.1037\n",
      "Epoch [15/100], Loss: 0.1027\n",
      "Epoch [16/100], Loss: 0.1004\n",
      "Epoch [17/100], Loss: 0.0992\n",
      "Epoch [18/100], Loss: 0.0985\n",
      "Epoch [19/100], Loss: 0.0959\n",
      "Epoch [20/100], Loss: 0.0957\n",
      "Epoch [21/100], Loss: 0.0936\n",
      "Epoch [22/100], Loss: 0.0918\n",
      "Epoch [23/100], Loss: 0.0910\n",
      "Epoch [24/100], Loss: 0.0878\n",
      "Epoch [25/100], Loss: 0.0880\n",
      "Epoch [26/100], Loss: 0.0854\n",
      "Epoch [27/100], Loss: 0.0845\n",
      "Epoch [28/100], Loss: 0.0841\n",
      "Epoch [29/100], Loss: 0.0822\n",
      "Epoch [30/100], Loss: 0.0809\n",
      "Epoch [31/100], Loss: 0.0805\n",
      "Epoch [32/100], Loss: 0.0776\n",
      "Epoch [33/100], Loss: 0.0777\n",
      "Epoch [34/100], Loss: 0.0760\n",
      "Epoch [35/100], Loss: 0.0754\n",
      "Epoch [36/100], Loss: 0.0732\n",
      "Epoch [37/100], Loss: 0.0730\n",
      "Epoch [38/100], Loss: 0.0722\n",
      "Epoch [39/100], Loss: 0.0718\n",
      "Epoch [40/100], Loss: 0.0700\n",
      "Epoch [41/100], Loss: 0.0691\n",
      "Epoch [42/100], Loss: 0.0693\n",
      "Epoch [43/100], Loss: 0.0678\n",
      "Epoch [44/100], Loss: 0.0679\n",
      "Epoch [45/100], Loss: 0.0664\n",
      "Epoch [46/100], Loss: 0.0639\n",
      "Epoch [47/100], Loss: 0.0637\n",
      "Epoch [48/100], Loss: 0.0646\n",
      "Epoch [49/100], Loss: 0.0642\n",
      "Epoch [50/100], Loss: 0.0612\n",
      "Epoch [51/100], Loss: 0.0628\n",
      "Epoch [52/100], Loss: 0.0614\n",
      "Epoch [53/100], Loss: 0.0609\n",
      "Epoch [54/100], Loss: 0.0601\n",
      "Epoch [55/100], Loss: 0.0584\n",
      "Epoch [56/100], Loss: 0.0596\n",
      "Epoch [57/100], Loss: 0.0596\n",
      "Epoch [58/100], Loss: 0.0586\n",
      "Epoch [59/100], Loss: 0.0597\n",
      "Epoch [60/100], Loss: 0.0567\n",
      "Epoch [61/100], Loss: 0.0556\n",
      "Epoch [62/100], Loss: 0.0559\n",
      "Epoch [63/100], Loss: 0.0555\n",
      "Epoch [64/100], Loss: 0.0556\n",
      "Epoch [65/100], Loss: 0.0546\n",
      "Epoch [66/100], Loss: 0.0531\n",
      "Epoch [67/100], Loss: 0.0519\n",
      "Epoch [68/100], Loss: 0.0524\n",
      "Epoch [69/100], Loss: 0.0524\n",
      "Epoch [70/100], Loss: 0.0520\n",
      "Epoch [71/100], Loss: 0.0512\n",
      "Epoch [72/100], Loss: 0.0518\n",
      "Epoch [73/100], Loss: 0.0492\n",
      "Epoch [74/100], Loss: 0.0513\n",
      "Epoch [75/100], Loss: 0.0506\n",
      "Epoch [76/100], Loss: 0.0489\n",
      "Epoch [77/100], Loss: 0.0484\n",
      "Epoch [78/100], Loss: 0.0484\n",
      "Epoch [79/100], Loss: 0.0480\n",
      "Epoch [80/100], Loss: 0.0483\n",
      "Epoch [81/100], Loss: 0.0483\n",
      "Epoch [82/100], Loss: 0.0485\n",
      "Epoch [83/100], Loss: 0.0476\n",
      "Epoch [84/100], Loss: 0.0452\n",
      "Epoch [85/100], Loss: 0.0484\n",
      "Epoch [86/100], Loss: 0.0480\n",
      "Epoch [87/100], Loss: 0.0473\n",
      "Epoch [88/100], Loss: 0.0448\n",
      "Epoch [89/100], Loss: 0.0458\n",
      "Epoch [90/100], Loss: 0.0448\n",
      "Epoch [91/100], Loss: 0.0433\n",
      "Epoch [92/100], Loss: 0.0434\n",
      "Epoch [93/100], Loss: 0.0444\n",
      "Epoch [94/100], Loss: 0.0428\n",
      "Epoch [95/100], Loss: 0.0449\n",
      "Epoch [96/100], Loss: 0.0429\n",
      "Epoch [97/100], Loss: 0.0432\n",
      "Epoch [98/100], Loss: 0.0433\n",
      "Epoch [99/100], Loss: 0.0419\n",
      "Epoch [100/100], Loss: 0.0419\n",
      "update data..\n",
      "task data norm and number entries: tensor(453.8499, device='cuda:0') torch.Size([200, 31370])\n",
      "..done\n",
      "test performance :  [99.57447052 93.77053833 88.57010651 85.4095993   0.        ]\n",
      "individual errors:  [array(95.41371, dtype=float32), array(75.66112, dtype=float32), array(78.92209, dtype=float32), array(91.64149, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1358\n",
      "Epoch [2/100], Loss: 0.1249\n",
      "Epoch [3/100], Loss: 0.1230\n",
      "Epoch [4/100], Loss: 0.1221\n",
      "Epoch [5/100], Loss: 0.1208\n",
      "Epoch [6/100], Loss: 0.1211\n",
      "Epoch [7/100], Loss: 0.1193\n",
      "Epoch [8/100], Loss: 0.1171\n",
      "Epoch [9/100], Loss: 0.1176\n",
      "Epoch [10/100], Loss: 0.1151\n",
      "Epoch [11/100], Loss: 0.1148\n",
      "Epoch [12/100], Loss: 0.1139\n",
      "Epoch [13/100], Loss: 0.1133\n",
      "Epoch [14/100], Loss: 0.1113\n",
      "Epoch [15/100], Loss: 0.1101\n",
      "Epoch [16/100], Loss: 0.1102\n",
      "Epoch [17/100], Loss: 0.1081\n",
      "Epoch [18/100], Loss: 0.1080\n",
      "Epoch [19/100], Loss: 0.1066\n",
      "Epoch [20/100], Loss: 0.1070\n",
      "Epoch [21/100], Loss: 0.1049\n",
      "Epoch [22/100], Loss: 0.1034\n",
      "Epoch [23/100], Loss: 0.1036\n",
      "Epoch [24/100], Loss: 0.1032\n",
      "Epoch [25/100], Loss: 0.1009\n",
      "Epoch [26/100], Loss: 0.1011\n",
      "Epoch [27/100], Loss: 0.1007\n",
      "Epoch [28/100], Loss: 0.0998\n",
      "Epoch [29/100], Loss: 0.0989\n",
      "Epoch [30/100], Loss: 0.0978\n",
      "Epoch [31/100], Loss: 0.0979\n",
      "Epoch [32/100], Loss: 0.0975\n",
      "Epoch [33/100], Loss: 0.0969\n",
      "Epoch [34/100], Loss: 0.0950\n",
      "Epoch [35/100], Loss: 0.0946\n",
      "Epoch [36/100], Loss: 0.0945\n",
      "Epoch [37/100], Loss: 0.0929\n",
      "Epoch [38/100], Loss: 0.0924\n",
      "Epoch [39/100], Loss: 0.0938\n",
      "Epoch [40/100], Loss: 0.0903\n",
      "Epoch [41/100], Loss: 0.0910\n",
      "Epoch [42/100], Loss: 0.0914\n",
      "Epoch [43/100], Loss: 0.0898\n",
      "Epoch [44/100], Loss: 0.0890\n",
      "Epoch [45/100], Loss: 0.0911\n",
      "Epoch [46/100], Loss: 0.0897\n",
      "Epoch [47/100], Loss: 0.0891\n",
      "Epoch [48/100], Loss: 0.0877\n",
      "Epoch [49/100], Loss: 0.0882\n",
      "Epoch [50/100], Loss: 0.0853\n",
      "Epoch [51/100], Loss: 0.0861\n",
      "Epoch [52/100], Loss: 0.0863\n",
      "Epoch [53/100], Loss: 0.0869\n",
      "Epoch [54/100], Loss: 0.0850\n",
      "Epoch [55/100], Loss: 0.0837\n",
      "Epoch [56/100], Loss: 0.0852\n",
      "Epoch [57/100], Loss: 0.0847\n",
      "Epoch [58/100], Loss: 0.0822\n",
      "Epoch [59/100], Loss: 0.0849\n",
      "Epoch [60/100], Loss: 0.0828\n",
      "Epoch [61/100], Loss: 0.0826\n",
      "Epoch [62/100], Loss: 0.0816\n",
      "Epoch [63/100], Loss: 0.0803\n",
      "Epoch [64/100], Loss: 0.0837\n",
      "Epoch [65/100], Loss: 0.0813\n",
      "Epoch [66/100], Loss: 0.0801\n",
      "Epoch [67/100], Loss: 0.0811\n",
      "Epoch [68/100], Loss: 0.0814\n",
      "Epoch [69/100], Loss: 0.0795\n",
      "Epoch [70/100], Loss: 0.0823\n",
      "Epoch [71/100], Loss: 0.0813\n",
      "Epoch [72/100], Loss: 0.0785\n",
      "Epoch [73/100], Loss: 0.0791\n",
      "Epoch [74/100], Loss: 0.0784\n",
      "Epoch [75/100], Loss: 0.0783\n",
      "Epoch [76/100], Loss: 0.0794\n",
      "Epoch [77/100], Loss: 0.0786\n",
      "Epoch [78/100], Loss: 0.0789\n",
      "Epoch [79/100], Loss: 0.0765\n",
      "Epoch [80/100], Loss: 0.0747\n",
      "Epoch [81/100], Loss: 0.0765\n",
      "Epoch [82/100], Loss: 0.0746\n",
      "Epoch [83/100], Loss: 0.0760\n",
      "Epoch [84/100], Loss: 0.0759\n",
      "Epoch [85/100], Loss: 0.0744\n",
      "Epoch [86/100], Loss: 0.0760\n",
      "Epoch [87/100], Loss: 0.0745\n",
      "Epoch [88/100], Loss: 0.0746\n",
      "Epoch [89/100], Loss: 0.0743\n",
      "Epoch [90/100], Loss: 0.0759\n",
      "Epoch [91/100], Loss: 0.0743\n",
      "Epoch [92/100], Loss: 0.0736\n",
      "Epoch [93/100], Loss: 0.0746\n",
      "Epoch [94/100], Loss: 0.0731\n",
      "Epoch [95/100], Loss: 0.0745\n",
      "Epoch [96/100], Loss: 0.0743\n",
      "Epoch [97/100], Loss: 0.0723\n",
      "Epoch [98/100], Loss: 0.0725\n",
      "Epoch [99/100], Loss: 0.0706\n",
      "Epoch [100/100], Loss: 0.0724\n",
      "test performance :  [99.57447052 93.77053833 88.57010651 85.4095993  80.14633179]\n",
      "individual errors:  [array(95.08274, dtype=float32), array(74.926544, dtype=float32), array(61.419422, dtype=float32), array(90.735146, dtype=float32), array(78.567825, dtype=float32)]\n",
      "EWC++  400 1e-05\n",
      "Epoch [1/100], Loss: 0.0991\n",
      "Epoch [2/100], Loss: 0.0503\n",
      "Epoch [3/100], Loss: 0.0484\n",
      "Epoch [4/100], Loss: 0.0465\n",
      "Epoch [5/100], Loss: 0.0451\n",
      "Epoch [6/100], Loss: 0.0437\n",
      "Epoch [7/100], Loss: 0.0417\n",
      "Epoch [8/100], Loss: 0.0401\n",
      "Epoch [9/100], Loss: 0.0383\n",
      "Epoch [10/100], Loss: 0.0369\n",
      "Epoch [11/100], Loss: 0.0354\n",
      "Epoch [12/100], Loss: 0.0336\n",
      "Epoch [13/100], Loss: 0.0323\n",
      "Epoch [14/100], Loss: 0.0306\n",
      "Epoch [15/100], Loss: 0.0286\n",
      "Epoch [16/100], Loss: 0.0275\n",
      "Epoch [17/100], Loss: 0.0263\n",
      "Epoch [18/100], Loss: 0.0244\n",
      "Epoch [19/100], Loss: 0.0232\n",
      "Epoch [20/100], Loss: 0.0229\n",
      "Epoch [21/100], Loss: 0.0207\n",
      "Epoch [22/100], Loss: 0.0203\n",
      "Epoch [23/100], Loss: 0.0196\n",
      "Epoch [24/100], Loss: 0.0183\n",
      "Epoch [25/100], Loss: 0.0171\n",
      "Epoch [26/100], Loss: 0.0168\n",
      "Epoch [27/100], Loss: 0.0152\n",
      "Epoch [28/100], Loss: 0.0154\n",
      "Epoch [29/100], Loss: 0.0138\n",
      "Epoch [30/100], Loss: 0.0135\n",
      "Epoch [31/100], Loss: 0.0128\n",
      "Epoch [32/100], Loss: 0.0118\n",
      "Epoch [33/100], Loss: 0.0118\n",
      "Epoch [34/100], Loss: 0.0107\n",
      "Epoch [35/100], Loss: 0.0102\n",
      "Epoch [36/100], Loss: 0.0094\n",
      "Epoch [37/100], Loss: 0.0095\n",
      "Epoch [38/100], Loss: 0.0097\n",
      "Epoch [39/100], Loss: 0.0083\n",
      "Epoch [40/100], Loss: 0.0086\n",
      "Epoch [41/100], Loss: 0.0092\n",
      "Epoch [42/100], Loss: 0.0075\n",
      "Epoch [43/100], Loss: 0.0073\n",
      "Epoch [44/100], Loss: 0.0069\n",
      "Epoch [45/100], Loss: 0.0068\n",
      "Epoch [46/100], Loss: 0.0070\n",
      "Epoch [47/100], Loss: 0.0066\n",
      "Epoch [48/100], Loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Loss: 0.0058\n",
      "Epoch [50/100], Loss: 0.0052\n",
      "Epoch [51/100], Loss: 0.0065\n",
      "Epoch [52/100], Loss: 0.0058\n",
      "Epoch [53/100], Loss: 0.0054\n",
      "Epoch [54/100], Loss: 0.0059\n",
      "Epoch [55/100], Loss: 0.0062\n",
      "Epoch [56/100], Loss: 0.0055\n",
      "Epoch [57/100], Loss: 0.0049\n",
      "Epoch [58/100], Loss: 0.0052\n",
      "Epoch [59/100], Loss: 0.0054\n",
      "Epoch [60/100], Loss: 0.0049\n",
      "Epoch [61/100], Loss: 0.0056\n",
      "Epoch [62/100], Loss: 0.0050\n",
      "Epoch [63/100], Loss: 0.0040\n",
      "Epoch [64/100], Loss: 0.0050\n",
      "Epoch [65/100], Loss: 0.0044\n",
      "Epoch [66/100], Loss: 0.0046\n",
      "Epoch [67/100], Loss: 0.0045\n",
      "Epoch [68/100], Loss: 0.0046\n",
      "Epoch [69/100], Loss: 0.0043\n",
      "Epoch [70/100], Loss: 0.0048\n",
      "Epoch [71/100], Loss: 0.0044\n",
      "Epoch [72/100], Loss: 0.0046\n",
      "Epoch [73/100], Loss: 0.0046\n",
      "Epoch [74/100], Loss: 0.0044\n",
      "Epoch [75/100], Loss: 0.0046\n",
      "Epoch [76/100], Loss: 0.0041\n",
      "Epoch [77/100], Loss: 0.0036\n",
      "Epoch [78/100], Loss: 0.0041\n",
      "Epoch [79/100], Loss: 0.0037\n",
      "Epoch [80/100], Loss: 0.0048\n",
      "Epoch [81/100], Loss: 0.0041\n",
      "Epoch [82/100], Loss: 0.0047\n",
      "Epoch [83/100], Loss: 0.0044\n",
      "Epoch [84/100], Loss: 0.0046\n",
      "Epoch [85/100], Loss: 0.0046\n",
      "Epoch [86/100], Loss: 0.0040\n",
      "Epoch [87/100], Loss: 0.0037\n",
      "Epoch [88/100], Loss: 0.0038\n",
      "Epoch [89/100], Loss: 0.0038\n",
      "Epoch [90/100], Loss: 0.0043\n",
      "Epoch [91/100], Loss: 0.0048\n",
      "Epoch [92/100], Loss: 0.0040\n",
      "Epoch [93/100], Loss: 0.0042\n",
      "Epoch [94/100], Loss: 0.0039\n",
      "Epoch [95/100], Loss: 0.0044\n",
      "Epoch [96/100], Loss: 0.0033\n",
      "Epoch [97/100], Loss: 0.0040\n",
      "Epoch [98/100], Loss: 0.0034\n",
      "Epoch [99/100], Loss: 0.0037\n",
      "Epoch [100/100], Loss: 0.0038\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(452.6159, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.66903, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1549\n",
      "Epoch [2/100], Loss: 0.1079\n",
      "Epoch [3/100], Loss: 0.1064\n",
      "Epoch [4/100], Loss: 0.1042\n",
      "Epoch [5/100], Loss: 0.1023\n",
      "Epoch [6/100], Loss: 0.1015\n",
      "Epoch [7/100], Loss: 0.0998\n",
      "Epoch [8/100], Loss: 0.0976\n",
      "Epoch [9/100], Loss: 0.0966\n",
      "Epoch [10/100], Loss: 0.0950\n",
      "Epoch [11/100], Loss: 0.0939\n",
      "Epoch [12/100], Loss: 0.0919\n",
      "Epoch [13/100], Loss: 0.0896\n",
      "Epoch [14/100], Loss: 0.0887\n",
      "Epoch [15/100], Loss: 0.0875\n",
      "Epoch [16/100], Loss: 0.0854\n",
      "Epoch [17/100], Loss: 0.0848\n",
      "Epoch [18/100], Loss: 0.0831\n",
      "Epoch [19/100], Loss: 0.0813\n",
      "Epoch [20/100], Loss: 0.0796\n",
      "Epoch [21/100], Loss: 0.0783\n",
      "Epoch [22/100], Loss: 0.0775\n",
      "Epoch [23/100], Loss: 0.0750\n",
      "Epoch [24/100], Loss: 0.0735\n",
      "Epoch [25/100], Loss: 0.0729\n",
      "Epoch [26/100], Loss: 0.0722\n",
      "Epoch [27/100], Loss: 0.0710\n",
      "Epoch [28/100], Loss: 0.0701\n",
      "Epoch [29/100], Loss: 0.0680\n",
      "Epoch [30/100], Loss: 0.0675\n",
      "Epoch [31/100], Loss: 0.0679\n",
      "Epoch [32/100], Loss: 0.0654\n",
      "Epoch [33/100], Loss: 0.0646\n",
      "Epoch [34/100], Loss: 0.0626\n",
      "Epoch [35/100], Loss: 0.0617\n",
      "Epoch [36/100], Loss: 0.0602\n",
      "Epoch [37/100], Loss: 0.0600\n",
      "Epoch [38/100], Loss: 0.0591\n",
      "Epoch [39/100], Loss: 0.0572\n",
      "Epoch [40/100], Loss: 0.0574\n",
      "Epoch [41/100], Loss: 0.0563\n",
      "Epoch [42/100], Loss: 0.0555\n",
      "Epoch [43/100], Loss: 0.0555\n",
      "Epoch [44/100], Loss: 0.0538\n",
      "Epoch [45/100], Loss: 0.0545\n",
      "Epoch [46/100], Loss: 0.0538\n",
      "Epoch [47/100], Loss: 0.0520\n",
      "Epoch [48/100], Loss: 0.0516\n",
      "Epoch [49/100], Loss: 0.0511\n",
      "Epoch [50/100], Loss: 0.0515\n",
      "Epoch [51/100], Loss: 0.0496\n",
      "Epoch [52/100], Loss: 0.0494\n",
      "Epoch [53/100], Loss: 0.0497\n",
      "Epoch [54/100], Loss: 0.0479\n",
      "Epoch [55/100], Loss: 0.0471\n",
      "Epoch [56/100], Loss: 0.0476\n",
      "Epoch [57/100], Loss: 0.0473\n",
      "Epoch [58/100], Loss: 0.0466\n",
      "Epoch [59/100], Loss: 0.0469\n",
      "Epoch [60/100], Loss: 0.0457\n",
      "Epoch [61/100], Loss: 0.0457\n",
      "Epoch [62/100], Loss: 0.0438\n",
      "Epoch [63/100], Loss: 0.0456\n",
      "Epoch [64/100], Loss: 0.0445\n",
      "Epoch [65/100], Loss: 0.0447\n",
      "Epoch [66/100], Loss: 0.0432\n",
      "Epoch [67/100], Loss: 0.0429\n",
      "Epoch [68/100], Loss: 0.0425\n",
      "Epoch [69/100], Loss: 0.0430\n",
      "Epoch [70/100], Loss: 0.0424\n",
      "Epoch [71/100], Loss: 0.0394\n",
      "Epoch [72/100], Loss: 0.0420\n",
      "Epoch [73/100], Loss: 0.0414\n",
      "Epoch [74/100], Loss: 0.0406\n",
      "Epoch [75/100], Loss: 0.0422\n",
      "Epoch [76/100], Loss: 0.0389\n",
      "Epoch [77/100], Loss: 0.0379\n",
      "Epoch [78/100], Loss: 0.0392\n",
      "Epoch [79/100], Loss: 0.0399\n",
      "Epoch [80/100], Loss: 0.0409\n",
      "Epoch [81/100], Loss: 0.0384\n",
      "Epoch [82/100], Loss: 0.0395\n",
      "Epoch [83/100], Loss: 0.0408\n",
      "Epoch [84/100], Loss: 0.0406\n",
      "Epoch [85/100], Loss: 0.0389\n",
      "Epoch [86/100], Loss: 0.0398\n",
      "Epoch [87/100], Loss: 0.0384\n",
      "Epoch [88/100], Loss: 0.0368\n",
      "Epoch [89/100], Loss: 0.0381\n",
      "Epoch [90/100], Loss: 0.0376\n",
      "Epoch [91/100], Loss: 0.0360\n",
      "Epoch [92/100], Loss: 0.0350\n",
      "Epoch [93/100], Loss: 0.0371\n",
      "Epoch [94/100], Loss: 0.0362\n",
      "Epoch [95/100], Loss: 0.0357\n",
      "Epoch [96/100], Loss: 0.0355\n",
      "Epoch [97/100], Loss: 0.0362\n",
      "Epoch [98/100], Loss: 0.0360\n",
      "Epoch [99/100], Loss: 0.0356\n",
      "Epoch [100/100], Loss: 0.0342\n",
      "update data..\n",
      "task data norm and number entries: tensor(445.9623, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924 93.84735107  0.          0.          0.        ]\n",
      "individual errors:  [array(97.63593, dtype=float32), array(90.05876, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1463\n",
      "Epoch [2/100], Loss: 0.1234\n",
      "Epoch [3/100], Loss: 0.1214\n",
      "Epoch [4/100], Loss: 0.1192\n",
      "Epoch [5/100], Loss: 0.1181\n",
      "Epoch [6/100], Loss: 0.1172\n",
      "Epoch [7/100], Loss: 0.1153\n",
      "Epoch [8/100], Loss: 0.1139\n",
      "Epoch [9/100], Loss: 0.1128\n",
      "Epoch [10/100], Loss: 0.1101\n",
      "Epoch [11/100], Loss: 0.1088\n",
      "Epoch [12/100], Loss: 0.1067\n",
      "Epoch [13/100], Loss: 0.1058\n",
      "Epoch [14/100], Loss: 0.1039\n",
      "Epoch [15/100], Loss: 0.1025\n",
      "Epoch [16/100], Loss: 0.1013\n",
      "Epoch [17/100], Loss: 0.0998\n",
      "Epoch [18/100], Loss: 0.0973\n",
      "Epoch [19/100], Loss: 0.0974\n",
      "Epoch [20/100], Loss: 0.0950\n",
      "Epoch [21/100], Loss: 0.0950\n",
      "Epoch [22/100], Loss: 0.0915\n",
      "Epoch [23/100], Loss: 0.0902\n",
      "Epoch [24/100], Loss: 0.0897\n",
      "Epoch [25/100], Loss: 0.0889\n",
      "Epoch [26/100], Loss: 0.0878\n",
      "Epoch [27/100], Loss: 0.0872\n",
      "Epoch [28/100], Loss: 0.0851\n",
      "Epoch [29/100], Loss: 0.0847\n",
      "Epoch [30/100], Loss: 0.0823\n",
      "Epoch [31/100], Loss: 0.0830\n",
      "Epoch [32/100], Loss: 0.0823\n",
      "Epoch [33/100], Loss: 0.0811\n",
      "Epoch [34/100], Loss: 0.0792\n",
      "Epoch [35/100], Loss: 0.0784\n",
      "Epoch [36/100], Loss: 0.0779\n",
      "Epoch [37/100], Loss: 0.0754\n",
      "Epoch [38/100], Loss: 0.0768\n",
      "Epoch [39/100], Loss: 0.0770\n",
      "Epoch [40/100], Loss: 0.0749\n",
      "Epoch [41/100], Loss: 0.0747\n",
      "Epoch [42/100], Loss: 0.0728\n",
      "Epoch [43/100], Loss: 0.0723\n",
      "Epoch [44/100], Loss: 0.0716\n",
      "Epoch [45/100], Loss: 0.0710\n",
      "Epoch [46/100], Loss: 0.0712\n",
      "Epoch [47/100], Loss: 0.0699\n",
      "Epoch [48/100], Loss: 0.0690\n",
      "Epoch [49/100], Loss: 0.0683\n",
      "Epoch [50/100], Loss: 0.0673\n",
      "Epoch [51/100], Loss: 0.0680\n",
      "Epoch [52/100], Loss: 0.0679\n",
      "Epoch [53/100], Loss: 0.0673\n",
      "Epoch [54/100], Loss: 0.0650\n",
      "Epoch [55/100], Loss: 0.0638\n",
      "Epoch [56/100], Loss: 0.0634\n",
      "Epoch [57/100], Loss: 0.0630\n",
      "Epoch [58/100], Loss: 0.0634\n",
      "Epoch [59/100], Loss: 0.0619\n",
      "Epoch [60/100], Loss: 0.0632\n",
      "Epoch [61/100], Loss: 0.0634\n",
      "Epoch [62/100], Loss: 0.0630\n",
      "Epoch [63/100], Loss: 0.0607\n",
      "Epoch [64/100], Loss: 0.0623\n",
      "Epoch [65/100], Loss: 0.0608\n",
      "Epoch [66/100], Loss: 0.0601\n",
      "Epoch [67/100], Loss: 0.0605\n",
      "Epoch [68/100], Loss: 0.0609\n",
      "Epoch [69/100], Loss: 0.0591\n",
      "Epoch [70/100], Loss: 0.0596\n",
      "Epoch [71/100], Loss: 0.0573\n",
      "Epoch [72/100], Loss: 0.0603\n",
      "Epoch [73/100], Loss: 0.0576\n",
      "Epoch [74/100], Loss: 0.0568\n",
      "Epoch [75/100], Loss: 0.0566\n",
      "Epoch [76/100], Loss: 0.0579\n",
      "Epoch [77/100], Loss: 0.0560\n",
      "Epoch [78/100], Loss: 0.0563\n",
      "Epoch [79/100], Loss: 0.0574\n",
      "Epoch [80/100], Loss: 0.0545\n",
      "Epoch [81/100], Loss: 0.0563\n",
      "Epoch [82/100], Loss: 0.0537\n",
      "Epoch [83/100], Loss: 0.0538\n",
      "Epoch [84/100], Loss: 0.0538\n",
      "Epoch [85/100], Loss: 0.0536\n",
      "Epoch [86/100], Loss: 0.0531\n",
      "Epoch [87/100], Loss: 0.0558\n",
      "Epoch [88/100], Loss: 0.0535\n",
      "Epoch [89/100], Loss: 0.0539\n",
      "Epoch [90/100], Loss: 0.0534\n",
      "Epoch [91/100], Loss: 0.0531\n",
      "Epoch [92/100], Loss: 0.0528\n",
      "Epoch [93/100], Loss: 0.0535\n",
      "Epoch [94/100], Loss: 0.0513\n",
      "Epoch [95/100], Loss: 0.0517\n",
      "Epoch [96/100], Loss: 0.0539\n",
      "Epoch [97/100], Loss: 0.0503\n",
      "Epoch [98/100], Loss: 0.0512\n",
      "Epoch [99/100], Loss: 0.0504\n",
      "Epoch [100/100], Loss: 0.0515\n",
      "update data..\n",
      "task data norm and number entries: tensor(430.7174, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924 93.84735107 89.40408325  0.          0.        ]\n",
      "individual errors:  [array(96.73759, dtype=float32), array(85.45544, dtype=float32), array(86.01921, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1408\n",
      "Epoch [2/100], Loss: 0.1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 0.1226\n",
      "Epoch [4/100], Loss: 0.1198\n",
      "Epoch [5/100], Loss: 0.1181\n",
      "Epoch [6/100], Loss: 0.1174\n",
      "Epoch [7/100], Loss: 0.1159\n",
      "Epoch [8/100], Loss: 0.1131\n",
      "Epoch [9/100], Loss: 0.1116\n",
      "Epoch [10/100], Loss: 0.1095\n",
      "Epoch [11/100], Loss: 0.1082\n",
      "Epoch [12/100], Loss: 0.1062\n",
      "Epoch [13/100], Loss: 0.1043\n",
      "Epoch [14/100], Loss: 0.1029\n",
      "Epoch [15/100], Loss: 0.1009\n",
      "Epoch [16/100], Loss: 0.0995\n",
      "Epoch [17/100], Loss: 0.0982\n",
      "Epoch [18/100], Loss: 0.0960\n",
      "Epoch [19/100], Loss: 0.0946\n",
      "Epoch [20/100], Loss: 0.0936\n",
      "Epoch [21/100], Loss: 0.0925\n",
      "Epoch [22/100], Loss: 0.0894\n",
      "Epoch [23/100], Loss: 0.0892\n",
      "Epoch [24/100], Loss: 0.0879\n",
      "Epoch [25/100], Loss: 0.0860\n",
      "Epoch [26/100], Loss: 0.0854\n",
      "Epoch [27/100], Loss: 0.0846\n",
      "Epoch [28/100], Loss: 0.0821\n",
      "Epoch [29/100], Loss: 0.0812\n",
      "Epoch [30/100], Loss: 0.0795\n",
      "Epoch [31/100], Loss: 0.0809\n",
      "Epoch [32/100], Loss: 0.0779\n",
      "Epoch [33/100], Loss: 0.0765\n",
      "Epoch [34/100], Loss: 0.0762\n",
      "Epoch [35/100], Loss: 0.0753\n",
      "Epoch [36/100], Loss: 0.0753\n",
      "Epoch [37/100], Loss: 0.0730\n",
      "Epoch [38/100], Loss: 0.0723\n",
      "Epoch [39/100], Loss: 0.0715\n",
      "Epoch [40/100], Loss: 0.0723\n",
      "Epoch [41/100], Loss: 0.0706\n",
      "Epoch [42/100], Loss: 0.0704\n",
      "Epoch [43/100], Loss: 0.0694\n",
      "Epoch [44/100], Loss: 0.0684\n",
      "Epoch [45/100], Loss: 0.0681\n",
      "Epoch [46/100], Loss: 0.0668\n",
      "Epoch [47/100], Loss: 0.0658\n",
      "Epoch [48/100], Loss: 0.0685\n",
      "Epoch [49/100], Loss: 0.0645\n",
      "Epoch [50/100], Loss: 0.0653\n",
      "Epoch [51/100], Loss: 0.0631\n",
      "Epoch [52/100], Loss: 0.0647\n",
      "Epoch [53/100], Loss: 0.0634\n",
      "Epoch [54/100], Loss: 0.0631\n",
      "Epoch [55/100], Loss: 0.0620\n",
      "Epoch [56/100], Loss: 0.0620\n",
      "Epoch [57/100], Loss: 0.0632\n",
      "Epoch [58/100], Loss: 0.0619\n",
      "Epoch [59/100], Loss: 0.0602\n",
      "Epoch [60/100], Loss: 0.0610\n",
      "Epoch [61/100], Loss: 0.0601\n",
      "Epoch [62/100], Loss: 0.0587\n",
      "Epoch [63/100], Loss: 0.0591\n",
      "Epoch [64/100], Loss: 0.0595\n",
      "Epoch [65/100], Loss: 0.0578\n",
      "Epoch [66/100], Loss: 0.0577\n",
      "Epoch [67/100], Loss: 0.0582\n",
      "Epoch [68/100], Loss: 0.0576\n",
      "Epoch [69/100], Loss: 0.0553\n",
      "Epoch [70/100], Loss: 0.0558\n",
      "Epoch [71/100], Loss: 0.0568\n",
      "Epoch [72/100], Loss: 0.0559\n",
      "Epoch [73/100], Loss: 0.0551\n",
      "Epoch [74/100], Loss: 0.0560\n",
      "Epoch [75/100], Loss: 0.0539\n",
      "Epoch [76/100], Loss: 0.0542\n",
      "Epoch [77/100], Loss: 0.0543\n",
      "Epoch [78/100], Loss: 0.0547\n",
      "Epoch [79/100], Loss: 0.0535\n",
      "Epoch [80/100], Loss: 0.0527\n",
      "Epoch [81/100], Loss: 0.0539\n",
      "Epoch [82/100], Loss: 0.0537\n",
      "Epoch [83/100], Loss: 0.0515\n",
      "Epoch [84/100], Loss: 0.0529\n",
      "Epoch [85/100], Loss: 0.0516\n",
      "Epoch [86/100], Loss: 0.0507\n",
      "Epoch [87/100], Loss: 0.0519\n",
      "Epoch [88/100], Loss: 0.0500\n",
      "Epoch [89/100], Loss: 0.0510\n",
      "Epoch [90/100], Loss: 0.0509\n",
      "Epoch [91/100], Loss: 0.0496\n",
      "Epoch [92/100], Loss: 0.0497\n",
      "Epoch [93/100], Loss: 0.0510\n",
      "Epoch [94/100], Loss: 0.0491\n",
      "Epoch [95/100], Loss: 0.0490\n",
      "Epoch [96/100], Loss: 0.0515\n",
      "Epoch [97/100], Loss: 0.0511\n",
      "Epoch [98/100], Loss: 0.0496\n",
      "Epoch [99/100], Loss: 0.0499\n",
      "Epoch [100/100], Loss: 0.0495\n",
      "update data..\n",
      "task data norm and number entries: tensor(447.7490, device='cuda:0') torch.Size([400, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924 93.84735107 89.40408325 86.91788483  0.        ]\n",
      "individual errors:  [array(95.79196, dtype=float32), array(81.831535, dtype=float32), array(78.70864, dtype=float32), array(91.33938, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1378\n",
      "Epoch [2/100], Loss: 0.1270\n",
      "Epoch [3/100], Loss: 0.1240\n",
      "Epoch [4/100], Loss: 0.1231\n",
      "Epoch [5/100], Loss: 0.1216\n",
      "Epoch [6/100], Loss: 0.1209\n",
      "Epoch [7/100], Loss: 0.1208\n",
      "Epoch [8/100], Loss: 0.1196\n",
      "Epoch [9/100], Loss: 0.1175\n",
      "Epoch [10/100], Loss: 0.1169\n",
      "Epoch [11/100], Loss: 0.1165\n",
      "Epoch [12/100], Loss: 0.1144\n",
      "Epoch [13/100], Loss: 0.1134\n",
      "Epoch [14/100], Loss: 0.1143\n",
      "Epoch [15/100], Loss: 0.1132\n",
      "Epoch [16/100], Loss: 0.1114\n",
      "Epoch [17/100], Loss: 0.1103\n",
      "Epoch [18/100], Loss: 0.1118\n",
      "Epoch [19/100], Loss: 0.1075\n",
      "Epoch [20/100], Loss: 0.1074\n",
      "Epoch [21/100], Loss: 0.1074\n",
      "Epoch [22/100], Loss: 0.1060\n",
      "Epoch [23/100], Loss: 0.1054\n",
      "Epoch [24/100], Loss: 0.1041\n",
      "Epoch [25/100], Loss: 0.1037\n",
      "Epoch [26/100], Loss: 0.1024\n",
      "Epoch [27/100], Loss: 0.1024\n",
      "Epoch [28/100], Loss: 0.1038\n",
      "Epoch [29/100], Loss: 0.1011\n",
      "Epoch [30/100], Loss: 0.1007\n",
      "Epoch [31/100], Loss: 0.0995\n",
      "Epoch [32/100], Loss: 0.1007\n",
      "Epoch [33/100], Loss: 0.0985\n",
      "Epoch [34/100], Loss: 0.0983\n",
      "Epoch [35/100], Loss: 0.0975\n",
      "Epoch [36/100], Loss: 0.0971\n",
      "Epoch [37/100], Loss: 0.0970\n",
      "Epoch [38/100], Loss: 0.0946\n",
      "Epoch [39/100], Loss: 0.0957\n",
      "Epoch [40/100], Loss: 0.0934\n",
      "Epoch [41/100], Loss: 0.0935\n",
      "Epoch [42/100], Loss: 0.0943\n",
      "Epoch [43/100], Loss: 0.0932\n",
      "Epoch [44/100], Loss: 0.0922\n",
      "Epoch [45/100], Loss: 0.0910\n",
      "Epoch [46/100], Loss: 0.0931\n",
      "Epoch [47/100], Loss: 0.0918\n",
      "Epoch [48/100], Loss: 0.0925\n",
      "Epoch [49/100], Loss: 0.0931\n",
      "Epoch [50/100], Loss: 0.0889\n",
      "Epoch [51/100], Loss: 0.0905\n",
      "Epoch [52/100], Loss: 0.0912\n",
      "Epoch [53/100], Loss: 0.0906\n",
      "Epoch [54/100], Loss: 0.0930\n",
      "Epoch [55/100], Loss: 0.0894\n",
      "Epoch [56/100], Loss: 0.0895\n",
      "Epoch [57/100], Loss: 0.0891\n",
      "Epoch [58/100], Loss: 0.0880\n",
      "Epoch [59/100], Loss: 0.0892\n",
      "Epoch [60/100], Loss: 0.0882\n",
      "Epoch [61/100], Loss: 0.0871\n",
      "Epoch [62/100], Loss: 0.0865\n",
      "Epoch [63/100], Loss: 0.0870\n",
      "Epoch [64/100], Loss: 0.0876\n",
      "Epoch [65/100], Loss: 0.0875\n",
      "Epoch [66/100], Loss: 0.0854\n",
      "Epoch [67/100], Loss: 0.0854\n",
      "Epoch [68/100], Loss: 0.0855\n",
      "Epoch [69/100], Loss: 0.0903\n",
      "Epoch [70/100], Loss: 0.0833\n",
      "Epoch [71/100], Loss: 0.0856\n",
      "Epoch [72/100], Loss: 0.0849\n",
      "Epoch [73/100], Loss: 0.0850\n",
      "Epoch [74/100], Loss: 0.0840\n",
      "Epoch [75/100], Loss: 0.0844\n",
      "Epoch [76/100], Loss: 0.0840\n",
      "Epoch [77/100], Loss: 0.0829\n",
      "Epoch [78/100], Loss: 0.0839\n",
      "Epoch [79/100], Loss: 0.0818\n",
      "Epoch [80/100], Loss: 0.0831\n",
      "Epoch [81/100], Loss: 0.0833\n",
      "Epoch [82/100], Loss: 0.0827\n",
      "Epoch [83/100], Loss: 0.0813\n",
      "Epoch [84/100], Loss: 0.0841\n",
      "Epoch [85/100], Loss: 0.0831\n",
      "Epoch [86/100], Loss: 0.0812\n",
      "Epoch [87/100], Loss: 0.0818\n",
      "Epoch [88/100], Loss: 0.0828\n",
      "Epoch [89/100], Loss: 0.0841\n",
      "Epoch [90/100], Loss: 0.0785\n",
      "Epoch [91/100], Loss: 0.0814\n",
      "Epoch [92/100], Loss: 0.0823\n",
      "Epoch [93/100], Loss: 0.0819\n",
      "Epoch [94/100], Loss: 0.0821\n",
      "Epoch [95/100], Loss: 0.0809\n",
      "Epoch [96/100], Loss: 0.0789\n",
      "Epoch [97/100], Loss: 0.0778\n",
      "Epoch [98/100], Loss: 0.0787\n",
      "Epoch [99/100], Loss: 0.0814\n",
      "Epoch [100/100], Loss: 0.0798\n",
      "test performance :  [99.66902924 93.84735107 89.40408325 86.91788483 82.57335663]\n",
      "individual errors:  [array(96.64303, dtype=float32), array(79.38296, dtype=float32), array(72.732124, dtype=float32), array(90.83585, dtype=float32), array(73.27282, dtype=float32)]\n",
      "EWC++  800 1e-05\n",
      "Epoch [1/100], Loss: 0.1025\n",
      "Epoch [2/100], Loss: 0.0505\n",
      "Epoch [3/100], Loss: 0.0479\n",
      "Epoch [4/100], Loss: 0.0465\n",
      "Epoch [5/100], Loss: 0.0449\n",
      "Epoch [6/100], Loss: 0.0427\n",
      "Epoch [7/100], Loss: 0.0421\n",
      "Epoch [8/100], Loss: 0.0405\n",
      "Epoch [9/100], Loss: 0.0385\n",
      "Epoch [10/100], Loss: 0.0370\n",
      "Epoch [11/100], Loss: 0.0353\n",
      "Epoch [12/100], Loss: 0.0339\n",
      "Epoch [13/100], Loss: 0.0322\n",
      "Epoch [14/100], Loss: 0.0309\n",
      "Epoch [15/100], Loss: 0.0289\n",
      "Epoch [16/100], Loss: 0.0279\n",
      "Epoch [17/100], Loss: 0.0259\n",
      "Epoch [18/100], Loss: 0.0246\n",
      "Epoch [19/100], Loss: 0.0228\n",
      "Epoch [20/100], Loss: 0.0221\n",
      "Epoch [21/100], Loss: 0.0212\n",
      "Epoch [22/100], Loss: 0.0209\n",
      "Epoch [23/100], Loss: 0.0191\n",
      "Epoch [24/100], Loss: 0.0180\n",
      "Epoch [25/100], Loss: 0.0173\n",
      "Epoch [26/100], Loss: 0.0163\n",
      "Epoch [27/100], Loss: 0.0146\n",
      "Epoch [28/100], Loss: 0.0144\n",
      "Epoch [29/100], Loss: 0.0140\n",
      "Epoch [30/100], Loss: 0.0127\n",
      "Epoch [31/100], Loss: 0.0122\n",
      "Epoch [32/100], Loss: 0.0111\n",
      "Epoch [33/100], Loss: 0.0110\n",
      "Epoch [34/100], Loss: 0.0103\n",
      "Epoch [35/100], Loss: 0.0101\n",
      "Epoch [36/100], Loss: 0.0103\n",
      "Epoch [37/100], Loss: 0.0092\n",
      "Epoch [38/100], Loss: 0.0089\n",
      "Epoch [39/100], Loss: 0.0077\n",
      "Epoch [40/100], Loss: 0.0079\n",
      "Epoch [41/100], Loss: 0.0076\n",
      "Epoch [42/100], Loss: 0.0077\n",
      "Epoch [43/100], Loss: 0.0075\n",
      "Epoch [44/100], Loss: 0.0065\n",
      "Epoch [45/100], Loss: 0.0074\n",
      "Epoch [46/100], Loss: 0.0067\n",
      "Epoch [47/100], Loss: 0.0067\n",
      "Epoch [48/100], Loss: 0.0067\n",
      "Epoch [49/100], Loss: 0.0069\n",
      "Epoch [50/100], Loss: 0.0063\n",
      "Epoch [51/100], Loss: 0.0062\n",
      "Epoch [52/100], Loss: 0.0056\n",
      "Epoch [53/100], Loss: 0.0054\n",
      "Epoch [54/100], Loss: 0.0046\n",
      "Epoch [55/100], Loss: 0.0056\n",
      "Epoch [56/100], Loss: 0.0056\n",
      "Epoch [57/100], Loss: 0.0045\n",
      "Epoch [58/100], Loss: 0.0056\n",
      "Epoch [59/100], Loss: 0.0051\n",
      "Epoch [60/100], Loss: 0.0053\n",
      "Epoch [61/100], Loss: 0.0051\n",
      "Epoch [62/100], Loss: 0.0045\n",
      "Epoch [63/100], Loss: 0.0048\n",
      "Epoch [64/100], Loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Loss: 0.0046\n",
      "Epoch [66/100], Loss: 0.0045\n",
      "Epoch [67/100], Loss: 0.0048\n",
      "Epoch [68/100], Loss: 0.0042\n",
      "Epoch [69/100], Loss: 0.0048\n",
      "Epoch [70/100], Loss: 0.0041\n",
      "Epoch [71/100], Loss: 0.0043\n",
      "Epoch [72/100], Loss: 0.0042\n",
      "Epoch [73/100], Loss: 0.0035\n",
      "Epoch [74/100], Loss: 0.0045\n",
      "Epoch [75/100], Loss: 0.0039\n",
      "Epoch [76/100], Loss: 0.0038\n",
      "Epoch [77/100], Loss: 0.0038\n",
      "Epoch [78/100], Loss: 0.0043\n",
      "Epoch [79/100], Loss: 0.0045\n",
      "Epoch [80/100], Loss: 0.0045\n",
      "Epoch [81/100], Loss: 0.0045\n",
      "Epoch [82/100], Loss: 0.0046\n",
      "Epoch [83/100], Loss: 0.0043\n",
      "Epoch [84/100], Loss: 0.0045\n",
      "Epoch [85/100], Loss: 0.0043\n",
      "Epoch [86/100], Loss: 0.0041\n",
      "Epoch [87/100], Loss: 0.0036\n",
      "Epoch [88/100], Loss: 0.0041\n",
      "Epoch [89/100], Loss: 0.0043\n",
      "Epoch [90/100], Loss: 0.0040\n",
      "Epoch [91/100], Loss: 0.0039\n",
      "Epoch [92/100], Loss: 0.0040\n",
      "Epoch [93/100], Loss: 0.0043\n",
      "Epoch [94/100], Loss: 0.0040\n",
      "Epoch [95/100], Loss: 0.0039\n",
      "Epoch [96/100], Loss: 0.0039\n",
      "Epoch [97/100], Loss: 0.0040\n",
      "Epoch [98/100], Loss: 0.0033\n",
      "Epoch [99/100], Loss: 0.0040\n",
      "Epoch [100/100], Loss: 0.0041\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(462.7179, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.66903, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1538\n",
      "Epoch [2/100], Loss: 0.1113\n",
      "Epoch [3/100], Loss: 0.1087\n",
      "Epoch [4/100], Loss: 0.1072\n",
      "Epoch [5/100], Loss: 0.1052\n",
      "Epoch [6/100], Loss: 0.1048\n",
      "Epoch [7/100], Loss: 0.1028\n",
      "Epoch [8/100], Loss: 0.1012\n",
      "Epoch [9/100], Loss: 0.0991\n",
      "Epoch [10/100], Loss: 0.0983\n",
      "Epoch [11/100], Loss: 0.0977\n",
      "Epoch [12/100], Loss: 0.0946\n",
      "Epoch [13/100], Loss: 0.0926\n",
      "Epoch [14/100], Loss: 0.0920\n",
      "Epoch [15/100], Loss: 0.0899\n",
      "Epoch [16/100], Loss: 0.0885\n",
      "Epoch [17/100], Loss: 0.0874\n",
      "Epoch [18/100], Loss: 0.0842\n",
      "Epoch [19/100], Loss: 0.0847\n",
      "Epoch [20/100], Loss: 0.0818\n",
      "Epoch [21/100], Loss: 0.0804\n",
      "Epoch [22/100], Loss: 0.0788\n",
      "Epoch [23/100], Loss: 0.0769\n",
      "Epoch [24/100], Loss: 0.0768\n",
      "Epoch [25/100], Loss: 0.0748\n",
      "Epoch [26/100], Loss: 0.0728\n",
      "Epoch [27/100], Loss: 0.0712\n",
      "Epoch [28/100], Loss: 0.0718\n",
      "Epoch [29/100], Loss: 0.0689\n",
      "Epoch [30/100], Loss: 0.0689\n",
      "Epoch [31/100], Loss: 0.0664\n",
      "Epoch [32/100], Loss: 0.0664\n",
      "Epoch [33/100], Loss: 0.0645\n",
      "Epoch [34/100], Loss: 0.0637\n",
      "Epoch [35/100], Loss: 0.0649\n",
      "Epoch [36/100], Loss: 0.0626\n",
      "Epoch [37/100], Loss: 0.0633\n",
      "Epoch [38/100], Loss: 0.0610\n",
      "Epoch [39/100], Loss: 0.0601\n",
      "Epoch [40/100], Loss: 0.0606\n",
      "Epoch [41/100], Loss: 0.0576\n",
      "Epoch [42/100], Loss: 0.0583\n",
      "Epoch [43/100], Loss: 0.0559\n",
      "Epoch [44/100], Loss: 0.0532\n",
      "Epoch [45/100], Loss: 0.0546\n",
      "Epoch [46/100], Loss: 0.0549\n",
      "Epoch [47/100], Loss: 0.0532\n",
      "Epoch [48/100], Loss: 0.0554\n",
      "Epoch [49/100], Loss: 0.0515\n",
      "Epoch [50/100], Loss: 0.0534\n",
      "Epoch [51/100], Loss: 0.0499\n",
      "Epoch [52/100], Loss: 0.0502\n",
      "Epoch [53/100], Loss: 0.0497\n",
      "Epoch [54/100], Loss: 0.0517\n",
      "Epoch [55/100], Loss: 0.0482\n",
      "Epoch [56/100], Loss: 0.0492\n",
      "Epoch [57/100], Loss: 0.0475\n",
      "Epoch [58/100], Loss: 0.0457\n",
      "Epoch [59/100], Loss: 0.0468\n",
      "Epoch [60/100], Loss: 0.0469\n",
      "Epoch [61/100], Loss: 0.0479\n",
      "Epoch [62/100], Loss: 0.0459\n",
      "Epoch [63/100], Loss: 0.0436\n",
      "Epoch [64/100], Loss: 0.0458\n",
      "Epoch [65/100], Loss: 0.0447\n",
      "Epoch [66/100], Loss: 0.0452\n",
      "Epoch [67/100], Loss: 0.0439\n",
      "Epoch [68/100], Loss: 0.0429\n",
      "Epoch [69/100], Loss: 0.0420\n",
      "Epoch [70/100], Loss: 0.0432\n",
      "Epoch [71/100], Loss: 0.0423\n",
      "Epoch [72/100], Loss: 0.0411\n",
      "Epoch [73/100], Loss: 0.0431\n",
      "Epoch [74/100], Loss: 0.0412\n",
      "Epoch [75/100], Loss: 0.0421\n",
      "Epoch [76/100], Loss: 0.0408\n",
      "Epoch [77/100], Loss: 0.0395\n",
      "Epoch [78/100], Loss: 0.0410\n",
      "Epoch [79/100], Loss: 0.0423\n",
      "Epoch [80/100], Loss: 0.0397\n",
      "Epoch [81/100], Loss: 0.0383\n",
      "Epoch [82/100], Loss: 0.0401\n",
      "Epoch [83/100], Loss: 0.0380\n",
      "Epoch [84/100], Loss: 0.0404\n",
      "Epoch [85/100], Loss: 0.0380\n",
      "Epoch [86/100], Loss: 0.0389\n",
      "Epoch [87/100], Loss: 0.0377\n",
      "Epoch [88/100], Loss: 0.0372\n",
      "Epoch [89/100], Loss: 0.0387\n",
      "Epoch [90/100], Loss: 0.0384\n",
      "Epoch [91/100], Loss: 0.0369\n",
      "Epoch [92/100], Loss: 0.0367\n",
      "Epoch [93/100], Loss: 0.0363\n",
      "Epoch [94/100], Loss: 0.0388\n",
      "Epoch [95/100], Loss: 0.0364\n",
      "Epoch [96/100], Loss: 0.0347\n",
      "Epoch [97/100], Loss: 0.0366\n",
      "Epoch [98/100], Loss: 0.0343\n",
      "Epoch [99/100], Loss: 0.0374\n",
      "Epoch [100/100], Loss: 0.0357\n",
      "update data..\n",
      "task data norm and number entries: tensor(447.9301, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924 93.64047241  0.          0.          0.        ]\n",
      "individual errors:  [array(98.25059, dtype=float32), array(89.03036, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1469\n",
      "Epoch [2/100], Loss: 0.1249\n",
      "Epoch [3/100], Loss: 0.1226\n",
      "Epoch [4/100], Loss: 0.1211\n",
      "Epoch [5/100], Loss: 0.1194\n",
      "Epoch [6/100], Loss: 0.1174\n",
      "Epoch [7/100], Loss: 0.1160\n",
      "Epoch [8/100], Loss: 0.1150\n",
      "Epoch [9/100], Loss: 0.1125\n",
      "Epoch [10/100], Loss: 0.1114\n",
      "Epoch [11/100], Loss: 0.1100\n",
      "Epoch [12/100], Loss: 0.1080\n",
      "Epoch [13/100], Loss: 0.1068\n",
      "Epoch [14/100], Loss: 0.1074\n",
      "Epoch [15/100], Loss: 0.1042\n",
      "Epoch [16/100], Loss: 0.1032\n",
      "Epoch [17/100], Loss: 0.1012\n",
      "Epoch [18/100], Loss: 0.1004\n",
      "Epoch [19/100], Loss: 0.0971\n",
      "Epoch [20/100], Loss: 0.0971\n",
      "Epoch [21/100], Loss: 0.0962\n",
      "Epoch [22/100], Loss: 0.0946\n",
      "Epoch [23/100], Loss: 0.0931\n",
      "Epoch [24/100], Loss: 0.0940\n",
      "Epoch [25/100], Loss: 0.0921\n",
      "Epoch [26/100], Loss: 0.0898\n",
      "Epoch [27/100], Loss: 0.0900\n",
      "Epoch [28/100], Loss: 0.0878\n",
      "Epoch [29/100], Loss: 0.0874\n",
      "Epoch [30/100], Loss: 0.0873\n",
      "Epoch [31/100], Loss: 0.0867\n",
      "Epoch [32/100], Loss: 0.0835\n",
      "Epoch [33/100], Loss: 0.0822\n",
      "Epoch [34/100], Loss: 0.0819\n",
      "Epoch [35/100], Loss: 0.0795\n",
      "Epoch [36/100], Loss: 0.0803\n",
      "Epoch [37/100], Loss: 0.0814\n",
      "Epoch [38/100], Loss: 0.0806\n",
      "Epoch [39/100], Loss: 0.0793\n",
      "Epoch [40/100], Loss: 0.0783\n",
      "Epoch [41/100], Loss: 0.0770\n",
      "Epoch [42/100], Loss: 0.0778\n",
      "Epoch [43/100], Loss: 0.0757\n",
      "Epoch [44/100], Loss: 0.0746\n",
      "Epoch [45/100], Loss: 0.0754\n",
      "Epoch [46/100], Loss: 0.0746\n",
      "Epoch [47/100], Loss: 0.0745\n",
      "Epoch [48/100], Loss: 0.0742\n",
      "Epoch [49/100], Loss: 0.0727\n",
      "Epoch [50/100], Loss: 0.0723\n",
      "Epoch [51/100], Loss: 0.0712\n",
      "Epoch [52/100], Loss: 0.0722\n",
      "Epoch [53/100], Loss: 0.0703\n",
      "Epoch [54/100], Loss: 0.0699\n",
      "Epoch [55/100], Loss: 0.0725\n",
      "Epoch [56/100], Loss: 0.0696\n",
      "Epoch [57/100], Loss: 0.0677\n",
      "Epoch [58/100], Loss: 0.0691\n",
      "Epoch [59/100], Loss: 0.0680\n",
      "Epoch [60/100], Loss: 0.0675\n",
      "Epoch [61/100], Loss: 0.0666\n",
      "Epoch [62/100], Loss: 0.0696\n",
      "Epoch [63/100], Loss: 0.0666\n",
      "Epoch [64/100], Loss: 0.0640\n",
      "Epoch [65/100], Loss: 0.0645\n",
      "Epoch [66/100], Loss: 0.0673\n",
      "Epoch [67/100], Loss: 0.0643\n",
      "Epoch [68/100], Loss: 0.0644\n",
      "Epoch [69/100], Loss: 0.0649\n",
      "Epoch [70/100], Loss: 0.0627\n",
      "Epoch [71/100], Loss: 0.0622\n",
      "Epoch [72/100], Loss: 0.0635\n",
      "Epoch [73/100], Loss: 0.0626\n",
      "Epoch [74/100], Loss: 0.0612\n",
      "Epoch [75/100], Loss: 0.0625\n",
      "Epoch [76/100], Loss: 0.0646\n",
      "Epoch [77/100], Loss: 0.0612\n",
      "Epoch [78/100], Loss: 0.0605\n",
      "Epoch [79/100], Loss: 0.0629\n",
      "Epoch [80/100], Loss: 0.0604\n",
      "Epoch [81/100], Loss: 0.0600\n",
      "Epoch [82/100], Loss: 0.0603\n",
      "Epoch [83/100], Loss: 0.0608\n",
      "Epoch [84/100], Loss: 0.0595\n",
      "Epoch [85/100], Loss: 0.0579\n",
      "Epoch [86/100], Loss: 0.0591\n",
      "Epoch [87/100], Loss: 0.0576\n",
      "Epoch [88/100], Loss: 0.0593\n",
      "Epoch [89/100], Loss: 0.0587\n",
      "Epoch [90/100], Loss: 0.0600\n",
      "Epoch [91/100], Loss: 0.0572\n",
      "Epoch [92/100], Loss: 0.0572\n",
      "Epoch [93/100], Loss: 0.0580\n",
      "Epoch [94/100], Loss: 0.0584\n",
      "Epoch [95/100], Loss: 0.0582\n",
      "Epoch [96/100], Loss: 0.0563\n",
      "Epoch [97/100], Loss: 0.0577\n",
      "Epoch [98/100], Loss: 0.0576\n",
      "Epoch [99/100], Loss: 0.0574\n",
      "Epoch [100/100], Loss: 0.0574\n",
      "update data..\n",
      "task data norm and number entries: tensor(437.0686, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924 93.64047241 87.56544495  0.          0.        ]\n",
      "individual errors:  [array(98.20331, dtype=float32), array(85.35749, dtype=float32), array(79.13554, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1376\n",
      "Epoch [2/100], Loss: 0.1246\n",
      "Epoch [3/100], Loss: 0.1207\n",
      "Epoch [4/100], Loss: 0.1189\n",
      "Epoch [5/100], Loss: 0.1173\n",
      "Epoch [6/100], Loss: 0.1166\n",
      "Epoch [7/100], Loss: 0.1130\n",
      "Epoch [8/100], Loss: 0.1134\n",
      "Epoch [9/100], Loss: 0.1108\n",
      "Epoch [10/100], Loss: 0.1079\n",
      "Epoch [11/100], Loss: 0.1049\n",
      "Epoch [12/100], Loss: 0.1049\n",
      "Epoch [13/100], Loss: 0.1029\n",
      "Epoch [14/100], Loss: 0.1023\n",
      "Epoch [15/100], Loss: 0.1000\n",
      "Epoch [16/100], Loss: 0.0984\n",
      "Epoch [17/100], Loss: 0.0960\n",
      "Epoch [18/100], Loss: 0.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 0.0929\n",
      "Epoch [20/100], Loss: 0.0916\n",
      "Epoch [21/100], Loss: 0.0899\n",
      "Epoch [22/100], Loss: 0.0901\n",
      "Epoch [23/100], Loss: 0.0874\n",
      "Epoch [24/100], Loss: 0.0877\n",
      "Epoch [25/100], Loss: 0.0834\n",
      "Epoch [26/100], Loss: 0.0829\n",
      "Epoch [27/100], Loss: 0.0832\n",
      "Epoch [28/100], Loss: 0.0814\n",
      "Epoch [29/100], Loss: 0.0800\n",
      "Epoch [30/100], Loss: 0.0816\n",
      "Epoch [31/100], Loss: 0.0790\n",
      "Epoch [32/100], Loss: 0.0782\n",
      "Epoch [33/100], Loss: 0.0779\n",
      "Epoch [34/100], Loss: 0.0771\n",
      "Epoch [35/100], Loss: 0.0770\n",
      "Epoch [36/100], Loss: 0.0747\n",
      "Epoch [37/100], Loss: 0.0736\n",
      "Epoch [38/100], Loss: 0.0732\n",
      "Epoch [39/100], Loss: 0.0733\n",
      "Epoch [40/100], Loss: 0.0713\n",
      "Epoch [41/100], Loss: 0.0699\n",
      "Epoch [42/100], Loss: 0.0704\n",
      "Epoch [43/100], Loss: 0.0703\n",
      "Epoch [44/100], Loss: 0.0686\n",
      "Epoch [45/100], Loss: 0.0697\n",
      "Epoch [46/100], Loss: 0.0679\n",
      "Epoch [47/100], Loss: 0.0675\n",
      "Epoch [48/100], Loss: 0.0666\n",
      "Epoch [49/100], Loss: 0.0666\n",
      "Epoch [50/100], Loss: 0.0655\n",
      "Epoch [51/100], Loss: 0.0664\n",
      "Epoch [52/100], Loss: 0.0635\n",
      "Epoch [53/100], Loss: 0.0633\n",
      "Epoch [54/100], Loss: 0.0620\n",
      "Epoch [55/100], Loss: 0.0620\n",
      "Epoch [56/100], Loss: 0.0622\n",
      "Epoch [57/100], Loss: 0.0614\n",
      "Epoch [58/100], Loss: 0.0607\n",
      "Epoch [59/100], Loss: 0.0614\n",
      "Epoch [60/100], Loss: 0.0610\n",
      "Epoch [61/100], Loss: 0.0606\n",
      "Epoch [62/100], Loss: 0.0606\n",
      "Epoch [63/100], Loss: 0.0624\n",
      "Epoch [64/100], Loss: 0.0596\n",
      "Epoch [65/100], Loss: 0.0601\n",
      "Epoch [66/100], Loss: 0.0586\n",
      "Epoch [67/100], Loss: 0.0575\n",
      "Epoch [68/100], Loss: 0.0568\n",
      "Epoch [69/100], Loss: 0.0590\n",
      "Epoch [70/100], Loss: 0.0566\n",
      "Epoch [71/100], Loss: 0.0579\n",
      "Epoch [72/100], Loss: 0.0571\n",
      "Epoch [73/100], Loss: 0.0552\n",
      "Epoch [74/100], Loss: 0.0558\n",
      "Epoch [75/100], Loss: 0.0554\n",
      "Epoch [76/100], Loss: 0.0567\n",
      "Epoch [77/100], Loss: 0.0555\n",
      "Epoch [78/100], Loss: 0.0549\n",
      "Epoch [79/100], Loss: 0.0551\n",
      "Epoch [80/100], Loss: 0.0559\n",
      "Epoch [81/100], Loss: 0.0560\n",
      "Epoch [82/100], Loss: 0.0550\n",
      "Epoch [83/100], Loss: 0.0549\n",
      "Epoch [84/100], Loss: 0.0547\n",
      "Epoch [85/100], Loss: 0.0537\n",
      "Epoch [86/100], Loss: 0.0533\n",
      "Epoch [87/100], Loss: 0.0543\n",
      "Epoch [88/100], Loss: 0.0543\n",
      "Epoch [89/100], Loss: 0.0526\n",
      "Epoch [90/100], Loss: 0.0545\n",
      "Epoch [91/100], Loss: 0.0526\n",
      "Epoch [92/100], Loss: 0.0559\n",
      "Epoch [93/100], Loss: 0.0519\n",
      "Epoch [94/100], Loss: 0.0531\n",
      "Epoch [95/100], Loss: 0.0527\n",
      "Epoch [96/100], Loss: 0.0519\n",
      "Epoch [97/100], Loss: 0.0520\n",
      "Epoch [98/100], Loss: 0.0517\n",
      "Epoch [99/100], Loss: 0.0520\n",
      "Epoch [100/100], Loss: 0.0510\n",
      "update data..\n",
      "task data norm and number entries: tensor(451.2207, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.66902924 93.64047241 87.56544495 86.08069611  0.        ]\n",
      "individual errors:  [array(96.54846, dtype=float32), array(82.664055, dtype=float32), array(75.08004, dtype=float32), array(90.03021, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1312\n",
      "Epoch [2/100], Loss: 0.1223\n",
      "Epoch [3/100], Loss: 0.1194\n",
      "Epoch [4/100], Loss: 0.1181\n",
      "Epoch [5/100], Loss: 0.1176\n",
      "Epoch [6/100], Loss: 0.1170\n",
      "Epoch [7/100], Loss: 0.1161\n",
      "Epoch [8/100], Loss: 0.1145\n",
      "Epoch [9/100], Loss: 0.1136\n",
      "Epoch [10/100], Loss: 0.1152\n",
      "Epoch [11/100], Loss: 0.1122\n",
      "Epoch [12/100], Loss: 0.1118\n",
      "Epoch [13/100], Loss: 0.1107\n",
      "Epoch [14/100], Loss: 0.1095\n",
      "Epoch [15/100], Loss: 0.1081\n",
      "Epoch [16/100], Loss: 0.1075\n",
      "Epoch [17/100], Loss: 0.1062\n",
      "Epoch [18/100], Loss: 0.1077\n",
      "Epoch [19/100], Loss: 0.1064\n",
      "Epoch [20/100], Loss: 0.1040\n",
      "Epoch [21/100], Loss: 0.1056\n",
      "Epoch [22/100], Loss: 0.1034\n",
      "Epoch [23/100], Loss: 0.1026\n",
      "Epoch [24/100], Loss: 0.1021\n",
      "Epoch [25/100], Loss: 0.1018\n",
      "Epoch [26/100], Loss: 0.1023\n",
      "Epoch [27/100], Loss: 0.1005\n",
      "Epoch [28/100], Loss: 0.0985\n",
      "Epoch [29/100], Loss: 0.0991\n",
      "Epoch [30/100], Loss: 0.1004\n",
      "Epoch [31/100], Loss: 0.0987\n",
      "Epoch [32/100], Loss: 0.0973\n",
      "Epoch [33/100], Loss: 0.0966\n",
      "Epoch [34/100], Loss: 0.0966\n",
      "Epoch [35/100], Loss: 0.0968\n",
      "Epoch [36/100], Loss: 0.0973\n",
      "Epoch [37/100], Loss: 0.0951\n",
      "Epoch [38/100], Loss: 0.0970\n",
      "Epoch [39/100], Loss: 0.0958\n",
      "Epoch [40/100], Loss: 0.0940\n",
      "Epoch [41/100], Loss: 0.0948\n",
      "Epoch [42/100], Loss: 0.0958\n",
      "Epoch [43/100], Loss: 0.0920\n",
      "Epoch [44/100], Loss: 0.0927\n",
      "Epoch [45/100], Loss: 0.0918\n",
      "Epoch [46/100], Loss: 0.0913\n",
      "Epoch [47/100], Loss: 0.0921\n",
      "Epoch [48/100], Loss: 0.0909\n",
      "Epoch [49/100], Loss: 0.0908\n",
      "Epoch [50/100], Loss: 0.0924\n",
      "Epoch [51/100], Loss: 0.0909\n",
      "Epoch [52/100], Loss: 0.0908\n",
      "Epoch [53/100], Loss: 0.0903\n",
      "Epoch [54/100], Loss: 0.0890\n",
      "Epoch [55/100], Loss: 0.0903\n",
      "Epoch [56/100], Loss: 0.0886\n",
      "Epoch [57/100], Loss: 0.0876\n",
      "Epoch [58/100], Loss: 0.0900\n",
      "Epoch [59/100], Loss: 0.0879\n",
      "Epoch [60/100], Loss: 0.0891\n",
      "Epoch [61/100], Loss: 0.0869\n",
      "Epoch [62/100], Loss: 0.0881\n",
      "Epoch [63/100], Loss: 0.0859\n",
      "Epoch [64/100], Loss: 0.0880\n",
      "Epoch [65/100], Loss: 0.0851\n",
      "Epoch [66/100], Loss: 0.0860\n",
      "Epoch [67/100], Loss: 0.0859\n",
      "Epoch [68/100], Loss: 0.0861\n",
      "Epoch [69/100], Loss: 0.0847\n",
      "Epoch [70/100], Loss: 0.0871\n",
      "Epoch [71/100], Loss: 0.0850\n",
      "Epoch [72/100], Loss: 0.0840\n",
      "Epoch [73/100], Loss: 0.0847\n",
      "Epoch [74/100], Loss: 0.0843\n",
      "Epoch [75/100], Loss: 0.0859\n",
      "Epoch [76/100], Loss: 0.0847\n",
      "Epoch [77/100], Loss: 0.0836\n",
      "Epoch [78/100], Loss: 0.0841\n",
      "Epoch [79/100], Loss: 0.0827\n",
      "Epoch [80/100], Loss: 0.0833\n",
      "Epoch [81/100], Loss: 0.0843\n",
      "Epoch [82/100], Loss: 0.0830\n",
      "Epoch [83/100], Loss: 0.0841\n",
      "Epoch [84/100], Loss: 0.0820\n",
      "Epoch [85/100], Loss: 0.0822\n",
      "Epoch [86/100], Loss: 0.0834\n",
      "Epoch [87/100], Loss: 0.0816\n",
      "Epoch [88/100], Loss: 0.0810\n",
      "Epoch [89/100], Loss: 0.0816\n",
      "Epoch [90/100], Loss: 0.0813\n",
      "Epoch [91/100], Loss: 0.0825\n",
      "Epoch [92/100], Loss: 0.0823\n",
      "Epoch [93/100], Loss: 0.0822\n",
      "Epoch [94/100], Loss: 0.0798\n",
      "Epoch [95/100], Loss: 0.0819\n",
      "Epoch [96/100], Loss: 0.0810\n",
      "Epoch [97/100], Loss: 0.0799\n",
      "Epoch [98/100], Loss: 0.0805\n",
      "Epoch [99/100], Loss: 0.0801\n",
      "Epoch [100/100], Loss: 0.0797\n",
      "test performance :  [99.66902924 93.64047241 87.56544495 86.08069611 81.5375061 ]\n",
      "individual errors:  [array(96.97399, dtype=float32), array(84.182175, dtype=float32), array(66.7556, dtype=float32), array(88.21752, dtype=float32), array(71.55824, dtype=float32)]\n",
      "EWC++  1600 1e-05\n",
      "Epoch [1/100], Loss: 0.0984\n",
      "Epoch [2/100], Loss: 0.0498\n",
      "Epoch [3/100], Loss: 0.0481\n",
      "Epoch [4/100], Loss: 0.0462\n",
      "Epoch [5/100], Loss: 0.0451\n",
      "Epoch [6/100], Loss: 0.0434\n",
      "Epoch [7/100], Loss: 0.0414\n",
      "Epoch [8/100], Loss: 0.0399\n",
      "Epoch [9/100], Loss: 0.0381\n",
      "Epoch [10/100], Loss: 0.0364\n",
      "Epoch [11/100], Loss: 0.0346\n",
      "Epoch [12/100], Loss: 0.0333\n",
      "Epoch [13/100], Loss: 0.0317\n",
      "Epoch [14/100], Loss: 0.0299\n",
      "Epoch [15/100], Loss: 0.0288\n",
      "Epoch [16/100], Loss: 0.0265\n",
      "Epoch [17/100], Loss: 0.0255\n",
      "Epoch [18/100], Loss: 0.0242\n",
      "Epoch [19/100], Loss: 0.0231\n",
      "Epoch [20/100], Loss: 0.0223\n",
      "Epoch [21/100], Loss: 0.0206\n",
      "Epoch [22/100], Loss: 0.0201\n",
      "Epoch [23/100], Loss: 0.0184\n",
      "Epoch [24/100], Loss: 0.0174\n",
      "Epoch [25/100], Loss: 0.0163\n",
      "Epoch [26/100], Loss: 0.0150\n",
      "Epoch [27/100], Loss: 0.0152\n",
      "Epoch [28/100], Loss: 0.0138\n",
      "Epoch [29/100], Loss: 0.0131\n",
      "Epoch [30/100], Loss: 0.0123\n",
      "Epoch [31/100], Loss: 0.0117\n",
      "Epoch [32/100], Loss: 0.0113\n",
      "Epoch [33/100], Loss: 0.0113\n",
      "Epoch [34/100], Loss: 0.0099\n",
      "Epoch [35/100], Loss: 0.0100\n",
      "Epoch [36/100], Loss: 0.0103\n",
      "Epoch [37/100], Loss: 0.0082\n",
      "Epoch [38/100], Loss: 0.0085\n",
      "Epoch [39/100], Loss: 0.0078\n",
      "Epoch [40/100], Loss: 0.0086\n",
      "Epoch [41/100], Loss: 0.0073\n",
      "Epoch [42/100], Loss: 0.0071\n",
      "Epoch [43/100], Loss: 0.0067\n",
      "Epoch [44/100], Loss: 0.0065\n",
      "Epoch [45/100], Loss: 0.0070\n",
      "Epoch [46/100], Loss: 0.0066\n",
      "Epoch [47/100], Loss: 0.0063\n",
      "Epoch [48/100], Loss: 0.0057\n",
      "Epoch [49/100], Loss: 0.0060\n",
      "Epoch [50/100], Loss: 0.0058\n",
      "Epoch [51/100], Loss: 0.0060\n",
      "Epoch [52/100], Loss: 0.0057\n",
      "Epoch [53/100], Loss: 0.0058\n",
      "Epoch [54/100], Loss: 0.0046\n",
      "Epoch [55/100], Loss: 0.0050\n",
      "Epoch [56/100], Loss: 0.0052\n",
      "Epoch [57/100], Loss: 0.0051\n",
      "Epoch [58/100], Loss: 0.0052\n",
      "Epoch [59/100], Loss: 0.0053\n",
      "Epoch [60/100], Loss: 0.0048\n",
      "Epoch [61/100], Loss: 0.0044\n",
      "Epoch [62/100], Loss: 0.0041\n",
      "Epoch [63/100], Loss: 0.0046\n",
      "Epoch [64/100], Loss: 0.0047\n",
      "Epoch [65/100], Loss: 0.0049\n",
      "Epoch [66/100], Loss: 0.0044\n",
      "Epoch [67/100], Loss: 0.0050\n",
      "Epoch [68/100], Loss: 0.0050\n",
      "Epoch [69/100], Loss: 0.0040\n",
      "Epoch [70/100], Loss: 0.0042\n",
      "Epoch [71/100], Loss: 0.0047\n",
      "Epoch [72/100], Loss: 0.0043\n",
      "Epoch [73/100], Loss: 0.0042\n",
      "Epoch [74/100], Loss: 0.0039\n",
      "Epoch [75/100], Loss: 0.0040\n",
      "Epoch [76/100], Loss: 0.0048\n",
      "Epoch [77/100], Loss: 0.0042\n",
      "Epoch [78/100], Loss: 0.0038\n",
      "Epoch [79/100], Loss: 0.0048\n",
      "Epoch [80/100], Loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Loss: 0.0036\n",
      "Epoch [82/100], Loss: 0.0041\n",
      "Epoch [83/100], Loss: 0.0041\n",
      "Epoch [84/100], Loss: 0.0039\n",
      "Epoch [85/100], Loss: 0.0036\n",
      "Epoch [86/100], Loss: 0.0039\n",
      "Epoch [87/100], Loss: 0.0036\n",
      "Epoch [88/100], Loss: 0.0039\n",
      "Epoch [89/100], Loss: 0.0040\n",
      "Epoch [90/100], Loss: 0.0036\n",
      "Epoch [91/100], Loss: 0.0034\n",
      "Epoch [92/100], Loss: 0.0036\n",
      "Epoch [93/100], Loss: 0.0038\n",
      "Epoch [94/100], Loss: 0.0038\n",
      "Epoch [95/100], Loss: 0.0033\n",
      "Epoch [96/100], Loss: 0.0037\n",
      "Epoch [97/100], Loss: 0.0041\n",
      "Epoch [98/100], Loss: 0.0036\n",
      "Epoch [99/100], Loss: 0.0036\n",
      "Epoch [100/100], Loss: 0.0029\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(460.1783, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.763596, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1548\n",
      "Epoch [2/100], Loss: 0.1120\n",
      "Epoch [3/100], Loss: 0.1094\n",
      "Epoch [4/100], Loss: 0.1081\n",
      "Epoch [5/100], Loss: 0.1063\n",
      "Epoch [6/100], Loss: 0.1054\n",
      "Epoch [7/100], Loss: 0.1038\n",
      "Epoch [8/100], Loss: 0.1031\n",
      "Epoch [9/100], Loss: 0.1008\n",
      "Epoch [10/100], Loss: 0.0982\n",
      "Epoch [11/100], Loss: 0.0968\n",
      "Epoch [12/100], Loss: 0.0963\n",
      "Epoch [13/100], Loss: 0.0948\n",
      "Epoch [14/100], Loss: 0.0927\n",
      "Epoch [15/100], Loss: 0.0911\n",
      "Epoch [16/100], Loss: 0.0892\n",
      "Epoch [17/100], Loss: 0.0872\n",
      "Epoch [18/100], Loss: 0.0862\n",
      "Epoch [19/100], Loss: 0.0851\n",
      "Epoch [20/100], Loss: 0.0828\n",
      "Epoch [21/100], Loss: 0.0816\n",
      "Epoch [22/100], Loss: 0.0789\n",
      "Epoch [23/100], Loss: 0.0795\n",
      "Epoch [24/100], Loss: 0.0787\n",
      "Epoch [25/100], Loss: 0.0765\n",
      "Epoch [26/100], Loss: 0.0763\n",
      "Epoch [27/100], Loss: 0.0736\n",
      "Epoch [28/100], Loss: 0.0735\n",
      "Epoch [29/100], Loss: 0.0713\n",
      "Epoch [30/100], Loss: 0.0716\n",
      "Epoch [31/100], Loss: 0.0700\n",
      "Epoch [32/100], Loss: 0.0681\n",
      "Epoch [33/100], Loss: 0.0689\n",
      "Epoch [34/100], Loss: 0.0662\n",
      "Epoch [35/100], Loss: 0.0643\n",
      "Epoch [36/100], Loss: 0.0645\n",
      "Epoch [37/100], Loss: 0.0636\n",
      "Epoch [38/100], Loss: 0.0630\n",
      "Epoch [39/100], Loss: 0.0624\n",
      "Epoch [40/100], Loss: 0.0588\n",
      "Epoch [41/100], Loss: 0.0588\n",
      "Epoch [42/100], Loss: 0.0590\n",
      "Epoch [43/100], Loss: 0.0580\n",
      "Epoch [44/100], Loss: 0.0580\n",
      "Epoch [45/100], Loss: 0.0559\n",
      "Epoch [46/100], Loss: 0.0550\n",
      "Epoch [47/100], Loss: 0.0549\n",
      "Epoch [48/100], Loss: 0.0551\n",
      "Epoch [49/100], Loss: 0.0522\n",
      "Epoch [50/100], Loss: 0.0531\n",
      "Epoch [51/100], Loss: 0.0529\n",
      "Epoch [52/100], Loss: 0.0517\n",
      "Epoch [53/100], Loss: 0.0512\n",
      "Epoch [54/100], Loss: 0.0493\n",
      "Epoch [55/100], Loss: 0.0497\n",
      "Epoch [56/100], Loss: 0.0505\n",
      "Epoch [57/100], Loss: 0.0494\n",
      "Epoch [58/100], Loss: 0.0506\n",
      "Epoch [59/100], Loss: 0.0484\n",
      "Epoch [60/100], Loss: 0.0488\n",
      "Epoch [61/100], Loss: 0.0472\n",
      "Epoch [62/100], Loss: 0.0459\n",
      "Epoch [63/100], Loss: 0.0465\n",
      "Epoch [64/100], Loss: 0.0457\n",
      "Epoch [65/100], Loss: 0.0448\n",
      "Epoch [66/100], Loss: 0.0448\n",
      "Epoch [67/100], Loss: 0.0448\n",
      "Epoch [68/100], Loss: 0.0431\n",
      "Epoch [69/100], Loss: 0.0432\n",
      "Epoch [70/100], Loss: 0.0443\n",
      "Epoch [71/100], Loss: 0.0420\n",
      "Epoch [72/100], Loss: 0.0431\n",
      "Epoch [73/100], Loss: 0.0432\n",
      "Epoch [74/100], Loss: 0.0434\n",
      "Epoch [75/100], Loss: 0.0415\n",
      "Epoch [76/100], Loss: 0.0428\n",
      "Epoch [77/100], Loss: 0.0414\n",
      "Epoch [78/100], Loss: 0.0413\n",
      "Epoch [79/100], Loss: 0.0396\n",
      "Epoch [80/100], Loss: 0.0391\n",
      "Epoch [81/100], Loss: 0.0416\n",
      "Epoch [82/100], Loss: 0.0406\n",
      "Epoch [83/100], Loss: 0.0401\n",
      "Epoch [84/100], Loss: 0.0396\n",
      "Epoch [85/100], Loss: 0.0388\n",
      "Epoch [86/100], Loss: 0.0400\n",
      "Epoch [87/100], Loss: 0.0393\n",
      "Epoch [88/100], Loss: 0.0386\n",
      "Epoch [89/100], Loss: 0.0408\n",
      "Epoch [90/100], Loss: 0.0388\n",
      "Epoch [91/100], Loss: 0.0396\n",
      "Epoch [92/100], Loss: 0.0375\n",
      "Epoch [93/100], Loss: 0.0381\n",
      "Epoch [94/100], Loss: 0.0366\n",
      "Epoch [95/100], Loss: 0.0388\n",
      "Epoch [96/100], Loss: 0.0385\n",
      "Epoch [97/100], Loss: 0.0375\n",
      "Epoch [98/100], Loss: 0.0366\n",
      "Epoch [99/100], Loss: 0.0361\n",
      "Epoch [100/100], Loss: 0.0378\n",
      "update data..\n",
      "task data norm and number entries: tensor(449.7434, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 93.99931335  0.          0.          0.        ]\n",
      "individual errors:  [array(98.723404, dtype=float32), array(89.275215, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1381\n",
      "Epoch [2/100], Loss: 0.1192\n",
      "Epoch [3/100], Loss: 0.1153\n",
      "Epoch [4/100], Loss: 0.1145\n",
      "Epoch [5/100], Loss: 0.1135\n",
      "Epoch [6/100], Loss: 0.1124\n",
      "Epoch [7/100], Loss: 0.1119\n",
      "Epoch [8/100], Loss: 0.1074\n",
      "Epoch [9/100], Loss: 0.1071\n",
      "Epoch [10/100], Loss: 0.1056\n",
      "Epoch [11/100], Loss: 0.1040\n",
      "Epoch [12/100], Loss: 0.1030\n",
      "Epoch [13/100], Loss: 0.1020\n",
      "Epoch [14/100], Loss: 0.0998\n",
      "Epoch [15/100], Loss: 0.0989\n",
      "Epoch [16/100], Loss: 0.0981\n",
      "Epoch [17/100], Loss: 0.0989\n",
      "Epoch [18/100], Loss: 0.0958\n",
      "Epoch [19/100], Loss: 0.0951\n",
      "Epoch [20/100], Loss: 0.0934\n",
      "Epoch [21/100], Loss: 0.0921\n",
      "Epoch [22/100], Loss: 0.0911\n",
      "Epoch [23/100], Loss: 0.0902\n",
      "Epoch [24/100], Loss: 0.0888\n",
      "Epoch [25/100], Loss: 0.0868\n",
      "Epoch [26/100], Loss: 0.0858\n",
      "Epoch [27/100], Loss: 0.0865\n",
      "Epoch [28/100], Loss: 0.0840\n",
      "Epoch [29/100], Loss: 0.0842\n",
      "Epoch [30/100], Loss: 0.0831\n",
      "Epoch [31/100], Loss: 0.0812\n",
      "Epoch [32/100], Loss: 0.0819\n",
      "Epoch [33/100], Loss: 0.0796\n",
      "Epoch [34/100], Loss: 0.0812\n",
      "Epoch [35/100], Loss: 0.0800\n",
      "Epoch [36/100], Loss: 0.0778\n",
      "Epoch [37/100], Loss: 0.0770\n",
      "Epoch [38/100], Loss: 0.0775\n",
      "Epoch [39/100], Loss: 0.0751\n",
      "Epoch [40/100], Loss: 0.0733\n",
      "Epoch [41/100], Loss: 0.0745\n",
      "Epoch [42/100], Loss: 0.0738\n",
      "Epoch [43/100], Loss: 0.0740\n",
      "Epoch [44/100], Loss: 0.0734\n",
      "Epoch [45/100], Loss: 0.0709\n",
      "Epoch [46/100], Loss: 0.0714\n",
      "Epoch [47/100], Loss: 0.0721\n",
      "Epoch [48/100], Loss: 0.0709\n",
      "Epoch [49/100], Loss: 0.0705\n",
      "Epoch [50/100], Loss: 0.0707\n",
      "Epoch [51/100], Loss: 0.0707\n",
      "Epoch [52/100], Loss: 0.0688\n",
      "Epoch [53/100], Loss: 0.0695\n",
      "Epoch [54/100], Loss: 0.0677\n",
      "Epoch [55/100], Loss: 0.0680\n",
      "Epoch [56/100], Loss: 0.0668\n",
      "Epoch [57/100], Loss: 0.0652\n",
      "Epoch [58/100], Loss: 0.0649\n",
      "Epoch [59/100], Loss: 0.0662\n",
      "Epoch [60/100], Loss: 0.0654\n",
      "Epoch [61/100], Loss: 0.0659\n",
      "Epoch [62/100], Loss: 0.0654\n",
      "Epoch [63/100], Loss: 0.0646\n",
      "Epoch [64/100], Loss: 0.0648\n",
      "Epoch [65/100], Loss: 0.0644\n",
      "Epoch [66/100], Loss: 0.0634\n",
      "Epoch [67/100], Loss: 0.0641\n",
      "Epoch [68/100], Loss: 0.0660\n",
      "Epoch [69/100], Loss: 0.0633\n",
      "Epoch [70/100], Loss: 0.0631\n",
      "Epoch [71/100], Loss: 0.0615\n",
      "Epoch [72/100], Loss: 0.0618\n",
      "Epoch [73/100], Loss: 0.0614\n",
      "Epoch [74/100], Loss: 0.0613\n",
      "Epoch [75/100], Loss: 0.0612\n",
      "Epoch [76/100], Loss: 0.0618\n",
      "Epoch [77/100], Loss: 0.0610\n",
      "Epoch [78/100], Loss: 0.0615\n",
      "Epoch [79/100], Loss: 0.0610\n",
      "Epoch [80/100], Loss: 0.0600\n",
      "Epoch [81/100], Loss: 0.0583\n",
      "Epoch [82/100], Loss: 0.0576\n",
      "Epoch [83/100], Loss: 0.0578\n",
      "Epoch [84/100], Loss: 0.0593\n",
      "Epoch [85/100], Loss: 0.0599\n",
      "Epoch [86/100], Loss: 0.0583\n",
      "Epoch [87/100], Loss: 0.0586\n",
      "Epoch [88/100], Loss: 0.0566\n",
      "Epoch [89/100], Loss: 0.0589\n",
      "Epoch [90/100], Loss: 0.0566\n",
      "Epoch [91/100], Loss: 0.0572\n",
      "Epoch [92/100], Loss: 0.0578\n",
      "Epoch [93/100], Loss: 0.0575\n",
      "Epoch [94/100], Loss: 0.0583\n",
      "Epoch [95/100], Loss: 0.0579\n",
      "Epoch [96/100], Loss: 0.0558\n",
      "Epoch [97/100], Loss: 0.0566\n",
      "Epoch [98/100], Loss: 0.0558\n",
      "Epoch [99/100], Loss: 0.0588\n",
      "Epoch [100/100], Loss: 0.0570\n",
      "update data..\n",
      "task data norm and number entries: tensor(431.3111, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 93.99931335 87.88685608  0.          0.        ]\n",
      "individual errors:  [array(98.487, dtype=float32), array(85.5044, dtype=float32), array(79.66915, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1328\n",
      "Epoch [2/100], Loss: 0.1199\n",
      "Epoch [3/100], Loss: 0.1164\n",
      "Epoch [4/100], Loss: 0.1153\n",
      "Epoch [5/100], Loss: 0.1128\n",
      "Epoch [6/100], Loss: 0.1134\n",
      "Epoch [7/100], Loss: 0.1101\n",
      "Epoch [8/100], Loss: 0.1083\n",
      "Epoch [9/100], Loss: 0.1069\n",
      "Epoch [10/100], Loss: 0.1054\n",
      "Epoch [11/100], Loss: 0.1043\n",
      "Epoch [12/100], Loss: 0.1026\n",
      "Epoch [13/100], Loss: 0.1011\n",
      "Epoch [14/100], Loss: 0.0997\n",
      "Epoch [15/100], Loss: 0.0979\n",
      "Epoch [16/100], Loss: 0.0974\n",
      "Epoch [17/100], Loss: 0.0969\n",
      "Epoch [18/100], Loss: 0.0945\n",
      "Epoch [19/100], Loss: 0.0918\n",
      "Epoch [20/100], Loss: 0.0905\n",
      "Epoch [21/100], Loss: 0.0886\n",
      "Epoch [22/100], Loss: 0.0882\n",
      "Epoch [23/100], Loss: 0.0864\n",
      "Epoch [24/100], Loss: 0.0860\n",
      "Epoch [25/100], Loss: 0.0845\n",
      "Epoch [26/100], Loss: 0.0845\n",
      "Epoch [27/100], Loss: 0.0823\n",
      "Epoch [28/100], Loss: 0.0806\n",
      "Epoch [29/100], Loss: 0.0803\n",
      "Epoch [30/100], Loss: 0.0788\n",
      "Epoch [31/100], Loss: 0.0777\n",
      "Epoch [32/100], Loss: 0.0781\n",
      "Epoch [33/100], Loss: 0.0763\n",
      "Epoch [34/100], Loss: 0.0755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Loss: 0.0743\n",
      "Epoch [36/100], Loss: 0.0743\n",
      "Epoch [37/100], Loss: 0.0731\n",
      "Epoch [38/100], Loss: 0.0727\n",
      "Epoch [39/100], Loss: 0.0733\n",
      "Epoch [40/100], Loss: 0.0724\n",
      "Epoch [41/100], Loss: 0.0715\n",
      "Epoch [42/100], Loss: 0.0688\n",
      "Epoch [43/100], Loss: 0.0683\n",
      "Epoch [44/100], Loss: 0.0691\n",
      "Epoch [45/100], Loss: 0.0685\n",
      "Epoch [46/100], Loss: 0.0682\n",
      "Epoch [47/100], Loss: 0.0685\n",
      "Epoch [48/100], Loss: 0.0674\n",
      "Epoch [49/100], Loss: 0.0653\n",
      "Epoch [50/100], Loss: 0.0648\n",
      "Epoch [51/100], Loss: 0.0639\n",
      "Epoch [52/100], Loss: 0.0658\n",
      "Epoch [53/100], Loss: 0.0645\n",
      "Epoch [54/100], Loss: 0.0649\n",
      "Epoch [55/100], Loss: 0.0636\n",
      "Epoch [56/100], Loss: 0.0620\n",
      "Epoch [57/100], Loss: 0.0620\n",
      "Epoch [58/100], Loss: 0.0612\n",
      "Epoch [59/100], Loss: 0.0613\n",
      "Epoch [60/100], Loss: 0.0619\n",
      "Epoch [61/100], Loss: 0.0593\n",
      "Epoch [62/100], Loss: 0.0606\n",
      "Epoch [63/100], Loss: 0.0602\n",
      "Epoch [64/100], Loss: 0.0604\n",
      "Epoch [65/100], Loss: 0.0585\n",
      "Epoch [66/100], Loss: 0.0598\n",
      "Epoch [67/100], Loss: 0.0592\n",
      "Epoch [68/100], Loss: 0.0589\n",
      "Epoch [69/100], Loss: 0.0579\n",
      "Epoch [70/100], Loss: 0.0571\n",
      "Epoch [71/100], Loss: 0.0572\n",
      "Epoch [72/100], Loss: 0.0609\n",
      "Epoch [73/100], Loss: 0.0567\n",
      "Epoch [74/100], Loss: 0.0576\n",
      "Epoch [75/100], Loss: 0.0575\n",
      "Epoch [76/100], Loss: 0.0564\n",
      "Epoch [77/100], Loss: 0.0562\n",
      "Epoch [78/100], Loss: 0.0540\n",
      "Epoch [79/100], Loss: 0.0575\n",
      "Epoch [80/100], Loss: 0.0567\n",
      "Epoch [81/100], Loss: 0.0564\n",
      "Epoch [82/100], Loss: 0.0561\n",
      "Epoch [83/100], Loss: 0.0554\n",
      "Epoch [84/100], Loss: 0.0558\n",
      "Epoch [85/100], Loss: 0.0559\n",
      "Epoch [86/100], Loss: 0.0538\n",
      "Epoch [87/100], Loss: 0.0533\n",
      "Epoch [88/100], Loss: 0.0544\n",
      "Epoch [89/100], Loss: 0.0529\n",
      "Epoch [90/100], Loss: 0.0531\n",
      "Epoch [91/100], Loss: 0.0530\n",
      "Epoch [92/100], Loss: 0.0553\n",
      "Epoch [93/100], Loss: 0.0521\n",
      "Epoch [94/100], Loss: 0.0532\n",
      "Epoch [95/100], Loss: 0.0537\n",
      "Epoch [96/100], Loss: 0.0526\n",
      "Epoch [97/100], Loss: 0.0543\n",
      "Epoch [98/100], Loss: 0.0546\n",
      "Epoch [99/100], Loss: 0.0527\n",
      "Epoch [100/100], Loss: 0.0537\n",
      "update data..\n",
      "task data norm and number entries: tensor(451.8970, device='cuda:0') torch.Size([1600, 31370])\n",
      "..done\n",
      "test performance :  [99.76359558 93.99931335 87.88685608 86.36472321  0.        ]\n",
      "individual errors:  [array(97.06856, dtype=float32), array(82.56611, dtype=float32), array(75.24013, dtype=float32), array(90.58409, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1301\n",
      "Epoch [2/100], Loss: 0.1207\n",
      "Epoch [3/100], Loss: 0.1176\n",
      "Epoch [4/100], Loss: 0.1171\n",
      "Epoch [5/100], Loss: 0.1168\n",
      "Epoch [6/100], Loss: 0.1148\n",
      "Epoch [7/100], Loss: 0.1173\n",
      "Epoch [8/100], Loss: 0.1137\n",
      "Epoch [9/100], Loss: 0.1128\n",
      "Epoch [10/100], Loss: 0.1127\n",
      "Epoch [11/100], Loss: 0.1113\n",
      "Epoch [12/100], Loss: 0.1102\n",
      "Epoch [13/100], Loss: 0.1098\n",
      "Epoch [14/100], Loss: 0.1095\n",
      "Epoch [15/100], Loss: 0.1076\n",
      "Epoch [16/100], Loss: 0.1073\n",
      "Epoch [17/100], Loss: 0.1064\n",
      "Epoch [18/100], Loss: 0.1056\n",
      "Epoch [19/100], Loss: 0.1046\n",
      "Epoch [20/100], Loss: 0.1042\n",
      "Epoch [21/100], Loss: 0.1025\n",
      "Epoch [22/100], Loss: 0.1041\n",
      "Epoch [23/100], Loss: 0.1042\n",
      "Epoch [24/100], Loss: 0.1018\n",
      "Epoch [25/100], Loss: 0.1012\n",
      "Epoch [26/100], Loss: 0.1023\n",
      "Epoch [27/100], Loss: 0.1004\n",
      "Epoch [28/100], Loss: 0.0995\n",
      "Epoch [29/100], Loss: 0.0992\n",
      "Epoch [30/100], Loss: 0.0986\n",
      "Epoch [31/100], Loss: 0.0976\n",
      "Epoch [32/100], Loss: 0.0972\n",
      "Epoch [33/100], Loss: 0.0964\n",
      "Epoch [34/100], Loss: 0.0973\n",
      "Epoch [35/100], Loss: 0.0961\n",
      "Epoch [36/100], Loss: 0.0952\n",
      "Epoch [37/100], Loss: 0.0965\n",
      "Epoch [38/100], Loss: 0.0952\n",
      "Epoch [39/100], Loss: 0.0961\n",
      "Epoch [40/100], Loss: 0.0937\n",
      "Epoch [41/100], Loss: 0.0937\n",
      "Epoch [42/100], Loss: 0.0946\n",
      "Epoch [43/100], Loss: 0.0965\n",
      "Epoch [44/100], Loss: 0.0936\n",
      "Epoch [45/100], Loss: 0.0925\n",
      "Epoch [46/100], Loss: 0.0925\n",
      "Epoch [47/100], Loss: 0.0914\n",
      "Epoch [48/100], Loss: 0.0916\n",
      "Epoch [49/100], Loss: 0.0916\n",
      "Epoch [50/100], Loss: 0.0914\n",
      "Epoch [51/100], Loss: 0.0901\n",
      "Epoch [52/100], Loss: 0.0908\n",
      "Epoch [53/100], Loss: 0.0901\n",
      "Epoch [54/100], Loss: 0.0903\n",
      "Epoch [55/100], Loss: 0.0899\n",
      "Epoch [56/100], Loss: 0.0904\n",
      "Epoch [57/100], Loss: 0.0907\n",
      "Epoch [58/100], Loss: 0.0876\n",
      "Epoch [59/100], Loss: 0.0885\n",
      "Epoch [60/100], Loss: 0.0888\n",
      "Epoch [61/100], Loss: 0.0894\n",
      "Epoch [62/100], Loss: 0.0884\n",
      "Epoch [63/100], Loss: 0.0875\n",
      "Epoch [64/100], Loss: 0.0872\n",
      "Epoch [65/100], Loss: 0.0870\n",
      "Epoch [66/100], Loss: 0.0876\n",
      "Epoch [67/100], Loss: 0.0867\n",
      "Epoch [68/100], Loss: 0.0869\n",
      "Epoch [69/100], Loss: 0.0867\n",
      "Epoch [70/100], Loss: 0.0858\n",
      "Epoch [71/100], Loss: 0.0855\n",
      "Epoch [72/100], Loss: 0.0853\n",
      "Epoch [73/100], Loss: 0.0848\n",
      "Epoch [74/100], Loss: 0.0865\n",
      "Epoch [75/100], Loss: 0.0867\n",
      "Epoch [76/100], Loss: 0.0859\n",
      "Epoch [77/100], Loss: 0.0859\n",
      "Epoch [78/100], Loss: 0.0846\n",
      "Epoch [79/100], Loss: 0.0838\n",
      "Epoch [80/100], Loss: 0.0841\n",
      "Epoch [81/100], Loss: 0.0833\n",
      "Epoch [82/100], Loss: 0.0854\n",
      "Epoch [83/100], Loss: 0.0853\n",
      "Epoch [84/100], Loss: 0.0836\n",
      "Epoch [85/100], Loss: 0.0842\n",
      "Epoch [86/100], Loss: 0.0853\n",
      "Epoch [87/100], Loss: 0.0855\n",
      "Epoch [88/100], Loss: 0.0842\n",
      "Epoch [89/100], Loss: 0.0834\n",
      "Epoch [90/100], Loss: 0.0842\n",
      "Epoch [91/100], Loss: 0.0834\n",
      "Epoch [92/100], Loss: 0.0840\n",
      "Epoch [93/100], Loss: 0.0818\n",
      "Epoch [94/100], Loss: 0.0830\n",
      "Epoch [95/100], Loss: 0.0850\n",
      "Epoch [96/100], Loss: 0.0809\n",
      "Epoch [97/100], Loss: 0.0827\n",
      "Epoch [98/100], Loss: 0.0823\n",
      "Epoch [99/100], Loss: 0.0832\n",
      "Epoch [100/100], Loss: 0.0828\n",
      "test performance :  [99.76359558 93.99931335 87.88685608 86.36472321 81.95950317]\n",
      "individual errors:  [array(97.06856, dtype=float32), array(81.39079, dtype=float32), array(72.57204, dtype=float32), array(88.922455, dtype=float32), array(69.84367, dtype=float32)]\n",
      "EWC++  3200 1e-05\n",
      "Epoch [1/100], Loss: 0.1012\n",
      "Epoch [2/100], Loss: 0.0496\n",
      "Epoch [3/100], Loss: 0.0476\n",
      "Epoch [4/100], Loss: 0.0463\n",
      "Epoch [5/100], Loss: 0.0444\n",
      "Epoch [6/100], Loss: 0.0430\n",
      "Epoch [7/100], Loss: 0.0406\n",
      "Epoch [8/100], Loss: 0.0391\n",
      "Epoch [9/100], Loss: 0.0375\n",
      "Epoch [10/100], Loss: 0.0354\n",
      "Epoch [11/100], Loss: 0.0338\n",
      "Epoch [12/100], Loss: 0.0313\n",
      "Epoch [13/100], Loss: 0.0310\n",
      "Epoch [14/100], Loss: 0.0288\n",
      "Epoch [15/100], Loss: 0.0276\n",
      "Epoch [16/100], Loss: 0.0256\n",
      "Epoch [17/100], Loss: 0.0241\n",
      "Epoch [18/100], Loss: 0.0228\n",
      "Epoch [19/100], Loss: 0.0219\n",
      "Epoch [20/100], Loss: 0.0195\n",
      "Epoch [21/100], Loss: 0.0197\n",
      "Epoch [22/100], Loss: 0.0177\n",
      "Epoch [23/100], Loss: 0.0181\n",
      "Epoch [24/100], Loss: 0.0163\n",
      "Epoch [25/100], Loss: 0.0155\n",
      "Epoch [26/100], Loss: 0.0147\n",
      "Epoch [27/100], Loss: 0.0143\n",
      "Epoch [28/100], Loss: 0.0130\n",
      "Epoch [29/100], Loss: 0.0130\n",
      "Epoch [30/100], Loss: 0.0117\n",
      "Epoch [31/100], Loss: 0.0121\n",
      "Epoch [32/100], Loss: 0.0109\n",
      "Epoch [33/100], Loss: 0.0101\n",
      "Epoch [34/100], Loss: 0.0093\n",
      "Epoch [35/100], Loss: 0.0088\n",
      "Epoch [36/100], Loss: 0.0083\n",
      "Epoch [37/100], Loss: 0.0088\n",
      "Epoch [38/100], Loss: 0.0078\n",
      "Epoch [39/100], Loss: 0.0078\n",
      "Epoch [40/100], Loss: 0.0069\n",
      "Epoch [41/100], Loss: 0.0077\n",
      "Epoch [42/100], Loss: 0.0071\n",
      "Epoch [43/100], Loss: 0.0066\n",
      "Epoch [44/100], Loss: 0.0058\n",
      "Epoch [45/100], Loss: 0.0057\n",
      "Epoch [46/100], Loss: 0.0066\n",
      "Epoch [47/100], Loss: 0.0057\n",
      "Epoch [48/100], Loss: 0.0059\n",
      "Epoch [49/100], Loss: 0.0050\n",
      "Epoch [50/100], Loss: 0.0055\n",
      "Epoch [51/100], Loss: 0.0050\n",
      "Epoch [52/100], Loss: 0.0049\n",
      "Epoch [53/100], Loss: 0.0060\n",
      "Epoch [54/100], Loss: 0.0048\n",
      "Epoch [55/100], Loss: 0.0051\n",
      "Epoch [56/100], Loss: 0.0051\n",
      "Epoch [57/100], Loss: 0.0044\n",
      "Epoch [58/100], Loss: 0.0048\n",
      "Epoch [59/100], Loss: 0.0052\n",
      "Epoch [60/100], Loss: 0.0049\n",
      "Epoch [61/100], Loss: 0.0046\n",
      "Epoch [62/100], Loss: 0.0051\n",
      "Epoch [63/100], Loss: 0.0041\n",
      "Epoch [64/100], Loss: 0.0048\n",
      "Epoch [65/100], Loss: 0.0051\n",
      "Epoch [66/100], Loss: 0.0052\n",
      "Epoch [67/100], Loss: 0.0044\n",
      "Epoch [68/100], Loss: 0.0045\n",
      "Epoch [69/100], Loss: 0.0046\n",
      "Epoch [70/100], Loss: 0.0046\n",
      "Epoch [71/100], Loss: 0.0043\n",
      "Epoch [72/100], Loss: 0.0048\n",
      "Epoch [73/100], Loss: 0.0050\n",
      "Epoch [74/100], Loss: 0.0043\n",
      "Epoch [75/100], Loss: 0.0038\n",
      "Epoch [76/100], Loss: 0.0041\n",
      "Epoch [77/100], Loss: 0.0040\n",
      "Epoch [78/100], Loss: 0.0037\n",
      "Epoch [79/100], Loss: 0.0039\n",
      "Epoch [80/100], Loss: 0.0037\n",
      "Epoch [81/100], Loss: 0.0044\n",
      "Epoch [82/100], Loss: 0.0036\n",
      "Epoch [83/100], Loss: 0.0047\n",
      "Epoch [84/100], Loss: 0.0041\n",
      "Epoch [85/100], Loss: 0.0042\n",
      "Epoch [86/100], Loss: 0.0041\n",
      "Epoch [87/100], Loss: 0.0036\n",
      "Epoch [88/100], Loss: 0.0036\n",
      "Epoch [89/100], Loss: 0.0043\n",
      "Epoch [90/100], Loss: 0.0032\n",
      "Epoch [91/100], Loss: 0.0041\n",
      "Epoch [92/100], Loss: 0.0040\n",
      "Epoch [93/100], Loss: 0.0044\n",
      "Epoch [94/100], Loss: 0.0046\n",
      "Epoch [95/100], Loss: 0.0038\n",
      "Epoch [96/100], Loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Loss: 0.0033\n",
      "Epoch [98/100], Loss: 0.0039\n",
      "Epoch [99/100], Loss: 0.0040\n",
      "Epoch [100/100], Loss: 0.0037\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(463.0654, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.71631, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1562\n",
      "Epoch [2/100], Loss: 0.1130\n",
      "Epoch [3/100], Loss: 0.1105\n",
      "Epoch [4/100], Loss: 0.1086\n",
      "Epoch [5/100], Loss: 0.1087\n",
      "Epoch [6/100], Loss: 0.1062\n",
      "Epoch [7/100], Loss: 0.1042\n",
      "Epoch [8/100], Loss: 0.1016\n",
      "Epoch [9/100], Loss: 0.1009\n",
      "Epoch [10/100], Loss: 0.0992\n",
      "Epoch [11/100], Loss: 0.0964\n",
      "Epoch [12/100], Loss: 0.0950\n",
      "Epoch [13/100], Loss: 0.0935\n",
      "Epoch [14/100], Loss: 0.0911\n",
      "Epoch [15/100], Loss: 0.0888\n",
      "Epoch [16/100], Loss: 0.0876\n",
      "Epoch [17/100], Loss: 0.0877\n",
      "Epoch [18/100], Loss: 0.0854\n",
      "Epoch [19/100], Loss: 0.0829\n",
      "Epoch [20/100], Loss: 0.0816\n",
      "Epoch [21/100], Loss: 0.0793\n",
      "Epoch [22/100], Loss: 0.0791\n",
      "Epoch [23/100], Loss: 0.0774\n",
      "Epoch [24/100], Loss: 0.0755\n",
      "Epoch [25/100], Loss: 0.0744\n",
      "Epoch [26/100], Loss: 0.0723\n",
      "Epoch [27/100], Loss: 0.0712\n",
      "Epoch [28/100], Loss: 0.0692\n",
      "Epoch [29/100], Loss: 0.0691\n",
      "Epoch [30/100], Loss: 0.0687\n",
      "Epoch [31/100], Loss: 0.0672\n",
      "Epoch [32/100], Loss: 0.0667\n",
      "Epoch [33/100], Loss: 0.0656\n",
      "Epoch [34/100], Loss: 0.0615\n",
      "Epoch [35/100], Loss: 0.0631\n",
      "Epoch [36/100], Loss: 0.0599\n",
      "Epoch [37/100], Loss: 0.0609\n",
      "Epoch [38/100], Loss: 0.0608\n",
      "Epoch [39/100], Loss: 0.0594\n",
      "Epoch [40/100], Loss: 0.0571\n",
      "Epoch [41/100], Loss: 0.0570\n",
      "Epoch [42/100], Loss: 0.0560\n",
      "Epoch [43/100], Loss: 0.0555\n",
      "Epoch [44/100], Loss: 0.0550\n",
      "Epoch [45/100], Loss: 0.0565\n",
      "Epoch [46/100], Loss: 0.0536\n",
      "Epoch [47/100], Loss: 0.0535\n",
      "Epoch [48/100], Loss: 0.0514\n",
      "Epoch [49/100], Loss: 0.0513\n",
      "Epoch [50/100], Loss: 0.0519\n",
      "Epoch [51/100], Loss: 0.0505\n",
      "Epoch [52/100], Loss: 0.0495\n",
      "Epoch [53/100], Loss: 0.0498\n",
      "Epoch [54/100], Loss: 0.0494\n",
      "Epoch [55/100], Loss: 0.0494\n",
      "Epoch [56/100], Loss: 0.0474\n",
      "Epoch [57/100], Loss: 0.0479\n",
      "Epoch [58/100], Loss: 0.0463\n",
      "Epoch [59/100], Loss: 0.0455\n",
      "Epoch [60/100], Loss: 0.0478\n",
      "Epoch [61/100], Loss: 0.0445\n",
      "Epoch [62/100], Loss: 0.0466\n",
      "Epoch [63/100], Loss: 0.0445\n",
      "Epoch [64/100], Loss: 0.0417\n",
      "Epoch [65/100], Loss: 0.0436\n",
      "Epoch [66/100], Loss: 0.0447\n",
      "Epoch [67/100], Loss: 0.0440\n",
      "Epoch [68/100], Loss: 0.0409\n",
      "Epoch [69/100], Loss: 0.0425\n",
      "Epoch [70/100], Loss: 0.0433\n",
      "Epoch [71/100], Loss: 0.0419\n",
      "Epoch [72/100], Loss: 0.0426\n",
      "Epoch [73/100], Loss: 0.0405\n",
      "Epoch [74/100], Loss: 0.0443\n",
      "Epoch [75/100], Loss: 0.0410\n",
      "Epoch [76/100], Loss: 0.0400\n",
      "Epoch [77/100], Loss: 0.0405\n",
      "Epoch [78/100], Loss: 0.0410\n",
      "Epoch [79/100], Loss: 0.0391\n",
      "Epoch [80/100], Loss: 0.0388\n",
      "Epoch [81/100], Loss: 0.0388\n",
      "Epoch [82/100], Loss: 0.0395\n",
      "Epoch [83/100], Loss: 0.0416\n",
      "Epoch [84/100], Loss: 0.0404\n",
      "Epoch [85/100], Loss: 0.0395\n",
      "Epoch [86/100], Loss: 0.0391\n",
      "Epoch [87/100], Loss: 0.0394\n",
      "Epoch [88/100], Loss: 0.0417\n",
      "Epoch [89/100], Loss: 0.0378\n",
      "Epoch [90/100], Loss: 0.0398\n",
      "Epoch [91/100], Loss: 0.0388\n",
      "Epoch [92/100], Loss: 0.0381\n",
      "Epoch [93/100], Loss: 0.0376\n",
      "Epoch [94/100], Loss: 0.0369\n",
      "Epoch [95/100], Loss: 0.0373\n",
      "Epoch [96/100], Loss: 0.0376\n",
      "Epoch [97/100], Loss: 0.0356\n",
      "Epoch [98/100], Loss: 0.0384\n",
      "Epoch [99/100], Loss: 0.0369\n",
      "Epoch [100/100], Loss: 0.0387\n",
      "update data..\n",
      "task data norm and number entries: tensor(452.0354, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859 93.80258179  0.          0.          0.        ]\n",
      "individual errors:  [array(98.77068, dtype=float32), array(88.83447, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1391\n",
      "Epoch [2/100], Loss: 0.1195\n",
      "Epoch [3/100], Loss: 0.1168\n",
      "Epoch [4/100], Loss: 0.1155\n",
      "Epoch [5/100], Loss: 0.1141\n",
      "Epoch [6/100], Loss: 0.1116\n",
      "Epoch [7/100], Loss: 0.1125\n",
      "Epoch [8/100], Loss: 0.1092\n",
      "Epoch [9/100], Loss: 0.1075\n",
      "Epoch [10/100], Loss: 0.1067\n",
      "Epoch [11/100], Loss: 0.1045\n",
      "Epoch [12/100], Loss: 0.1030\n",
      "Epoch [13/100], Loss: 0.1028\n",
      "Epoch [14/100], Loss: 0.1004\n",
      "Epoch [15/100], Loss: 0.0975\n",
      "Epoch [16/100], Loss: 0.0973\n",
      "Epoch [17/100], Loss: 0.0959\n",
      "Epoch [18/100], Loss: 0.0938\n",
      "Epoch [19/100], Loss: 0.0930\n",
      "Epoch [20/100], Loss: 0.0921\n",
      "Epoch [21/100], Loss: 0.0911\n",
      "Epoch [22/100], Loss: 0.0904\n",
      "Epoch [23/100], Loss: 0.0867\n",
      "Epoch [24/100], Loss: 0.0878\n",
      "Epoch [25/100], Loss: 0.0850\n",
      "Epoch [26/100], Loss: 0.0844\n",
      "Epoch [27/100], Loss: 0.0857\n",
      "Epoch [28/100], Loss: 0.0828\n",
      "Epoch [29/100], Loss: 0.0816\n",
      "Epoch [30/100], Loss: 0.0812\n",
      "Epoch [31/100], Loss: 0.0808\n",
      "Epoch [32/100], Loss: 0.0808\n",
      "Epoch [33/100], Loss: 0.0779\n",
      "Epoch [34/100], Loss: 0.0780\n",
      "Epoch [35/100], Loss: 0.0809\n",
      "Epoch [36/100], Loss: 0.0793\n",
      "Epoch [37/100], Loss: 0.0755\n",
      "Epoch [38/100], Loss: 0.0748\n",
      "Epoch [39/100], Loss: 0.0744\n",
      "Epoch [40/100], Loss: 0.0746\n",
      "Epoch [41/100], Loss: 0.0733\n",
      "Epoch [42/100], Loss: 0.0741\n",
      "Epoch [43/100], Loss: 0.0732\n",
      "Epoch [44/100], Loss: 0.0718\n",
      "Epoch [45/100], Loss: 0.0724\n",
      "Epoch [46/100], Loss: 0.0704\n",
      "Epoch [47/100], Loss: 0.0701\n",
      "Epoch [48/100], Loss: 0.0688\n",
      "Epoch [49/100], Loss: 0.0687\n",
      "Epoch [50/100], Loss: 0.0668\n",
      "Epoch [51/100], Loss: 0.0694\n",
      "Epoch [52/100], Loss: 0.0668\n",
      "Epoch [53/100], Loss: 0.0677\n",
      "Epoch [54/100], Loss: 0.0667\n",
      "Epoch [55/100], Loss: 0.0676\n",
      "Epoch [56/100], Loss: 0.0676\n",
      "Epoch [57/100], Loss: 0.0653\n",
      "Epoch [58/100], Loss: 0.0650\n",
      "Epoch [59/100], Loss: 0.0662\n",
      "Epoch [60/100], Loss: 0.0647\n",
      "Epoch [61/100], Loss: 0.0658\n",
      "Epoch [62/100], Loss: 0.0630\n",
      "Epoch [63/100], Loss: 0.0634\n",
      "Epoch [64/100], Loss: 0.0633\n",
      "Epoch [65/100], Loss: 0.0628\n",
      "Epoch [66/100], Loss: 0.0604\n",
      "Epoch [67/100], Loss: 0.0624\n",
      "Epoch [68/100], Loss: 0.0619\n",
      "Epoch [69/100], Loss: 0.0619\n",
      "Epoch [70/100], Loss: 0.0634\n",
      "Epoch [71/100], Loss: 0.0619\n",
      "Epoch [72/100], Loss: 0.0612\n",
      "Epoch [73/100], Loss: 0.0615\n",
      "Epoch [74/100], Loss: 0.0619\n",
      "Epoch [75/100], Loss: 0.0595\n",
      "Epoch [76/100], Loss: 0.0609\n",
      "Epoch [77/100], Loss: 0.0612\n",
      "Epoch [78/100], Loss: 0.0632\n",
      "Epoch [79/100], Loss: 0.0604\n",
      "Epoch [80/100], Loss: 0.0591\n",
      "Epoch [81/100], Loss: 0.0586\n",
      "Epoch [82/100], Loss: 0.0590\n",
      "Epoch [83/100], Loss: 0.0619\n",
      "Epoch [84/100], Loss: 0.0559\n",
      "Epoch [85/100], Loss: 0.0603\n",
      "Epoch [86/100], Loss: 0.0577\n",
      "Epoch [87/100], Loss: 0.0591\n",
      "Epoch [88/100], Loss: 0.0585\n",
      "Epoch [89/100], Loss: 0.0565\n",
      "Epoch [90/100], Loss: 0.0572\n",
      "Epoch [91/100], Loss: 0.0585\n",
      "Epoch [92/100], Loss: 0.0574\n",
      "Epoch [93/100], Loss: 0.0591\n",
      "Epoch [94/100], Loss: 0.0562\n",
      "Epoch [95/100], Loss: 0.0557\n",
      "Epoch [96/100], Loss: 0.0552\n",
      "Epoch [97/100], Loss: 0.0552\n",
      "Epoch [98/100], Loss: 0.0562\n",
      "Epoch [99/100], Loss: 0.0546\n",
      "Epoch [100/100], Loss: 0.0587\n",
      "update data..\n",
      "task data norm and number entries: tensor(435.5235, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859 93.80258179 88.45402527  0.          0.        ]\n",
      "individual errors:  [array(98.53428, dtype=float32), array(85.5044, dtype=float32), array(81.32337, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1393\n",
      "Epoch [2/100], Loss: 0.1256\n",
      "Epoch [3/100], Loss: 0.1223\n",
      "Epoch [4/100], Loss: 0.1206\n",
      "Epoch [5/100], Loss: 0.1187\n",
      "Epoch [6/100], Loss: 0.1179\n",
      "Epoch [7/100], Loss: 0.1146\n",
      "Epoch [8/100], Loss: 0.1125\n",
      "Epoch [9/100], Loss: 0.1119\n",
      "Epoch [10/100], Loss: 0.1090\n",
      "Epoch [11/100], Loss: 0.1077\n",
      "Epoch [12/100], Loss: 0.1073\n",
      "Epoch [13/100], Loss: 0.1028\n",
      "Epoch [14/100], Loss: 0.1026\n",
      "Epoch [15/100], Loss: 0.1001\n",
      "Epoch [16/100], Loss: 0.0976\n",
      "Epoch [17/100], Loss: 0.0968\n",
      "Epoch [18/100], Loss: 0.0955\n",
      "Epoch [19/100], Loss: 0.0930\n",
      "Epoch [20/100], Loss: 0.0929\n",
      "Epoch [21/100], Loss: 0.0904\n",
      "Epoch [22/100], Loss: 0.0901\n",
      "Epoch [23/100], Loss: 0.0888\n",
      "Epoch [24/100], Loss: 0.0849\n",
      "Epoch [25/100], Loss: 0.0847\n",
      "Epoch [26/100], Loss: 0.0842\n",
      "Epoch [27/100], Loss: 0.0827\n",
      "Epoch [28/100], Loss: 0.0833\n",
      "Epoch [29/100], Loss: 0.0810\n",
      "Epoch [30/100], Loss: 0.0806\n",
      "Epoch [31/100], Loss: 0.0801\n",
      "Epoch [32/100], Loss: 0.0758\n",
      "Epoch [33/100], Loss: 0.0771\n",
      "Epoch [34/100], Loss: 0.0769\n",
      "Epoch [35/100], Loss: 0.0765\n",
      "Epoch [36/100], Loss: 0.0754\n",
      "Epoch [37/100], Loss: 0.0746\n",
      "Epoch [38/100], Loss: 0.0746\n",
      "Epoch [39/100], Loss: 0.0729\n",
      "Epoch [40/100], Loss: 0.0713\n",
      "Epoch [41/100], Loss: 0.0700\n",
      "Epoch [42/100], Loss: 0.0706\n",
      "Epoch [43/100], Loss: 0.0697\n",
      "Epoch [44/100], Loss: 0.0686\n",
      "Epoch [45/100], Loss: 0.0696\n",
      "Epoch [46/100], Loss: 0.0680\n",
      "Epoch [47/100], Loss: 0.0687\n",
      "Epoch [48/100], Loss: 0.0666\n",
      "Epoch [49/100], Loss: 0.0658\n",
      "Epoch [50/100], Loss: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Loss: 0.0666\n",
      "Epoch [52/100], Loss: 0.0658\n",
      "Epoch [53/100], Loss: 0.0647\n",
      "Epoch [54/100], Loss: 0.0644\n",
      "Epoch [55/100], Loss: 0.0620\n",
      "Epoch [56/100], Loss: 0.0642\n",
      "Epoch [57/100], Loss: 0.0633\n",
      "Epoch [58/100], Loss: 0.0638\n",
      "Epoch [59/100], Loss: 0.0638\n",
      "Epoch [60/100], Loss: 0.0623\n",
      "Epoch [61/100], Loss: 0.0606\n",
      "Epoch [62/100], Loss: 0.0602\n",
      "Epoch [63/100], Loss: 0.0607\n",
      "Epoch [64/100], Loss: 0.0597\n",
      "Epoch [65/100], Loss: 0.0611\n",
      "Epoch [66/100], Loss: 0.0607\n",
      "Epoch [67/100], Loss: 0.0598\n",
      "Epoch [68/100], Loss: 0.0584\n",
      "Epoch [69/100], Loss: 0.0610\n",
      "Epoch [70/100], Loss: 0.0587\n",
      "Epoch [71/100], Loss: 0.0597\n",
      "Epoch [72/100], Loss: 0.0596\n",
      "Epoch [73/100], Loss: 0.0590\n",
      "Epoch [74/100], Loss: 0.0590\n",
      "Epoch [75/100], Loss: 0.0573\n",
      "Epoch [76/100], Loss: 0.0584\n",
      "Epoch [77/100], Loss: 0.0577\n",
      "Epoch [78/100], Loss: 0.0568\n",
      "Epoch [79/100], Loss: 0.0570\n",
      "Epoch [80/100], Loss: 0.0571\n",
      "Epoch [81/100], Loss: 0.0577\n",
      "Epoch [82/100], Loss: 0.0570\n",
      "Epoch [83/100], Loss: 0.0569\n",
      "Epoch [84/100], Loss: 0.0560\n",
      "Epoch [85/100], Loss: 0.0558\n",
      "Epoch [86/100], Loss: 0.0577\n",
      "Epoch [87/100], Loss: 0.0565\n",
      "Epoch [88/100], Loss: 0.0584\n",
      "Epoch [89/100], Loss: 0.0573\n",
      "Epoch [90/100], Loss: 0.0560\n",
      "Epoch [91/100], Loss: 0.0567\n",
      "Epoch [92/100], Loss: 0.0562\n",
      "Epoch [93/100], Loss: 0.0554\n",
      "Epoch [94/100], Loss: 0.0568\n",
      "Epoch [95/100], Loss: 0.0542\n",
      "Epoch [96/100], Loss: 0.0549\n",
      "Epoch [97/100], Loss: 0.0572\n",
      "Epoch [98/100], Loss: 0.0551\n",
      "Epoch [99/100], Loss: 0.0546\n",
      "Epoch [100/100], Loss: 0.0562\n",
      "update data..\n",
      "task data norm and number entries: tensor(454.7788, device='cuda:0') torch.Size([3200, 31370])\n",
      "..done\n",
      "test performance :  [99.71630859 93.80258179 88.45402527 86.75229645  0.        ]\n",
      "individual errors:  [array(97.44681, dtype=float32), array(83.59451, dtype=float32), array(76.89434, dtype=float32), array(89.07352, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1332\n",
      "Epoch [2/100], Loss: 0.1229\n",
      "Epoch [3/100], Loss: 0.1204\n",
      "Epoch [4/100], Loss: 0.1196\n",
      "Epoch [5/100], Loss: 0.1187\n",
      "Epoch [6/100], Loss: 0.1184\n",
      "Epoch [7/100], Loss: 0.1165\n",
      "Epoch [8/100], Loss: 0.1160\n",
      "Epoch [9/100], Loss: 0.1149\n",
      "Epoch [10/100], Loss: 0.1144\n",
      "Epoch [11/100], Loss: 0.1133\n",
      "Epoch [12/100], Loss: 0.1124\n",
      "Epoch [13/100], Loss: 0.1149\n",
      "Epoch [14/100], Loss: 0.1092\n",
      "Epoch [15/100], Loss: 0.1103\n",
      "Epoch [16/100], Loss: 0.1086\n",
      "Epoch [17/100], Loss: 0.1066\n",
      "Epoch [18/100], Loss: 0.1063\n",
      "Epoch [19/100], Loss: 0.1057\n",
      "Epoch [20/100], Loss: 0.1043\n",
      "Epoch [21/100], Loss: 0.1056\n",
      "Epoch [22/100], Loss: 0.1028\n",
      "Epoch [23/100], Loss: 0.1031\n",
      "Epoch [24/100], Loss: 0.1019\n",
      "Epoch [25/100], Loss: 0.1017\n",
      "Epoch [26/100], Loss: 0.1014\n",
      "Epoch [27/100], Loss: 0.1015\n",
      "Epoch [28/100], Loss: 0.0998\n",
      "Epoch [29/100], Loss: 0.1002\n",
      "Epoch [30/100], Loss: 0.0987\n",
      "Epoch [31/100], Loss: 0.0985\n",
      "Epoch [32/100], Loss: 0.0980\n",
      "Epoch [33/100], Loss: 0.0973\n",
      "Epoch [34/100], Loss: 0.0963\n",
      "Epoch [35/100], Loss: 0.0960\n",
      "Epoch [36/100], Loss: 0.0972\n",
      "Epoch [37/100], Loss: 0.0955\n",
      "Epoch [38/100], Loss: 0.0960\n",
      "Epoch [39/100], Loss: 0.0970\n",
      "Epoch [40/100], Loss: 0.0961\n",
      "Epoch [41/100], Loss: 0.0941\n",
      "Epoch [42/100], Loss: 0.0947\n",
      "Epoch [43/100], Loss: 0.0944\n",
      "Epoch [44/100], Loss: 0.0955\n",
      "Epoch [45/100], Loss: 0.0927\n",
      "Epoch [46/100], Loss: 0.0929\n",
      "Epoch [47/100], Loss: 0.0936\n",
      "Epoch [48/100], Loss: 0.0922\n",
      "Epoch [49/100], Loss: 0.0929\n",
      "Epoch [50/100], Loss: 0.0913\n",
      "Epoch [51/100], Loss: 0.0912\n",
      "Epoch [52/100], Loss: 0.0903\n",
      "Epoch [53/100], Loss: 0.0905\n",
      "Epoch [54/100], Loss: 0.0923\n",
      "Epoch [55/100], Loss: 0.0901\n",
      "Epoch [56/100], Loss: 0.0907\n",
      "Epoch [57/100], Loss: 0.0904\n",
      "Epoch [58/100], Loss: 0.0891\n",
      "Epoch [59/100], Loss: 0.0892\n",
      "Epoch [60/100], Loss: 0.0897\n",
      "Epoch [61/100], Loss: 0.0878\n",
      "Epoch [62/100], Loss: 0.0898\n",
      "Epoch [63/100], Loss: 0.0895\n",
      "Epoch [64/100], Loss: 0.0874\n",
      "Epoch [65/100], Loss: 0.0890\n",
      "Epoch [66/100], Loss: 0.0885\n",
      "Epoch [67/100], Loss: 0.0881\n",
      "Epoch [68/100], Loss: 0.0872\n",
      "Epoch [69/100], Loss: 0.0864\n",
      "Epoch [70/100], Loss: 0.0873\n",
      "Epoch [71/100], Loss: 0.0863\n",
      "Epoch [72/100], Loss: 0.0887\n",
      "Epoch [73/100], Loss: 0.0857\n",
      "Epoch [74/100], Loss: 0.0869\n",
      "Epoch [75/100], Loss: 0.0861\n",
      "Epoch [76/100], Loss: 0.0888\n",
      "Epoch [77/100], Loss: 0.0847\n",
      "Epoch [78/100], Loss: 0.0874\n",
      "Epoch [79/100], Loss: 0.0873\n",
      "Epoch [80/100], Loss: 0.0864\n",
      "Epoch [81/100], Loss: 0.0849\n",
      "Epoch [82/100], Loss: 0.0857\n",
      "Epoch [83/100], Loss: 0.0854\n",
      "Epoch [84/100], Loss: 0.0840\n",
      "Epoch [85/100], Loss: 0.0868\n",
      "Epoch [86/100], Loss: 0.0838\n",
      "Epoch [87/100], Loss: 0.0863\n",
      "Epoch [88/100], Loss: 0.0838\n",
      "Epoch [89/100], Loss: 0.0838\n",
      "Epoch [90/100], Loss: 0.0859\n",
      "Epoch [91/100], Loss: 0.0838\n",
      "Epoch [92/100], Loss: 0.0843\n",
      "Epoch [93/100], Loss: 0.0852\n",
      "Epoch [94/100], Loss: 0.0854\n",
      "Epoch [95/100], Loss: 0.0841\n",
      "Epoch [96/100], Loss: 0.0830\n",
      "Epoch [97/100], Loss: 0.0846\n",
      "Epoch [98/100], Loss: 0.0830\n",
      "Epoch [99/100], Loss: 0.0840\n",
      "Epoch [100/100], Loss: 0.0833\n",
      "test performance :  [99.71630859 93.80258179 88.45402527 86.75229645 81.88118744]\n",
      "individual errors:  [array(97.39953, dtype=float32), array(82.32125, dtype=float32), array(71.824974, dtype=float32), array(87.76435, dtype=float32), array(70.09582, dtype=float32)]\n",
      "EWC++  6400 1e-05\n",
      "Epoch [1/100], Loss: 0.1000\n",
      "Epoch [2/100], Loss: 0.0497\n",
      "Epoch [3/100], Loss: 0.0482\n",
      "Epoch [4/100], Loss: 0.0462\n",
      "Epoch [5/100], Loss: 0.0451\n",
      "Epoch [6/100], Loss: 0.0432\n",
      "Epoch [7/100], Loss: 0.0416\n",
      "Epoch [8/100], Loss: 0.0400\n",
      "Epoch [9/100], Loss: 0.0385\n",
      "Epoch [10/100], Loss: 0.0359\n",
      "Epoch [11/100], Loss: 0.0346\n",
      "Epoch [12/100], Loss: 0.0334\n",
      "Epoch [13/100], Loss: 0.0318\n",
      "Epoch [14/100], Loss: 0.0295\n",
      "Epoch [15/100], Loss: 0.0290\n",
      "Epoch [16/100], Loss: 0.0271\n",
      "Epoch [17/100], Loss: 0.0259\n",
      "Epoch [18/100], Loss: 0.0249\n",
      "Epoch [19/100], Loss: 0.0234\n",
      "Epoch [20/100], Loss: 0.0224\n",
      "Epoch [21/100], Loss: 0.0210\n",
      "Epoch [22/100], Loss: 0.0194\n",
      "Epoch [23/100], Loss: 0.0190\n",
      "Epoch [24/100], Loss: 0.0181\n",
      "Epoch [25/100], Loss: 0.0163\n",
      "Epoch [26/100], Loss: 0.0161\n",
      "Epoch [27/100], Loss: 0.0145\n",
      "Epoch [28/100], Loss: 0.0142\n",
      "Epoch [29/100], Loss: 0.0134\n",
      "Epoch [30/100], Loss: 0.0125\n",
      "Epoch [31/100], Loss: 0.0124\n",
      "Epoch [32/100], Loss: 0.0119\n",
      "Epoch [33/100], Loss: 0.0113\n",
      "Epoch [34/100], Loss: 0.0101\n",
      "Epoch [35/100], Loss: 0.0099\n",
      "Epoch [36/100], Loss: 0.0101\n",
      "Epoch [37/100], Loss: 0.0092\n",
      "Epoch [38/100], Loss: 0.0097\n",
      "Epoch [39/100], Loss: 0.0084\n",
      "Epoch [40/100], Loss: 0.0086\n",
      "Epoch [41/100], Loss: 0.0080\n",
      "Epoch [42/100], Loss: 0.0072\n",
      "Epoch [43/100], Loss: 0.0074\n",
      "Epoch [44/100], Loss: 0.0072\n",
      "Epoch [45/100], Loss: 0.0058\n",
      "Epoch [46/100], Loss: 0.0066\n",
      "Epoch [47/100], Loss: 0.0061\n",
      "Epoch [48/100], Loss: 0.0065\n",
      "Epoch [49/100], Loss: 0.0055\n",
      "Epoch [50/100], Loss: 0.0054\n",
      "Epoch [51/100], Loss: 0.0048\n",
      "Epoch [52/100], Loss: 0.0057\n",
      "Epoch [53/100], Loss: 0.0051\n",
      "Epoch [54/100], Loss: 0.0051\n",
      "Epoch [55/100], Loss: 0.0049\n",
      "Epoch [56/100], Loss: 0.0049\n",
      "Epoch [57/100], Loss: 0.0046\n",
      "Epoch [58/100], Loss: 0.0044\n",
      "Epoch [59/100], Loss: 0.0046\n",
      "Epoch [60/100], Loss: 0.0041\n",
      "Epoch [61/100], Loss: 0.0048\n",
      "Epoch [62/100], Loss: 0.0040\n",
      "Epoch [63/100], Loss: 0.0041\n",
      "Epoch [64/100], Loss: 0.0042\n",
      "Epoch [65/100], Loss: 0.0041\n",
      "Epoch [66/100], Loss: 0.0048\n",
      "Epoch [67/100], Loss: 0.0045\n",
      "Epoch [68/100], Loss: 0.0041\n",
      "Epoch [69/100], Loss: 0.0042\n",
      "Epoch [70/100], Loss: 0.0040\n",
      "Epoch [71/100], Loss: 0.0038\n",
      "Epoch [72/100], Loss: 0.0044\n",
      "Epoch [73/100], Loss: 0.0037\n",
      "Epoch [74/100], Loss: 0.0034\n",
      "Epoch [75/100], Loss: 0.0037\n",
      "Epoch [76/100], Loss: 0.0036\n",
      "Epoch [77/100], Loss: 0.0045\n",
      "Epoch [78/100], Loss: 0.0042\n",
      "Epoch [79/100], Loss: 0.0043\n",
      "Epoch [80/100], Loss: 0.0045\n",
      "Epoch [81/100], Loss: 0.0037\n",
      "Epoch [82/100], Loss: 0.0036\n",
      "Epoch [83/100], Loss: 0.0035\n",
      "Epoch [84/100], Loss: 0.0039\n",
      "Epoch [85/100], Loss: 0.0043\n",
      "Epoch [86/100], Loss: 0.0044\n",
      "Epoch [87/100], Loss: 0.0038\n",
      "Epoch [88/100], Loss: 0.0039\n",
      "Epoch [89/100], Loss: 0.0034\n",
      "Epoch [90/100], Loss: 0.0040\n",
      "Epoch [91/100], Loss: 0.0038\n",
      "Epoch [92/100], Loss: 0.0039\n",
      "Epoch [93/100], Loss: 0.0036\n",
      "Epoch [94/100], Loss: 0.0033\n",
      "Epoch [95/100], Loss: 0.0039\n",
      "Epoch [96/100], Loss: 0.0036\n",
      "Epoch [97/100], Loss: 0.0038\n",
      "Epoch [98/100], Loss: 0.0044\n",
      "Epoch [99/100], Loss: 0.0031\n",
      "Epoch [100/100], Loss: 0.0039\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(462.7638, device='cuda:0') torch.Size([6400, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  0.         0.         0.         0.       ]\n",
      "individual errors:  [array(99.858154, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1561\n",
      "Epoch [2/100], Loss: 0.1127\n",
      "Epoch [3/100], Loss: 0.1108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 0.1086\n",
      "Epoch [5/100], Loss: 0.1079\n",
      "Epoch [6/100], Loss: 0.1064\n",
      "Epoch [7/100], Loss: 0.1043\n",
      "Epoch [8/100], Loss: 0.1025\n",
      "Epoch [9/100], Loss: 0.1011\n",
      "Epoch [10/100], Loss: 0.0995\n",
      "Epoch [11/100], Loss: 0.0975\n",
      "Epoch [12/100], Loss: 0.0961\n",
      "Epoch [13/100], Loss: 0.0943\n",
      "Epoch [14/100], Loss: 0.0928\n",
      "Epoch [15/100], Loss: 0.0910\n",
      "Epoch [16/100], Loss: 0.0894\n",
      "Epoch [17/100], Loss: 0.0878\n",
      "Epoch [18/100], Loss: 0.0865\n",
      "Epoch [19/100], Loss: 0.0846\n",
      "Epoch [20/100], Loss: 0.0830\n",
      "Epoch [21/100], Loss: 0.0823\n",
      "Epoch [22/100], Loss: 0.0800\n",
      "Epoch [23/100], Loss: 0.0781\n",
      "Epoch [24/100], Loss: 0.0769\n",
      "Epoch [25/100], Loss: 0.0772\n",
      "Epoch [26/100], Loss: 0.0745\n",
      "Epoch [27/100], Loss: 0.0740\n",
      "Epoch [28/100], Loss: 0.0727\n",
      "Epoch [29/100], Loss: 0.0719\n",
      "Epoch [30/100], Loss: 0.0683\n",
      "Epoch [31/100], Loss: 0.0690\n",
      "Epoch [32/100], Loss: 0.0671\n",
      "Epoch [33/100], Loss: 0.0666\n",
      "Epoch [34/100], Loss: 0.0646\n",
      "Epoch [35/100], Loss: 0.0657\n",
      "Epoch [36/100], Loss: 0.0635\n",
      "Epoch [37/100], Loss: 0.0623\n",
      "Epoch [38/100], Loss: 0.0623\n",
      "Epoch [39/100], Loss: 0.0617\n",
      "Epoch [40/100], Loss: 0.0594\n",
      "Epoch [41/100], Loss: 0.0590\n",
      "Epoch [42/100], Loss: 0.0576\n",
      "Epoch [43/100], Loss: 0.0575\n",
      "Epoch [44/100], Loss: 0.0569\n",
      "Epoch [45/100], Loss: 0.0555\n",
      "Epoch [46/100], Loss: 0.0550\n",
      "Epoch [47/100], Loss: 0.0555\n",
      "Epoch [48/100], Loss: 0.0527\n",
      "Epoch [49/100], Loss: 0.0533\n",
      "Epoch [50/100], Loss: 0.0542\n",
      "Epoch [51/100], Loss: 0.0522\n",
      "Epoch [52/100], Loss: 0.0509\n",
      "Epoch [53/100], Loss: 0.0517\n",
      "Epoch [54/100], Loss: 0.0494\n",
      "Epoch [55/100], Loss: 0.0483\n",
      "Epoch [56/100], Loss: 0.0485\n",
      "Epoch [57/100], Loss: 0.0485\n",
      "Epoch [58/100], Loss: 0.0480\n",
      "Epoch [59/100], Loss: 0.0488\n",
      "Epoch [60/100], Loss: 0.0470\n",
      "Epoch [61/100], Loss: 0.0461\n",
      "Epoch [62/100], Loss: 0.0453\n",
      "Epoch [63/100], Loss: 0.0460\n",
      "Epoch [64/100], Loss: 0.0465\n",
      "Epoch [65/100], Loss: 0.0457\n",
      "Epoch [66/100], Loss: 0.0458\n",
      "Epoch [67/100], Loss: 0.0438\n",
      "Epoch [68/100], Loss: 0.0448\n",
      "Epoch [69/100], Loss: 0.0456\n",
      "Epoch [70/100], Loss: 0.0442\n",
      "Epoch [71/100], Loss: 0.0446\n",
      "Epoch [72/100], Loss: 0.0434\n",
      "Epoch [73/100], Loss: 0.0421\n",
      "Epoch [74/100], Loss: 0.0421\n",
      "Epoch [75/100], Loss: 0.0402\n",
      "Epoch [76/100], Loss: 0.0405\n",
      "Epoch [77/100], Loss: 0.0406\n",
      "Epoch [78/100], Loss: 0.0424\n",
      "Epoch [79/100], Loss: 0.0428\n",
      "Epoch [80/100], Loss: 0.0396\n",
      "Epoch [81/100], Loss: 0.0428\n",
      "Epoch [82/100], Loss: 0.0411\n",
      "Epoch [83/100], Loss: 0.0391\n",
      "Epoch [84/100], Loss: 0.0421\n",
      "Epoch [85/100], Loss: 0.0409\n",
      "Epoch [86/100], Loss: 0.0417\n",
      "Epoch [87/100], Loss: 0.0403\n",
      "Epoch [88/100], Loss: 0.0400\n",
      "Epoch [89/100], Loss: 0.0381\n",
      "Epoch [90/100], Loss: 0.0379\n",
      "Epoch [91/100], Loss: 0.0379\n",
      "Epoch [92/100], Loss: 0.0402\n",
      "Epoch [93/100], Loss: 0.0397\n",
      "Epoch [94/100], Loss: 0.0384\n",
      "Epoch [95/100], Loss: 0.0403\n",
      "Epoch [96/100], Loss: 0.0382\n",
      "Epoch [97/100], Loss: 0.0391\n",
      "Epoch [98/100], Loss: 0.0370\n",
      "Epoch [99/100], Loss: 0.0381\n",
      "Epoch [100/100], Loss: 0.0389\n",
      "update data..\n",
      "task data norm and number entries: tensor(452.4038, device='cuda:0') torch.Size([6400, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543 93.557724   0.         0.         0.       ]\n",
      "individual errors:  [array(98.77068, dtype=float32), array(88.34476, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1393\n",
      "Epoch [2/100], Loss: 0.1210\n",
      "Epoch [3/100], Loss: 0.1162\n",
      "Epoch [4/100], Loss: 0.1151\n",
      "Epoch [5/100], Loss: 0.1136\n",
      "Epoch [6/100], Loss: 0.1135\n",
      "Epoch [7/100], Loss: 0.1102\n",
      "Epoch [8/100], Loss: 0.1105\n",
      "Epoch [9/100], Loss: 0.1073\n",
      "Epoch [10/100], Loss: 0.1069\n",
      "Epoch [11/100], Loss: 0.1056\n",
      "Epoch [12/100], Loss: 0.1036\n",
      "Epoch [13/100], Loss: 0.1031\n",
      "Epoch [14/100], Loss: 0.1016\n",
      "Epoch [15/100], Loss: 0.0999\n",
      "Epoch [16/100], Loss: 0.0987\n",
      "Epoch [17/100], Loss: 0.0975\n",
      "Epoch [18/100], Loss: 0.0954\n",
      "Epoch [19/100], Loss: 0.0939\n",
      "Epoch [20/100], Loss: 0.0926\n",
      "Epoch [21/100], Loss: 0.0916\n",
      "Epoch [22/100], Loss: 0.0921\n",
      "Epoch [23/100], Loss: 0.0911\n",
      "Epoch [24/100], Loss: 0.0870\n",
      "Epoch [25/100], Loss: 0.0876\n",
      "Epoch [26/100], Loss: 0.0871\n",
      "Epoch [27/100], Loss: 0.0846\n",
      "Epoch [28/100], Loss: 0.0842\n",
      "Epoch [29/100], Loss: 0.0837\n",
      "Epoch [30/100], Loss: 0.0830\n",
      "Epoch [31/100], Loss: 0.0823\n",
      "Epoch [32/100], Loss: 0.0830\n",
      "Epoch [33/100], Loss: 0.0819\n",
      "Epoch [34/100], Loss: 0.0813\n",
      "Epoch [35/100], Loss: 0.0789\n",
      "Epoch [36/100], Loss: 0.0771\n",
      "Epoch [37/100], Loss: 0.0778\n",
      "Epoch [38/100], Loss: 0.0769\n",
      "Epoch [39/100], Loss: 0.0757\n",
      "Epoch [40/100], Loss: 0.0749\n",
      "Epoch [41/100], Loss: 0.0746\n",
      "Epoch [42/100], Loss: 0.0759\n",
      "Epoch [43/100], Loss: 0.0741\n",
      "Epoch [44/100], Loss: 0.0742\n",
      "Epoch [45/100], Loss: 0.0714\n",
      "Epoch [46/100], Loss: 0.0728\n",
      "Epoch [47/100], Loss: 0.0713\n",
      "Epoch [48/100], Loss: 0.0714\n",
      "Epoch [49/100], Loss: 0.0713\n",
      "Epoch [50/100], Loss: 0.0706\n",
      "Epoch [51/100], Loss: 0.0684\n",
      "Epoch [52/100], Loss: 0.0684\n",
      "Epoch [53/100], Loss: 0.0685\n",
      "Epoch [54/100], Loss: 0.0675\n",
      "Epoch [55/100], Loss: 0.0686\n",
      "Epoch [56/100], Loss: 0.0676\n",
      "Epoch [57/100], Loss: 0.0679\n",
      "Epoch [58/100], Loss: 0.0642\n",
      "Epoch [59/100], Loss: 0.0670\n",
      "Epoch [60/100], Loss: 0.0657\n",
      "Epoch [61/100], Loss: 0.0637\n",
      "Epoch [62/100], Loss: 0.0673\n",
      "Epoch [63/100], Loss: 0.0665\n",
      "Epoch [64/100], Loss: 0.0647\n",
      "Epoch [65/100], Loss: 0.0646\n",
      "Epoch [66/100], Loss: 0.0664\n",
      "Epoch [67/100], Loss: 0.0653\n",
      "Epoch [68/100], Loss: 0.0659\n",
      "Epoch [69/100], Loss: 0.0639\n",
      "Epoch [70/100], Loss: 0.0621\n",
      "Epoch [71/100], Loss: 0.0642\n",
      "Epoch [72/100], Loss: 0.0616\n",
      "Epoch [73/100], Loss: 0.0622\n",
      "Epoch [74/100], Loss: 0.0613\n",
      "Epoch [75/100], Loss: 0.0624\n",
      "Epoch [76/100], Loss: 0.0599\n",
      "Epoch [77/100], Loss: 0.0618\n",
      "Epoch [78/100], Loss: 0.0604\n",
      "Epoch [79/100], Loss: 0.0616\n",
      "Epoch [80/100], Loss: 0.0621\n",
      "Epoch [81/100], Loss: 0.0584\n",
      "Epoch [82/100], Loss: 0.0618\n",
      "Epoch [83/100], Loss: 0.0598\n",
      "Epoch [84/100], Loss: 0.0614\n",
      "Epoch [85/100], Loss: 0.0602\n",
      "Epoch [86/100], Loss: 0.0579\n",
      "Epoch [87/100], Loss: 0.0600\n",
      "Epoch [88/100], Loss: 0.0595\n",
      "Epoch [89/100], Loss: 0.0587\n",
      "Epoch [90/100], Loss: 0.0576\n",
      "Epoch [91/100], Loss: 0.0576\n",
      "Epoch [92/100], Loss: 0.0587\n",
      "Epoch [93/100], Loss: 0.0583\n",
      "Epoch [94/100], Loss: 0.0591\n",
      "Epoch [95/100], Loss: 0.0563\n",
      "Epoch [96/100], Loss: 0.0571\n",
      "Epoch [97/100], Loss: 0.0589\n",
      "Epoch [98/100], Loss: 0.0584\n",
      "Epoch [99/100], Loss: 0.0560\n",
      "Epoch [100/100], Loss: 0.0562\n",
      "update data..\n",
      "task data norm and number entries: tensor(436.7426, device='cuda:0') torch.Size([6400, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.557724   87.34118652  0.          0.        ]\n",
      "individual errors:  [array(98.39243, dtype=float32), array(86.04309, dtype=float32), array(77.58804, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1377\n",
      "Epoch [2/100], Loss: 0.1222\n",
      "Epoch [3/100], Loss: 0.1197\n",
      "Epoch [4/100], Loss: 0.1173\n",
      "Epoch [5/100], Loss: 0.1165\n",
      "Epoch [6/100], Loss: 0.1148\n",
      "Epoch [7/100], Loss: 0.1132\n",
      "Epoch [8/100], Loss: 0.1105\n",
      "Epoch [9/100], Loss: 0.1094\n",
      "Epoch [10/100], Loss: 0.1075\n",
      "Epoch [11/100], Loss: 0.1054\n",
      "Epoch [12/100], Loss: 0.1022\n",
      "Epoch [13/100], Loss: 0.1019\n",
      "Epoch [14/100], Loss: 0.1004\n",
      "Epoch [15/100], Loss: 0.0994\n",
      "Epoch [16/100], Loss: 0.0975\n",
      "Epoch [17/100], Loss: 0.0949\n",
      "Epoch [18/100], Loss: 0.0936\n",
      "Epoch [19/100], Loss: 0.0922\n",
      "Epoch [20/100], Loss: 0.0910\n",
      "Epoch [21/100], Loss: 0.0884\n",
      "Epoch [22/100], Loss: 0.0891\n",
      "Epoch [23/100], Loss: 0.0873\n",
      "Epoch [24/100], Loss: 0.0862\n",
      "Epoch [25/100], Loss: 0.0838\n",
      "Epoch [26/100], Loss: 0.0839\n",
      "Epoch [27/100], Loss: 0.0822\n",
      "Epoch [28/100], Loss: 0.0812\n",
      "Epoch [29/100], Loss: 0.0803\n",
      "Epoch [30/100], Loss: 0.0793\n",
      "Epoch [31/100], Loss: 0.0766\n",
      "Epoch [32/100], Loss: 0.0763\n",
      "Epoch [33/100], Loss: 0.0762\n",
      "Epoch [34/100], Loss: 0.0761\n",
      "Epoch [35/100], Loss: 0.0753\n",
      "Epoch [36/100], Loss: 0.0740\n",
      "Epoch [37/100], Loss: 0.0725\n",
      "Epoch [38/100], Loss: 0.0717\n",
      "Epoch [39/100], Loss: 0.0721\n",
      "Epoch [40/100], Loss: 0.0707\n",
      "Epoch [41/100], Loss: 0.0712\n",
      "Epoch [42/100], Loss: 0.0697\n",
      "Epoch [43/100], Loss: 0.0701\n",
      "Epoch [44/100], Loss: 0.0682\n",
      "Epoch [45/100], Loss: 0.0675\n",
      "Epoch [46/100], Loss: 0.0664\n",
      "Epoch [47/100], Loss: 0.0667\n",
      "Epoch [48/100], Loss: 0.0670\n",
      "Epoch [49/100], Loss: 0.0666\n",
      "Epoch [50/100], Loss: 0.0645\n",
      "Epoch [51/100], Loss: 0.0647\n",
      "Epoch [52/100], Loss: 0.0636\n",
      "Epoch [53/100], Loss: 0.0625\n",
      "Epoch [54/100], Loss: 0.0651\n",
      "Epoch [55/100], Loss: 0.0636\n",
      "Epoch [56/100], Loss: 0.0608\n",
      "Epoch [57/100], Loss: 0.0633\n",
      "Epoch [58/100], Loss: 0.0623\n",
      "Epoch [59/100], Loss: 0.0617\n",
      "Epoch [60/100], Loss: 0.0620\n",
      "Epoch [61/100], Loss: 0.0609\n",
      "Epoch [62/100], Loss: 0.0610\n",
      "Epoch [63/100], Loss: 0.0594\n",
      "Epoch [64/100], Loss: 0.0596\n",
      "Epoch [65/100], Loss: 0.0604\n",
      "Epoch [66/100], Loss: 0.0581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Loss: 0.0606\n",
      "Epoch [68/100], Loss: 0.0595\n",
      "Epoch [69/100], Loss: 0.0572\n",
      "Epoch [70/100], Loss: 0.0596\n",
      "Epoch [71/100], Loss: 0.0584\n",
      "Epoch [72/100], Loss: 0.0577\n",
      "Epoch [73/100], Loss: 0.0567\n",
      "Epoch [74/100], Loss: 0.0561\n",
      "Epoch [75/100], Loss: 0.0571\n",
      "Epoch [76/100], Loss: 0.0558\n",
      "Epoch [77/100], Loss: 0.0555\n",
      "Epoch [78/100], Loss: 0.0562\n",
      "Epoch [79/100], Loss: 0.0571\n",
      "Epoch [80/100], Loss: 0.0562\n",
      "Epoch [81/100], Loss: 0.0579\n",
      "Epoch [82/100], Loss: 0.0568\n",
      "Epoch [83/100], Loss: 0.0542\n",
      "Epoch [84/100], Loss: 0.0554\n",
      "Epoch [85/100], Loss: 0.0558\n",
      "Epoch [86/100], Loss: 0.0545\n",
      "Epoch [87/100], Loss: 0.0551\n",
      "Epoch [88/100], Loss: 0.0566\n",
      "Epoch [89/100], Loss: 0.0551\n",
      "Epoch [90/100], Loss: 0.0563\n",
      "Epoch [91/100], Loss: 0.0579\n",
      "Epoch [92/100], Loss: 0.0549\n",
      "Epoch [93/100], Loss: 0.0537\n",
      "Epoch [94/100], Loss: 0.0554\n",
      "Epoch [95/100], Loss: 0.0534\n",
      "Epoch [96/100], Loss: 0.0559\n",
      "Epoch [97/100], Loss: 0.0552\n",
      "Epoch [98/100], Loss: 0.0547\n",
      "Epoch [99/100], Loss: 0.0543\n",
      "Epoch [100/100], Loss: 0.0543\n",
      "update data..\n",
      "task data norm and number entries: tensor(453.9015, device='cuda:0') torch.Size([6400, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.557724   87.34118652 85.71626282  0.        ]\n",
      "individual errors:  [array(97.54137, dtype=float32), array(83.055824, dtype=float32), array(72.892204, dtype=float32), array(89.375626, dtype=float32)]\n",
      "Epoch [1/100], Loss: 0.1344\n",
      "Epoch [2/100], Loss: 0.1243\n",
      "Epoch [3/100], Loss: 0.1227\n",
      "Epoch [4/100], Loss: 0.1205\n",
      "Epoch [5/100], Loss: 0.1188\n",
      "Epoch [6/100], Loss: 0.1184\n",
      "Epoch [7/100], Loss: 0.1177\n",
      "Epoch [8/100], Loss: 0.1175\n",
      "Epoch [9/100], Loss: 0.1164\n",
      "Epoch [10/100], Loss: 0.1149\n",
      "Epoch [11/100], Loss: 0.1138\n",
      "Epoch [12/100], Loss: 0.1129\n",
      "Epoch [13/100], Loss: 0.1144\n",
      "Epoch [14/100], Loss: 0.1113\n",
      "Epoch [15/100], Loss: 0.1100\n",
      "Epoch [16/100], Loss: 0.1098\n",
      "Epoch [17/100], Loss: 0.1089\n",
      "Epoch [18/100], Loss: 0.1084\n",
      "Epoch [19/100], Loss: 0.1080\n",
      "Epoch [20/100], Loss: 0.1069\n",
      "Epoch [21/100], Loss: 0.1075\n",
      "Epoch [22/100], Loss: 0.1082\n",
      "Epoch [23/100], Loss: 0.1044\n",
      "Epoch [24/100], Loss: 0.1045\n",
      "Epoch [25/100], Loss: 0.1037\n",
      "Epoch [26/100], Loss: 0.1030\n",
      "Epoch [27/100], Loss: 0.1025\n",
      "Epoch [28/100], Loss: 0.1014\n",
      "Epoch [29/100], Loss: 0.1020\n",
      "Epoch [30/100], Loss: 0.1002\n",
      "Epoch [31/100], Loss: 0.1004\n",
      "Epoch [32/100], Loss: 0.0995\n",
      "Epoch [33/100], Loss: 0.0989\n",
      "Epoch [34/100], Loss: 0.0981\n",
      "Epoch [35/100], Loss: 0.0976\n",
      "Epoch [36/100], Loss: 0.0976\n",
      "Epoch [37/100], Loss: 0.0977\n",
      "Epoch [38/100], Loss: 0.0974\n",
      "Epoch [39/100], Loss: 0.0966\n",
      "Epoch [40/100], Loss: 0.0960\n",
      "Epoch [41/100], Loss: 0.0969\n",
      "Epoch [42/100], Loss: 0.0946\n",
      "Epoch [43/100], Loss: 0.0943\n",
      "Epoch [44/100], Loss: 0.0955\n",
      "Epoch [45/100], Loss: 0.0959\n",
      "Epoch [46/100], Loss: 0.0954\n",
      "Epoch [47/100], Loss: 0.0937\n",
      "Epoch [48/100], Loss: 0.0943\n",
      "Epoch [49/100], Loss: 0.0927\n",
      "Epoch [50/100], Loss: 0.0932\n",
      "Epoch [51/100], Loss: 0.0942\n",
      "Epoch [52/100], Loss: 0.0923\n",
      "Epoch [53/100], Loss: 0.0928\n",
      "Epoch [54/100], Loss: 0.0910\n",
      "Epoch [55/100], Loss: 0.0929\n",
      "Epoch [56/100], Loss: 0.0909\n",
      "Epoch [57/100], Loss: 0.0921\n",
      "Epoch [58/100], Loss: 0.0925\n",
      "Epoch [59/100], Loss: 0.0902\n",
      "Epoch [60/100], Loss: 0.0897\n",
      "Epoch [61/100], Loss: 0.0889\n",
      "Epoch [62/100], Loss: 0.0885\n",
      "Epoch [63/100], Loss: 0.0897\n",
      "Epoch [64/100], Loss: 0.0909\n",
      "Epoch [65/100], Loss: 0.0917\n",
      "Epoch [66/100], Loss: 0.0896\n",
      "Epoch [67/100], Loss: 0.0888\n",
      "Epoch [68/100], Loss: 0.0873\n",
      "Epoch [69/100], Loss: 0.0886\n",
      "Epoch [70/100], Loss: 0.0875\n",
      "Epoch [71/100], Loss: 0.0883\n",
      "Epoch [72/100], Loss: 0.0880\n",
      "Epoch [73/100], Loss: 0.0869\n",
      "Epoch [74/100], Loss: 0.0874\n",
      "Epoch [75/100], Loss: 0.0871\n",
      "Epoch [76/100], Loss: 0.0880\n",
      "Epoch [77/100], Loss: 0.0881\n",
      "Epoch [78/100], Loss: 0.0863\n",
      "Epoch [79/100], Loss: 0.0877\n",
      "Epoch [80/100], Loss: 0.0877\n",
      "Epoch [81/100], Loss: 0.0871\n",
      "Epoch [82/100], Loss: 0.0868\n",
      "Epoch [83/100], Loss: 0.0856\n",
      "Epoch [84/100], Loss: 0.0862\n",
      "Epoch [85/100], Loss: 0.0863\n",
      "Epoch [86/100], Loss: 0.0852\n",
      "Epoch [87/100], Loss: 0.0872\n",
      "Epoch [88/100], Loss: 0.0863\n",
      "Epoch [89/100], Loss: 0.0833\n",
      "Epoch [90/100], Loss: 0.0839\n",
      "Epoch [91/100], Loss: 0.0853\n",
      "Epoch [92/100], Loss: 0.0861\n",
      "Epoch [93/100], Loss: 0.0853\n",
      "Epoch [94/100], Loss: 0.0841\n",
      "Epoch [95/100], Loss: 0.0849\n",
      "Epoch [96/100], Loss: 0.0852\n",
      "Epoch [97/100], Loss: 0.0860\n",
      "Epoch [98/100], Loss: 0.0835\n",
      "Epoch [99/100], Loss: 0.0859\n",
      "Epoch [100/100], Loss: 0.0860\n",
      "test performance :  [99.8581543  93.557724   87.34118652 85.71626282 81.77747345]\n",
      "individual errors:  [array(97.16312, dtype=float32), array(83.93732, dtype=float32), array(71.23799, dtype=float32), array(87.814705, dtype=float32), array(68.73424, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "lr = 5e-3 # size of step\n",
    "results2 = []\n",
    "inderrors = []\n",
    "ss = [50,100,200,400,800,1600,3200,6400]\n",
    "for s in ss:\n",
    "    res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-5,s=s),num_epochs=num_epochs )\n",
    "    results2 += [res]\n",
    "    inderrors += [inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50, 5e-3, lam 5e-6 [99.71630859 86.61508942 64.12440491 56.21234894 54.12968445] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss = [50,100,200,400,800,1600,3200,6400]\n",
    "for res,s in zip(results,ss):\n",
    "    plt.plot(res,label=str(s),marker='x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss = [50,100,200,400,800,1600,3200,6400]\n",
    "for res,s in zip(results2,ss):\n",
    "    plt.plot(res,label=str(s),marker='x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  800 1e-05\n",
      "Epoch [1/50], Loss: 0.1005\n",
      "Epoch [2/50], Loss: 0.0635\n",
      "Epoch [3/50], Loss: 0.0424\n",
      "Epoch [4/50], Loss: 0.0328\n",
      "Epoch [5/50], Loss: 0.0272\n",
      "Epoch [6/50], Loss: 0.0218\n",
      "Epoch [7/50], Loss: 0.0180\n",
      "Epoch [8/50], Loss: 0.0138\n",
      "Epoch [9/50], Loss: 0.0117\n",
      "Epoch [10/50], Loss: 0.0099\n",
      "Epoch [11/50], Loss: 0.0072\n",
      "Epoch [12/50], Loss: 0.0065\n",
      "Epoch [13/50], Loss: 0.0059\n",
      "Epoch [14/50], Loss: 0.0058\n",
      "Epoch [15/50], Loss: 0.0051\n",
      "Epoch [16/50], Loss: 0.0048\n",
      "Epoch [17/50], Loss: 0.0042\n",
      "Epoch [18/50], Loss: 0.0044\n",
      "Epoch [19/50], Loss: 0.0048\n",
      "Epoch [20/50], Loss: 0.0054\n",
      "Epoch [21/50], Loss: 0.0046\n",
      "Epoch [22/50], Loss: 0.0037\n",
      "Epoch [23/50], Loss: 0.0045\n",
      "Epoch [24/50], Loss: 0.0040\n",
      "Epoch [25/50], Loss: 0.0041\n",
      "Epoch [26/50], Loss: 0.0040\n",
      "Epoch [27/50], Loss: 0.0044\n",
      "Epoch [28/50], Loss: 0.0052\n",
      "Epoch [29/50], Loss: 0.0040\n",
      "Epoch [30/50], Loss: 0.0036\n",
      "Epoch [31/50], Loss: 0.0038\n",
      "Epoch [32/50], Loss: 0.0038\n",
      "Epoch [33/50], Loss: 0.0039\n",
      "Epoch [34/50], Loss: 0.0033\n",
      "Epoch [35/50], Loss: 0.0033\n",
      "Epoch [36/50], Loss: 0.0032\n",
      "Epoch [37/50], Loss: 0.0035\n",
      "Epoch [38/50], Loss: 0.0036\n",
      "Epoch [39/50], Loss: 0.0036\n",
      "Epoch [40/50], Loss: 0.0034\n",
      "Epoch [41/50], Loss: 0.0030\n",
      "Epoch [42/50], Loss: 0.0038\n",
      "Epoch [43/50], Loss: 0.0034\n",
      "Epoch [44/50], Loss: 0.0048\n",
      "Epoch [45/50], Loss: 0.0033\n",
      "Epoch [46/50], Loss: 0.0027\n",
      "Epoch [47/50], Loss: 0.0035\n",
      "Epoch [48/50], Loss: 0.0034\n",
      "Epoch [49/50], Loss: 0.0033\n",
      "Epoch [50/50], Loss: 0.0040\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(465.0576, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  0.         0.         0.         0.       ]\n",
      "individual errors:  [array(99.858154, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1519\n",
      "Epoch [2/50], Loss: 0.1755\n",
      "Epoch [3/50], Loss: 0.1228\n",
      "Epoch [4/50], Loss: 0.1076\n",
      "Epoch [5/50], Loss: 0.1032\n",
      "Epoch [6/50], Loss: 0.1003\n",
      "Epoch [7/50], Loss: 0.0969\n",
      "Epoch [8/50], Loss: 0.0943\n",
      "Epoch [9/50], Loss: 0.0919\n",
      "Epoch [10/50], Loss: 0.0879\n",
      "Epoch [11/50], Loss: 0.0844\n",
      "Epoch [12/50], Loss: 0.0817\n",
      "Epoch [13/50], Loss: 0.0778\n",
      "Epoch [14/50], Loss: 0.0755\n",
      "Epoch [15/50], Loss: 0.0740\n",
      "Epoch [16/50], Loss: 0.0693\n",
      "Epoch [17/50], Loss: 0.0667\n",
      "Epoch [18/50], Loss: 0.0650\n",
      "Epoch [19/50], Loss: 0.0632\n",
      "Epoch [20/50], Loss: 0.0603\n",
      "Epoch [21/50], Loss: 0.0595\n",
      "Epoch [22/50], Loss: 0.0563\n",
      "Epoch [23/50], Loss: 0.0566\n",
      "Epoch [24/50], Loss: 0.0508\n",
      "Epoch [25/50], Loss: 0.0515\n",
      "Epoch [26/50], Loss: 0.0489\n",
      "Epoch [27/50], Loss: 0.0497\n",
      "Epoch [28/50], Loss: 0.0472\n",
      "Epoch [29/50], Loss: 0.0477\n",
      "Epoch [30/50], Loss: 0.0483\n",
      "Epoch [31/50], Loss: 0.0446\n",
      "Epoch [32/50], Loss: 0.0444\n",
      "Epoch [33/50], Loss: 0.0431\n",
      "Epoch [34/50], Loss: 0.0394\n",
      "Epoch [35/50], Loss: 0.0425\n",
      "Epoch [36/50], Loss: 0.0414\n",
      "Epoch [37/50], Loss: 0.0406\n",
      "Epoch [38/50], Loss: 0.0407\n",
      "Epoch [39/50], Loss: 0.0393\n",
      "Epoch [40/50], Loss: 0.0381\n",
      "Epoch [41/50], Loss: 0.0388\n",
      "Epoch [42/50], Loss: 0.0356\n",
      "Epoch [43/50], Loss: 0.0369\n",
      "Epoch [44/50], Loss: 0.0362\n",
      "Epoch [45/50], Loss: 0.0374\n",
      "Epoch [46/50], Loss: 0.0353\n",
      "Epoch [47/50], Loss: 0.0356\n",
      "Epoch [48/50], Loss: 0.0352\n",
      "Epoch [49/50], Loss: 0.0336\n",
      "Epoch [50/50], Loss: 0.0336\n",
      "update data..\n",
      "task data norm and number entries: tensor(452.4349, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.31033325  0.          0.          0.        ]\n",
      "individual errors:  [array(98.91253, dtype=float32), array(87.70813, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1413\n",
      "Epoch [2/50], Loss: 0.5193\n",
      "Epoch [3/50], Loss: 0.1586\n",
      "Epoch [4/50], Loss: 0.1198\n",
      "Epoch [5/50], Loss: 0.1160\n",
      "Epoch [6/50], Loss: 0.1148\n",
      "Epoch [7/50], Loss: 0.1115\n",
      "Epoch [8/50], Loss: 0.1088\n",
      "Epoch [9/50], Loss: 0.1061\n",
      "Epoch [10/50], Loss: 0.1039\n",
      "Epoch [11/50], Loss: 0.1038\n",
      "Epoch [12/50], Loss: 0.0997\n",
      "Epoch [13/50], Loss: 0.0983\n",
      "Epoch [14/50], Loss: 0.0947\n",
      "Epoch [15/50], Loss: 0.0932\n",
      "Epoch [16/50], Loss: 0.0895\n",
      "Epoch [17/50], Loss: 0.0902\n",
      "Epoch [18/50], Loss: 0.0855\n",
      "Epoch [19/50], Loss: 0.0857\n",
      "Epoch [20/50], Loss: 0.0851\n",
      "Epoch [21/50], Loss: 0.0819\n",
      "Epoch [22/50], Loss: 0.0796\n",
      "Epoch [23/50], Loss: 0.0793\n",
      "Epoch [24/50], Loss: 0.0777\n",
      "Epoch [25/50], Loss: 0.0752\n",
      "Epoch [26/50], Loss: 0.0727\n",
      "Epoch [27/50], Loss: 0.0733\n",
      "Epoch [28/50], Loss: 0.0747\n",
      "Epoch [29/50], Loss: 0.0701\n",
      "Epoch [30/50], Loss: 0.0686\n",
      "Epoch [31/50], Loss: 0.0692\n",
      "Epoch [32/50], Loss: 0.0695\n",
      "Epoch [33/50], Loss: 0.0679\n",
      "Epoch [34/50], Loss: 0.0677\n",
      "Epoch [35/50], Loss: 0.0662\n",
      "Epoch [36/50], Loss: 0.0642\n",
      "Epoch [37/50], Loss: 0.0646\n",
      "Epoch [38/50], Loss: 0.0618\n",
      "Epoch [39/50], Loss: 0.0601\n",
      "Epoch [40/50], Loss: 0.0597\n",
      "Epoch [41/50], Loss: 0.0616\n",
      "Epoch [42/50], Loss: 0.0591\n",
      "Epoch [43/50], Loss: 0.0612\n",
      "Epoch [44/50], Loss: 0.0615\n",
      "Epoch [45/50], Loss: 0.0569\n",
      "Epoch [46/50], Loss: 0.0588\n",
      "Epoch [47/50], Loss: 0.0561\n",
      "Epoch [48/50], Loss: 0.0575\n",
      "Epoch [49/50], Loss: 0.0559\n",
      "Epoch [50/50], Loss: 0.0560\n",
      "update data..\n",
      "task data norm and number entries: tensor(437.4991, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.31033325 87.28726196  0.          0.        ]\n",
      "individual errors:  [array(98.91253, dtype=float32), array(84.72086, dtype=float32), array(78.228386, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1390\n",
      "Epoch [2/50], Loss: 0.1419\n",
      "Epoch [3/50], Loss: 0.1618\n",
      "Epoch [4/50], Loss: 0.1213\n",
      "Epoch [5/50], Loss: 0.1167\n",
      "Epoch [6/50], Loss: 0.1133\n",
      "Epoch [7/50], Loss: 0.1123\n",
      "Epoch [8/50], Loss: 0.1087\n",
      "Epoch [9/50], Loss: 0.1069\n",
      "Epoch [10/50], Loss: 0.1037\n",
      "Epoch [11/50], Loss: 0.1027\n",
      "Epoch [12/50], Loss: 0.0988\n",
      "Epoch [13/50], Loss: 0.0973\n",
      "Epoch [14/50], Loss: 0.0934\n",
      "Epoch [15/50], Loss: 0.0907\n",
      "Epoch [16/50], Loss: 0.0904\n",
      "Epoch [17/50], Loss: 0.0862\n",
      "Epoch [18/50], Loss: 0.0856\n",
      "Epoch [19/50], Loss: 0.0829\n",
      "Epoch [20/50], Loss: 0.0810\n",
      "Epoch [21/50], Loss: 0.0801\n",
      "Epoch [22/50], Loss: 0.0784\n",
      "Epoch [23/50], Loss: 0.0761\n",
      "Epoch [24/50], Loss: 0.0750\n",
      "Epoch [25/50], Loss: 0.0732\n",
      "Epoch [26/50], Loss: 0.0707\n",
      "Epoch [27/50], Loss: 0.0696\n",
      "Epoch [28/50], Loss: 0.0696\n",
      "Epoch [29/50], Loss: 0.0680\n",
      "Epoch [30/50], Loss: 0.0682\n",
      "Epoch [31/50], Loss: 0.0656\n",
      "Epoch [32/50], Loss: 0.0639\n",
      "Epoch [33/50], Loss: 0.0657\n",
      "Epoch [34/50], Loss: 0.0645\n",
      "Epoch [35/50], Loss: 0.0620\n",
      "Epoch [36/50], Loss: 0.0598\n",
      "Epoch [37/50], Loss: 0.0616\n",
      "Epoch [38/50], Loss: 0.0613\n",
      "Epoch [39/50], Loss: 0.0589\n",
      "Epoch [40/50], Loss: 0.0593\n",
      "Epoch [41/50], Loss: 0.0591\n",
      "Epoch [42/50], Loss: 0.0569\n",
      "Epoch [43/50], Loss: 0.0584\n",
      "Epoch [44/50], Loss: 0.0573\n",
      "Epoch [45/50], Loss: 0.0553\n",
      "Epoch [46/50], Loss: 0.0551\n",
      "Epoch [47/50], Loss: 0.0547\n",
      "Epoch [48/50], Loss: 0.0552\n",
      "Epoch [49/50], Loss: 0.0532\n",
      "Epoch [50/50], Loss: 0.0535\n",
      "update data..\n",
      "task data norm and number entries: tensor(451.7911, device='cuda:0') torch.Size([800, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.31033325 87.28726196 85.64082336  0.        ]\n",
      "individual errors:  [array(98.723404, dtype=float32), array(82.07639, dtype=float32), array(71.985054, dtype=float32), array(89.77845, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1297\n",
      "Epoch [2/50], Loss: 0.1356\n",
      "Epoch [3/50], Loss: 0.1788\n",
      "Epoch [4/50], Loss: 0.1206\n",
      "Epoch [5/50], Loss: 0.1156\n",
      "Epoch [6/50], Loss: 0.1142\n",
      "Epoch [7/50], Loss: 0.1125\n",
      "Epoch [8/50], Loss: 0.1123\n",
      "Epoch [9/50], Loss: 0.1108\n",
      "Epoch [10/50], Loss: 0.1098\n",
      "Epoch [11/50], Loss: 0.1088\n",
      "Epoch [12/50], Loss: 0.1092\n",
      "Epoch [13/50], Loss: 0.1077\n",
      "Epoch [14/50], Loss: 0.1049\n",
      "Epoch [15/50], Loss: 0.1044\n",
      "Epoch [16/50], Loss: 0.1031\n",
      "Epoch [17/50], Loss: 0.1018\n",
      "Epoch [18/50], Loss: 0.1038\n",
      "Epoch [19/50], Loss: 0.1014\n",
      "Epoch [20/50], Loss: 0.1010\n",
      "Epoch [21/50], Loss: 0.0987\n",
      "Epoch [22/50], Loss: 0.0977\n",
      "Epoch [23/50], Loss: 0.0963\n",
      "Epoch [24/50], Loss: 0.0963\n",
      "Epoch [25/50], Loss: 0.0966\n",
      "Epoch [26/50], Loss: 0.0934\n",
      "Epoch [27/50], Loss: 0.0972\n",
      "Epoch [28/50], Loss: 0.0934\n",
      "Epoch [29/50], Loss: 0.0923\n",
      "Epoch [30/50], Loss: 0.0925\n",
      "Epoch [31/50], Loss: 0.0919\n",
      "Epoch [32/50], Loss: 0.0890\n",
      "Epoch [33/50], Loss: 0.0923\n",
      "Epoch [34/50], Loss: 0.0884\n",
      "Epoch [35/50], Loss: 0.0894\n",
      "Epoch [36/50], Loss: 0.0870\n",
      "Epoch [37/50], Loss: 0.0891\n",
      "Epoch [38/50], Loss: 0.0900\n",
      "Epoch [39/50], Loss: 0.0863\n",
      "Epoch [40/50], Loss: 0.0869\n",
      "Epoch [41/50], Loss: 0.0856\n",
      "Epoch [42/50], Loss: 0.0903\n",
      "Epoch [43/50], Loss: 0.0844\n",
      "Epoch [44/50], Loss: 0.0856\n",
      "Epoch [45/50], Loss: 0.0854\n",
      "Epoch [46/50], Loss: 0.0923\n",
      "Epoch [47/50], Loss: 0.0848\n",
      "Epoch [48/50], Loss: 0.0850\n",
      "Epoch [49/50], Loss: 0.0815\n",
      "Epoch [50/50], Loss: 0.0842\n",
      "test performance :  [99.8581543  93.31033325 87.28726196 85.64082336 81.07493591]\n",
      "individual errors:  [array(98.676125, dtype=float32), array(81.63565, dtype=float32), array(70.33084, dtype=float32), array(88.7714, dtype=float32), array(65.96066, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lr = 5e-2 # size of step\n",
    "results3 = []\n",
    "inderrors3 = []\n",
    "ss = [800]\n",
    "for s in ss:\n",
    "    res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-5,s=s),num_epochs=num_epochs )\n",
    "    results3 += [res]\n",
    "    inderrors3 += [inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  4704 1e-05\n",
      "Epoch [1/50], Loss: 0.0966\n",
      "Epoch [2/50], Loss: 0.0592\n",
      "Epoch [3/50], Loss: 0.0418\n",
      "Epoch [4/50], Loss: 0.0299\n",
      "Epoch [5/50], Loss: 0.0238\n",
      "Epoch [6/50], Loss: 0.0182\n",
      "Epoch [7/50], Loss: 0.0137\n",
      "Epoch [8/50], Loss: 0.0114\n",
      "Epoch [9/50], Loss: 0.0089\n",
      "Epoch [10/50], Loss: 0.0073\n",
      "Epoch [11/50], Loss: 0.0055\n",
      "Epoch [12/50], Loss: 0.0055\n",
      "Epoch [13/50], Loss: 0.0049\n",
      "Epoch [14/50], Loss: 0.0049\n",
      "Epoch [15/50], Loss: 0.0046\n",
      "Epoch [16/50], Loss: 0.0049\n",
      "Epoch [17/50], Loss: 0.0041\n",
      "Epoch [18/50], Loss: 0.0046\n",
      "Epoch [19/50], Loss: 0.0036\n",
      "Epoch [20/50], Loss: 0.0048\n",
      "Epoch [21/50], Loss: 0.0041\n",
      "Epoch [22/50], Loss: 0.0041\n",
      "Epoch [23/50], Loss: 0.0038\n",
      "Epoch [24/50], Loss: 0.0038\n",
      "Epoch [25/50], Loss: 0.0041\n",
      "Epoch [26/50], Loss: 0.0034\n",
      "Epoch [27/50], Loss: 0.0036\n",
      "Epoch [28/50], Loss: 0.0034\n",
      "Epoch [29/50], Loss: 0.0033\n",
      "Epoch [30/50], Loss: 0.0038\n",
      "Epoch [31/50], Loss: 0.0033\n",
      "Epoch [32/50], Loss: 0.0030\n",
      "Epoch [33/50], Loss: 0.0033\n",
      "Epoch [34/50], Loss: 0.0043\n",
      "Epoch [35/50], Loss: 0.0031\n",
      "Epoch [36/50], Loss: 0.0043\n",
      "Epoch [37/50], Loss: 0.0028\n",
      "Epoch [38/50], Loss: 0.0035\n",
      "Epoch [39/50], Loss: 0.0037\n",
      "Epoch [40/50], Loss: 0.0031\n",
      "Epoch [41/50], Loss: 0.0030\n",
      "Epoch [42/50], Loss: 0.0027\n",
      "Epoch [43/50], Loss: 0.0030\n",
      "Epoch [44/50], Loss: 0.0030\n",
      "Epoch [45/50], Loss: 0.0031\n",
      "Epoch [46/50], Loss: 0.0032\n",
      "Epoch [47/50], Loss: 0.0032\n",
      "Epoch [48/50], Loss: 0.0032\n",
      "Epoch [49/50], Loss: 0.0032\n",
      "Epoch [50/50], Loss: 0.0034\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(455.1155, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  0.         0.         0.         0.       ]\n",
      "individual errors:  [array(99.858154, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1590\n",
      "Epoch [2/50], Loss: 0.1981\n",
      "Epoch [3/50], Loss: 0.1240\n",
      "Epoch [4/50], Loss: 0.1069\n",
      "Epoch [5/50], Loss: 0.1016\n",
      "Epoch [6/50], Loss: 0.0985\n",
      "Epoch [7/50], Loss: 0.0947\n",
      "Epoch [8/50], Loss: 0.0906\n",
      "Epoch [9/50], Loss: 0.0867\n",
      "Epoch [10/50], Loss: 0.0827\n",
      "Epoch [11/50], Loss: 0.0808\n",
      "Epoch [12/50], Loss: 0.0767\n",
      "Epoch [13/50], Loss: 0.0724\n",
      "Epoch [14/50], Loss: 0.0706\n",
      "Epoch [15/50], Loss: 0.0682\n",
      "Epoch [16/50], Loss: 0.0650\n",
      "Epoch [17/50], Loss: 0.0619\n",
      "Epoch [18/50], Loss: 0.0600\n",
      "Epoch [19/50], Loss: 0.0558\n",
      "Epoch [20/50], Loss: 0.0574\n",
      "Epoch [21/50], Loss: 0.0549\n",
      "Epoch [22/50], Loss: 0.0551\n",
      "Epoch [23/50], Loss: 0.0517\n",
      "Epoch [24/50], Loss: 0.0490\n",
      "Epoch [25/50], Loss: 0.0494\n",
      "Epoch [26/50], Loss: 0.0465\n",
      "Epoch [27/50], Loss: 0.0482\n",
      "Epoch [28/50], Loss: 0.0459\n",
      "Epoch [29/50], Loss: 0.0465\n",
      "Epoch [30/50], Loss: 0.0435\n",
      "Epoch [31/50], Loss: 0.0412\n",
      "Epoch [32/50], Loss: 0.0448\n",
      "Epoch [33/50], Loss: 0.0407\n",
      "Epoch [34/50], Loss: 0.0409\n",
      "Epoch [35/50], Loss: 0.0418\n",
      "Epoch [36/50], Loss: 0.0398\n",
      "Epoch [37/50], Loss: 0.0401\n",
      "Epoch [38/50], Loss: 0.0401\n",
      "Epoch [39/50], Loss: 0.0397\n",
      "Epoch [40/50], Loss: 0.0393\n",
      "Epoch [41/50], Loss: 0.0390\n",
      "Epoch [42/50], Loss: 0.0410\n",
      "Epoch [43/50], Loss: 0.0386\n",
      "Epoch [44/50], Loss: 0.0387\n",
      "Epoch [45/50], Loss: 0.0341\n",
      "Epoch [46/50], Loss: 0.0383\n",
      "Epoch [47/50], Loss: 0.0366\n",
      "Epoch [48/50], Loss: 0.0357\n",
      "Epoch [49/50], Loss: 0.0368\n",
      "Epoch [50/50], Loss: 0.0361\n",
      "update data..\n",
      "task data norm and number entries: tensor(444.9214, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.33480835  0.          0.          0.        ]\n",
      "individual errors:  [array(98.91253, dtype=float32), array(87.757095, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1481\n",
      "Epoch [2/50], Loss: 0.4560\n",
      "Epoch [3/50], Loss: 0.1555\n",
      "Epoch [4/50], Loss: 0.1271\n",
      "Epoch [5/50], Loss: 0.1194\n",
      "Epoch [6/50], Loss: 0.1183\n",
      "Epoch [7/50], Loss: 0.1174\n",
      "Epoch [8/50], Loss: 0.1140\n",
      "Epoch [9/50], Loss: 0.1130\n",
      "Epoch [10/50], Loss: 0.1100\n",
      "Epoch [11/50], Loss: 0.1071\n",
      "Epoch [12/50], Loss: 0.1057\n",
      "Epoch [13/50], Loss: 0.1030\n",
      "Epoch [14/50], Loss: 0.0996\n",
      "Epoch [15/50], Loss: 0.0989\n",
      "Epoch [16/50], Loss: 0.0974\n",
      "Epoch [17/50], Loss: 0.0938\n",
      "Epoch [18/50], Loss: 0.0912\n",
      "Epoch [19/50], Loss: 0.0899\n",
      "Epoch [20/50], Loss: 0.0884\n",
      "Epoch [21/50], Loss: 0.0869\n",
      "Epoch [22/50], Loss: 0.0847\n",
      "Epoch [23/50], Loss: 0.0822\n",
      "Epoch [24/50], Loss: 0.0807\n",
      "Epoch [25/50], Loss: 0.0812\n",
      "Epoch [26/50], Loss: 0.0792\n",
      "Epoch [27/50], Loss: 0.0776\n",
      "Epoch [28/50], Loss: 0.0760\n",
      "Epoch [29/50], Loss: 0.0743\n",
      "Epoch [30/50], Loss: 0.0750\n",
      "Epoch [31/50], Loss: 0.0727\n",
      "Epoch [32/50], Loss: 0.0729\n",
      "Epoch [33/50], Loss: 0.0719\n",
      "Epoch [34/50], Loss: 0.0703\n",
      "Epoch [35/50], Loss: 0.0701\n",
      "Epoch [36/50], Loss: 0.0690\n",
      "Epoch [37/50], Loss: 0.0687\n",
      "Epoch [38/50], Loss: 0.0690\n",
      "Epoch [39/50], Loss: 0.0648\n",
      "Epoch [40/50], Loss: 0.0674\n",
      "Epoch [41/50], Loss: 0.0637\n",
      "Epoch [42/50], Loss: 0.0632\n",
      "Epoch [43/50], Loss: 0.0638\n",
      "Epoch [44/50], Loss: 0.0643\n",
      "Epoch [45/50], Loss: 0.0613\n",
      "Epoch [46/50], Loss: 0.0648\n",
      "Epoch [47/50], Loss: 0.0613\n",
      "Epoch [48/50], Loss: 0.0614\n",
      "Epoch [49/50], Loss: 0.0617\n",
      "Epoch [50/50], Loss: 0.0599\n",
      "update data..\n",
      "task data norm and number entries: tensor(429.4788, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.33480835 87.28760529  0.          0.        ]\n",
      "individual errors:  [array(98.676125, dtype=float32), array(86.238976, dtype=float32), array(76.9477, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1392\n",
      "Epoch [2/50], Loss: 0.1436\n",
      "Epoch [3/50], Loss: 0.1618\n",
      "Epoch [4/50], Loss: 0.1215\n",
      "Epoch [5/50], Loss: 0.1158\n",
      "Epoch [6/50], Loss: 0.1145\n",
      "Epoch [7/50], Loss: 0.1107\n",
      "Epoch [8/50], Loss: 0.1096\n",
      "Epoch [9/50], Loss: 0.1068\n",
      "Epoch [10/50], Loss: 0.1034\n",
      "Epoch [11/50], Loss: 0.1018\n",
      "Epoch [12/50], Loss: 0.0995\n",
      "Epoch [13/50], Loss: 0.0969\n",
      "Epoch [14/50], Loss: 0.0949\n",
      "Epoch [15/50], Loss: 0.0918\n",
      "Epoch [16/50], Loss: 0.0898\n",
      "Epoch [17/50], Loss: 0.0892\n",
      "Epoch [18/50], Loss: 0.0847\n",
      "Epoch [19/50], Loss: 0.0833\n",
      "Epoch [20/50], Loss: 0.0822\n",
      "Epoch [21/50], Loss: 0.0809\n",
      "Epoch [22/50], Loss: 0.0786\n",
      "Epoch [23/50], Loss: 0.0766\n",
      "Epoch [24/50], Loss: 0.0760\n",
      "Epoch [25/50], Loss: 0.0740\n",
      "Epoch [26/50], Loss: 0.0724\n",
      "Epoch [27/50], Loss: 0.0728\n",
      "Epoch [28/50], Loss: 0.0714\n",
      "Epoch [29/50], Loss: 0.0691\n",
      "Epoch [30/50], Loss: 0.0692\n",
      "Epoch [31/50], Loss: 0.0677\n",
      "Epoch [32/50], Loss: 0.0662\n",
      "Epoch [33/50], Loss: 0.0664\n",
      "Epoch [34/50], Loss: 0.0671\n",
      "Epoch [35/50], Loss: 0.0620\n",
      "Epoch [36/50], Loss: 0.0631\n",
      "Epoch [37/50], Loss: 0.0613\n",
      "Epoch [38/50], Loss: 0.0626\n",
      "Epoch [39/50], Loss: 0.0624\n",
      "Epoch [40/50], Loss: 0.0617\n",
      "Epoch [41/50], Loss: 0.0596\n",
      "Epoch [42/50], Loss: 0.0619\n",
      "Epoch [43/50], Loss: 0.0590\n",
      "Epoch [44/50], Loss: 0.0586\n",
      "Epoch [45/50], Loss: 0.0604\n",
      "Epoch [46/50], Loss: 0.0567\n",
      "Epoch [47/50], Loss: 0.0583\n",
      "Epoch [48/50], Loss: 0.0579\n",
      "Epoch [49/50], Loss: 0.0588\n",
      "Epoch [50/50], Loss: 0.0565\n",
      "update data..\n",
      "task data norm and number entries: tensor(448.3977, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.8581543  93.33480835 87.28760529 85.96055603  0.        ]\n",
      "individual errors:  [array(98.297874, dtype=float32), array(83.54554, dtype=float32), array(73.47919, dtype=float32), array(88.51964, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1352\n",
      "Epoch [2/50], Loss: 0.1385\n",
      "Epoch [3/50], Loss: 0.1772\n",
      "Epoch [4/50], Loss: 0.1254\n",
      "Epoch [5/50], Loss: 0.1209\n",
      "Epoch [6/50], Loss: 0.1208\n",
      "Epoch [7/50], Loss: 0.1192\n",
      "Epoch [8/50], Loss: 0.1172\n",
      "Epoch [9/50], Loss: 0.1171\n",
      "Epoch [10/50], Loss: 0.1164\n",
      "Epoch [11/50], Loss: 0.1181\n",
      "Epoch [12/50], Loss: 0.1144\n",
      "Epoch [13/50], Loss: 0.1124\n",
      "Epoch [14/50], Loss: 0.1097\n",
      "Epoch [15/50], Loss: 0.1112\n",
      "Epoch [16/50], Loss: 0.1090\n",
      "Epoch [17/50], Loss: 0.1073\n",
      "Epoch [18/50], Loss: 0.1064\n",
      "Epoch [19/50], Loss: 0.1057\n",
      "Epoch [20/50], Loss: 0.1051\n",
      "Epoch [21/50], Loss: 0.1037\n",
      "Epoch [22/50], Loss: 0.1034\n",
      "Epoch [23/50], Loss: 0.1026\n",
      "Epoch [24/50], Loss: 0.1000\n",
      "Epoch [25/50], Loss: 0.1007\n",
      "Epoch [26/50], Loss: 0.0991\n",
      "Epoch [27/50], Loss: 0.1006\n",
      "Epoch [28/50], Loss: 0.0969\n",
      "Epoch [29/50], Loss: 0.0980\n",
      "Epoch [30/50], Loss: 0.0953\n",
      "Epoch [31/50], Loss: 0.0960\n",
      "Epoch [32/50], Loss: 0.0972\n",
      "Epoch [33/50], Loss: 0.0957\n",
      "Epoch [34/50], Loss: 0.0940\n",
      "Epoch [35/50], Loss: 0.0942\n",
      "Epoch [36/50], Loss: 0.0927\n",
      "Epoch [37/50], Loss: 0.0931\n",
      "Epoch [38/50], Loss: 0.0945\n",
      "Epoch [39/50], Loss: 0.0932\n",
      "Epoch [40/50], Loss: 0.0911\n",
      "Epoch [41/50], Loss: 0.0899\n",
      "Epoch [42/50], Loss: 0.0925\n",
      "Epoch [43/50], Loss: 0.0971\n",
      "Epoch [44/50], Loss: 0.0983\n",
      "Epoch [45/50], Loss: 0.0893\n",
      "Epoch [46/50], Loss: 0.0898\n",
      "Epoch [47/50], Loss: 0.0868\n",
      "Epoch [48/50], Loss: 0.0896\n",
      "Epoch [49/50], Loss: 0.0919\n",
      "Epoch [50/50], Loss: 0.0873\n",
      "test performance :  [99.8581543  93.33480835 87.28760529 85.96055603 79.5315094 ]\n",
      "individual errors:  [array(98.487, dtype=float32), array(81.73359, dtype=float32), array(68.24973, dtype=float32), array(87.260826, dtype=float32), array(61.926373, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lr = 5e-2 # size of step\n",
    "res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-5,s=6*784),num_epochs=num_epochs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  4704 1e-06\n",
      "Epoch [1/50], Loss: 0.0979\n",
      "Epoch [2/50], Loss: 0.0904\n",
      "Epoch [3/50], Loss: 0.0841\n",
      "Epoch [4/50], Loss: 0.0788\n",
      "Epoch [5/50], Loss: 0.0742\n",
      "Epoch [6/50], Loss: 0.0705\n",
      "Epoch [7/50], Loss: 0.0672\n",
      "Epoch [8/50], Loss: 0.0645\n",
      "Epoch [9/50], Loss: 0.0624\n",
      "Epoch [10/50], Loss: 0.0605\n",
      "Epoch [11/50], Loss: 0.0587\n",
      "Epoch [12/50], Loss: 0.0574\n",
      "Epoch [13/50], Loss: 0.0563\n",
      "Epoch [14/50], Loss: 0.0552\n",
      "Epoch [15/50], Loss: 0.0541\n",
      "Epoch [16/50], Loss: 0.0538\n",
      "Epoch [17/50], Loss: 0.0528\n",
      "Epoch [18/50], Loss: 0.0524\n",
      "Epoch [19/50], Loss: 0.0522\n",
      "Epoch [20/50], Loss: 0.0516\n",
      "Epoch [21/50], Loss: 0.0513\n",
      "Epoch [22/50], Loss: 0.0513\n",
      "Epoch [23/50], Loss: 0.0510\n",
      "Epoch [24/50], Loss: 0.0507\n",
      "Epoch [25/50], Loss: 0.0507\n",
      "Epoch [26/50], Loss: 0.0506\n",
      "Epoch [27/50], Loss: 0.0502\n",
      "Epoch [28/50], Loss: 0.0502\n",
      "Epoch [29/50], Loss: 0.0502\n",
      "Epoch [30/50], Loss: 0.0504\n",
      "Epoch [31/50], Loss: 0.0500\n",
      "Epoch [32/50], Loss: 0.0500\n",
      "Epoch [33/50], Loss: 0.0498\n",
      "Epoch [34/50], Loss: 0.0497\n",
      "Epoch [35/50], Loss: 0.0498\n",
      "Epoch [36/50], Loss: 0.0500\n",
      "Epoch [37/50], Loss: 0.0499\n",
      "Epoch [38/50], Loss: 0.0498\n",
      "Epoch [39/50], Loss: 0.0501\n",
      "Epoch [40/50], Loss: 0.0500\n",
      "Epoch [41/50], Loss: 0.0498\n",
      "Epoch [42/50], Loss: 0.0498\n",
      "Epoch [43/50], Loss: 0.0499\n",
      "Epoch [44/50], Loss: 0.0496\n",
      "Epoch [45/50], Loss: 0.0495\n",
      "Epoch [46/50], Loss: 0.0498\n",
      "Epoch [47/50], Loss: 0.0498\n",
      "Epoch [48/50], Loss: 0.0496\n",
      "Epoch [49/50], Loss: 0.0502\n",
      "Epoch [50/50], Loss: 0.0497\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(461.5188, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(53.664303, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1488\n",
      "Epoch [2/50], Loss: 0.1341\n",
      "Epoch [3/50], Loss: 0.1219\n",
      "Epoch [4/50], Loss: 0.1118\n",
      "Epoch [5/50], Loss: 0.1033\n",
      "Epoch [6/50], Loss: 0.0963\n",
      "Epoch [7/50], Loss: 0.0904\n",
      "Epoch [8/50], Loss: 0.0855\n",
      "Epoch [9/50], Loss: 0.0814\n",
      "Epoch [10/50], Loss: 0.0780\n",
      "Epoch [11/50], Loss: 0.0751\n",
      "Epoch [12/50], Loss: 0.0728\n",
      "Epoch [13/50], Loss: 0.0708\n",
      "Epoch [14/50], Loss: 0.0692\n",
      "Epoch [15/50], Loss: 0.0678\n",
      "Epoch [16/50], Loss: 0.0667\n",
      "Epoch [17/50], Loss: 0.0657\n",
      "Epoch [18/50], Loss: 0.0649\n",
      "Epoch [19/50], Loss: 0.0643\n",
      "Epoch [20/50], Loss: 0.0637\n",
      "Epoch [21/50], Loss: 0.0633\n",
      "Epoch [22/50], Loss: 0.0629\n",
      "Epoch [23/50], Loss: 0.0626\n",
      "Epoch [24/50], Loss: 0.0623\n",
      "Epoch [25/50], Loss: 0.0620\n",
      "Epoch [26/50], Loss: 0.0619\n",
      "Epoch [27/50], Loss: 0.0617\n",
      "Epoch [28/50], Loss: 0.0615\n",
      "Epoch [29/50], Loss: 0.0615\n",
      "Epoch [30/50], Loss: 0.0615\n",
      "Epoch [31/50], Loss: 0.0613\n",
      "Epoch [32/50], Loss: 0.0613\n",
      "Epoch [33/50], Loss: 0.0612\n",
      "Epoch [34/50], Loss: 0.0612\n",
      "Epoch [35/50], Loss: 0.0611\n",
      "Epoch [36/50], Loss: 0.0611\n",
      "Epoch [37/50], Loss: 0.0612\n",
      "Epoch [38/50], Loss: 0.0611\n",
      "Epoch [39/50], Loss: 0.0611\n",
      "Epoch [40/50], Loss: 0.0610\n",
      "Epoch [41/50], Loss: 0.0610\n",
      "Epoch [42/50], Loss: 0.0610\n",
      "Epoch [43/50], Loss: 0.0610\n",
      "Epoch [44/50], Loss: 0.0610\n",
      "Epoch [45/50], Loss: 0.0611\n",
      "Epoch [46/50], Loss: 0.0610\n",
      "Epoch [47/50], Loss: 0.0610\n",
      "Epoch [48/50], Loss: 0.0610\n",
      "Epoch [49/50], Loss: 0.0610\n",
      "Epoch [50/50], Loss: 0.0610\n",
      "update data..\n",
      "task data norm and number entries: tensor(450.3715, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567  0.          0.          0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(49.46131, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1392\n",
      "Epoch [2/50], Loss: 0.1271\n",
      "Epoch [3/50], Loss: 0.1171\n",
      "Epoch [4/50], Loss: 0.1088\n",
      "Epoch [5/50], Loss: 0.1018\n",
      "Epoch [6/50], Loss: 0.0960\n",
      "Epoch [7/50], Loss: 0.0912\n",
      "Epoch [8/50], Loss: 0.0872\n",
      "Epoch [9/50], Loss: 0.0841\n",
      "Epoch [10/50], Loss: 0.0814\n",
      "Epoch [11/50], Loss: 0.0792\n",
      "Epoch [12/50], Loss: 0.0771\n",
      "Epoch [13/50], Loss: 0.0755\n",
      "Epoch [14/50], Loss: 0.0743\n",
      "Epoch [15/50], Loss: 0.0731\n",
      "Epoch [16/50], Loss: 0.0723\n",
      "Epoch [17/50], Loss: 0.0715\n",
      "Epoch [18/50], Loss: 0.0708\n",
      "Epoch [19/50], Loss: 0.0703\n",
      "Epoch [20/50], Loss: 0.0700\n",
      "Epoch [21/50], Loss: 0.0695\n",
      "Epoch [22/50], Loss: 0.0694\n",
      "Epoch [23/50], Loss: 0.0691\n",
      "Epoch [24/50], Loss: 0.0688\n",
      "Epoch [25/50], Loss: 0.0687\n",
      "Epoch [26/50], Loss: 0.0686\n",
      "Epoch [27/50], Loss: 0.0684\n",
      "Epoch [28/50], Loss: 0.0684\n",
      "Epoch [29/50], Loss: 0.0681\n",
      "Epoch [30/50], Loss: 0.0682\n",
      "Epoch [31/50], Loss: 0.0681\n",
      "Epoch [32/50], Loss: 0.0680\n",
      "Epoch [33/50], Loss: 0.0680\n",
      "Epoch [34/50], Loss: 0.0679\n",
      "Epoch [35/50], Loss: 0.0682\n",
      "Epoch [36/50], Loss: 0.0680\n",
      "Epoch [37/50], Loss: 0.0681\n",
      "Epoch [38/50], Loss: 0.0678\n",
      "Epoch [39/50], Loss: 0.0678\n",
      "Epoch [40/50], Loss: 0.0678\n",
      "Epoch [41/50], Loss: 0.0680\n",
      "Epoch [42/50], Loss: 0.0679\n",
      "Epoch [43/50], Loss: 0.0678\n",
      "Epoch [44/50], Loss: 0.0678\n",
      "Epoch [45/50], Loss: 0.0680\n",
      "Epoch [46/50], Loss: 0.0680\n",
      "Epoch [47/50], Loss: 0.0678\n",
      "Epoch [48/50], Loss: 0.0679\n",
      "Epoch [49/50], Loss: 0.0679\n",
      "Epoch [50/50], Loss: 0.0677\n",
      "update data..\n",
      "task data norm and number entries: tensor(434.7939, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567 17.46709442  0.          0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(52.40128, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1331\n",
      "Epoch [2/50], Loss: 0.1210\n",
      "Epoch [3/50], Loss: 0.1113\n",
      "Epoch [4/50], Loss: 0.1035\n",
      "Epoch [5/50], Loss: 0.0972\n",
      "Epoch [6/50], Loss: 0.0924\n",
      "Epoch [7/50], Loss: 0.0883\n",
      "Epoch [8/50], Loss: 0.0851\n",
      "Epoch [9/50], Loss: 0.0826\n",
      "Epoch [10/50], Loss: 0.0806\n",
      "Epoch [11/50], Loss: 0.0788\n",
      "Epoch [12/50], Loss: 0.0775\n",
      "Epoch [13/50], Loss: 0.0766\n",
      "Epoch [14/50], Loss: 0.0756\n",
      "Epoch [15/50], Loss: 0.0749\n",
      "Epoch [16/50], Loss: 0.0745\n",
      "Epoch [17/50], Loss: 0.0740\n",
      "Epoch [18/50], Loss: 0.0737\n",
      "Epoch [19/50], Loss: 0.0734\n",
      "Epoch [20/50], Loss: 0.0731\n",
      "Epoch [21/50], Loss: 0.0729\n",
      "Epoch [22/50], Loss: 0.0729\n",
      "Epoch [23/50], Loss: 0.0728\n",
      "Epoch [24/50], Loss: 0.0725\n",
      "Epoch [25/50], Loss: 0.0724\n",
      "Epoch [26/50], Loss: 0.0724\n",
      "Epoch [27/50], Loss: 0.0723\n",
      "Epoch [28/50], Loss: 0.0723\n",
      "Epoch [29/50], Loss: 0.0723\n",
      "Epoch [30/50], Loss: 0.0722\n",
      "Epoch [31/50], Loss: 0.0722\n",
      "Epoch [32/50], Loss: 0.0722\n",
      "Epoch [33/50], Loss: 0.0722\n",
      "Epoch [34/50], Loss: 0.0722\n",
      "Epoch [35/50], Loss: 0.0722\n",
      "Epoch [36/50], Loss: 0.0722\n",
      "Epoch [37/50], Loss: 0.0722\n",
      "Epoch [38/50], Loss: 0.0723\n",
      "Epoch [39/50], Loss: 0.0723\n",
      "Epoch [40/50], Loss: 0.0722\n",
      "Epoch [41/50], Loss: 0.0722\n",
      "Epoch [42/50], Loss: 0.0722\n",
      "Epoch [43/50], Loss: 0.0721\n",
      "Epoch [44/50], Loss: 0.0722\n",
      "Epoch [45/50], Loss: 0.0722\n",
      "Epoch [46/50], Loss: 0.0722\n",
      "Epoch [47/50], Loss: 0.0722\n",
      "Epoch [48/50], Loss: 0.0721\n",
      "Epoch [49/50], Loss: 0.0722\n",
      "Epoch [50/50], Loss: 0.0723\n",
      "update data..\n",
      "task data norm and number entries: tensor(453.0820, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567 17.46709442 12.94058418  0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(51.762337, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1295\n",
      "Epoch [2/50], Loss: 0.1180\n",
      "Epoch [3/50], Loss: 0.1090\n",
      "Epoch [4/50], Loss: 0.1019\n",
      "Epoch [5/50], Loss: 0.0963\n",
      "Epoch [6/50], Loss: 0.0919\n",
      "Epoch [7/50], Loss: 0.0885\n",
      "Epoch [8/50], Loss: 0.0857\n",
      "Epoch [9/50], Loss: 0.0836\n",
      "Epoch [10/50], Loss: 0.0819\n",
      "Epoch [11/50], Loss: 0.0806\n",
      "Epoch [12/50], Loss: 0.0795\n",
      "Epoch [13/50], Loss: 0.0787\n",
      "Epoch [14/50], Loss: 0.0781\n",
      "Epoch [15/50], Loss: 0.0776\n",
      "Epoch [16/50], Loss: 0.0772\n",
      "Epoch [17/50], Loss: 0.0769\n",
      "Epoch [18/50], Loss: 0.0766\n",
      "Epoch [19/50], Loss: 0.0764\n",
      "Epoch [20/50], Loss: 0.0763\n",
      "Epoch [21/50], Loss: 0.0762\n",
      "Epoch [22/50], Loss: 0.0760\n",
      "Epoch [23/50], Loss: 0.0760\n",
      "Epoch [24/50], Loss: 0.0759\n",
      "Epoch [25/50], Loss: 0.0758\n",
      "Epoch [26/50], Loss: 0.0759\n",
      "Epoch [27/50], Loss: 0.0758\n",
      "Epoch [28/50], Loss: 0.0758\n",
      "Epoch [29/50], Loss: 0.0758\n",
      "Epoch [30/50], Loss: 0.0758\n",
      "Epoch [31/50], Loss: 0.0757\n",
      "Epoch [32/50], Loss: 0.0757\n",
      "Epoch [33/50], Loss: 0.0757\n",
      "Epoch [34/50], Loss: 0.0757\n",
      "Epoch [35/50], Loss: 0.0757\n",
      "Epoch [36/50], Loss: 0.0757\n",
      "Epoch [37/50], Loss: 0.0757\n",
      "Epoch [38/50], Loss: 0.0757\n",
      "Epoch [39/50], Loss: 0.0757\n",
      "Epoch [40/50], Loss: 0.0757\n",
      "Epoch [41/50], Loss: 0.0757\n",
      "Epoch [42/50], Loss: 0.0757\n",
      "Epoch [43/50], Loss: 0.0757\n",
      "Epoch [44/50], Loss: 0.0757\n",
      "Epoch [45/50], Loss: 0.0757\n",
      "Epoch [46/50], Loss: 0.0757\n",
      "Epoch [47/50], Loss: 0.0757\n",
      "Epoch [48/50], Loss: 0.0757\n",
      "Epoch [49/50], Loss: 0.0757\n",
      "Epoch [50/50], Loss: 0.0757\n",
      "test performance :  [53.66430283 24.73065567 17.46709442 12.94058418 10.17650032]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(50.8825, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lr = 1e-2 # size of step\n",
    "res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-6,s=6*784),num_epochs=num_epochs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  4704 1e-06\n",
      "Epoch [1/50], Loss: 0.1004\n",
      "Epoch [2/50], Loss: 0.0996\n",
      "Epoch [3/50], Loss: 0.0988\n",
      "Epoch [4/50], Loss: 0.0980\n",
      "Epoch [5/50], Loss: 0.0971\n",
      "Epoch [6/50], Loss: 0.0964\n",
      "Epoch [7/50], Loss: 0.0957\n",
      "Epoch [8/50], Loss: 0.0949\n",
      "Epoch [9/50], Loss: 0.0941\n",
      "Epoch [10/50], Loss: 0.0934\n",
      "Epoch [11/50], Loss: 0.0927\n",
      "Epoch [12/50], Loss: 0.0919\n",
      "Epoch [13/50], Loss: 0.0912\n",
      "Epoch [14/50], Loss: 0.0906\n",
      "Epoch [15/50], Loss: 0.0899\n",
      "Epoch [16/50], Loss: 0.0892\n",
      "Epoch [17/50], Loss: 0.0886\n",
      "Epoch [18/50], Loss: 0.0879\n",
      "Epoch [19/50], Loss: 0.0873\n",
      "Epoch [20/50], Loss: 0.0867\n",
      "Epoch [21/50], Loss: 0.0861\n",
      "Epoch [22/50], Loss: 0.0855\n",
      "Epoch [23/50], Loss: 0.0849\n",
      "Epoch [24/50], Loss: 0.0843\n",
      "Epoch [25/50], Loss: 0.0837\n",
      "Epoch [26/50], Loss: 0.0832\n",
      "Epoch [27/50], Loss: 0.0826\n",
      "Epoch [28/50], Loss: 0.0820\n",
      "Epoch [29/50], Loss: 0.0816\n",
      "Epoch [30/50], Loss: 0.0810\n",
      "Epoch [31/50], Loss: 0.0806\n",
      "Epoch [32/50], Loss: 0.0800\n",
      "Epoch [33/50], Loss: 0.0796\n",
      "Epoch [34/50], Loss: 0.0790\n",
      "Epoch [35/50], Loss: 0.0786\n",
      "Epoch [36/50], Loss: 0.0781\n",
      "Epoch [37/50], Loss: 0.0775\n",
      "Epoch [38/50], Loss: 0.0771\n",
      "Epoch [39/50], Loss: 0.0768\n",
      "Epoch [40/50], Loss: 0.0763\n",
      "Epoch [41/50], Loss: 0.0758\n",
      "Epoch [42/50], Loss: 0.0754\n",
      "Epoch [43/50], Loss: 0.0750\n",
      "Epoch [44/50], Loss: 0.0745\n",
      "Epoch [45/50], Loss: 0.0741\n",
      "Epoch [46/50], Loss: 0.0737\n",
      "Epoch [47/50], Loss: 0.0733\n",
      "Epoch [48/50], Loss: 0.0729\n",
      "Epoch [49/50], Loss: 0.0725\n",
      "Epoch [50/50], Loss: 0.0720\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(457.6818, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(53.664303, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1070\n",
      "Epoch [2/50], Loss: 0.1062\n",
      "Epoch [3/50], Loss: 0.1053\n",
      "Epoch [4/50], Loss: 0.1044\n",
      "Epoch [5/50], Loss: 0.1036\n",
      "Epoch [6/50], Loss: 0.1027\n",
      "Epoch [7/50], Loss: 0.1020\n",
      "Epoch [8/50], Loss: 0.1011\n",
      "Epoch [9/50], Loss: 0.1004\n",
      "Epoch [10/50], Loss: 0.0996\n",
      "Epoch [11/50], Loss: 0.0987\n",
      "Epoch [12/50], Loss: 0.0980\n",
      "Epoch [13/50], Loss: 0.0972\n",
      "Epoch [14/50], Loss: 0.0965\n",
      "Epoch [15/50], Loss: 0.0959\n",
      "Epoch [16/50], Loss: 0.0952\n",
      "Epoch [17/50], Loss: 0.0943\n",
      "Epoch [18/50], Loss: 0.0937\n",
      "Epoch [19/50], Loss: 0.0931\n",
      "Epoch [20/50], Loss: 0.0924\n",
      "Epoch [21/50], Loss: 0.0918\n",
      "Epoch [22/50], Loss: 0.0912\n",
      "Epoch [23/50], Loss: 0.0905\n",
      "Epoch [24/50], Loss: 0.0899\n",
      "Epoch [25/50], Loss: 0.0893\n",
      "Epoch [26/50], Loss: 0.0888\n",
      "Epoch [27/50], Loss: 0.0882\n",
      "Epoch [28/50], Loss: 0.0876\n",
      "Epoch [29/50], Loss: 0.0869\n",
      "Epoch [30/50], Loss: 0.0864\n",
      "Epoch [31/50], Loss: 0.0860\n",
      "Epoch [32/50], Loss: 0.0854\n",
      "Epoch [33/50], Loss: 0.0848\n",
      "Epoch [34/50], Loss: 0.0843\n",
      "Epoch [35/50], Loss: 0.0838\n",
      "Epoch [36/50], Loss: 0.0834\n",
      "Epoch [37/50], Loss: 0.0829\n",
      "Epoch [38/50], Loss: 0.0825\n",
      "Epoch [39/50], Loss: 0.0820\n",
      "Epoch [40/50], Loss: 0.0815\n",
      "Epoch [41/50], Loss: 0.0810\n",
      "Epoch [42/50], Loss: 0.0805\n",
      "Epoch [43/50], Loss: 0.0802\n",
      "Epoch [44/50], Loss: 0.0798\n",
      "Epoch [45/50], Loss: 0.0793\n",
      "Epoch [46/50], Loss: 0.0789\n",
      "Epoch [47/50], Loss: 0.0786\n",
      "Epoch [48/50], Loss: 0.0781\n",
      "Epoch [49/50], Loss: 0.0778\n",
      "Epoch [50/50], Loss: 0.0774\n",
      "update data..\n",
      "task data norm and number entries: tensor(447.3636, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567  0.          0.          0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(49.46131, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1070\n",
      "Epoch [2/50], Loss: 0.1062\n",
      "Epoch [3/50], Loss: 0.1054\n",
      "Epoch [4/50], Loss: 0.1046\n",
      "Epoch [5/50], Loss: 0.1038\n",
      "Epoch [6/50], Loss: 0.1030\n",
      "Epoch [7/50], Loss: 0.1023\n",
      "Epoch [8/50], Loss: 0.1015\n",
      "Epoch [9/50], Loss: 0.1008\n",
      "Epoch [10/50], Loss: 0.1001\n",
      "Epoch [11/50], Loss: 0.0994\n",
      "Epoch [12/50], Loss: 0.0987\n",
      "Epoch [13/50], Loss: 0.0980\n",
      "Epoch [14/50], Loss: 0.0973\n",
      "Epoch [15/50], Loss: 0.0967\n",
      "Epoch [16/50], Loss: 0.0960\n",
      "Epoch [17/50], Loss: 0.0954\n",
      "Epoch [18/50], Loss: 0.0948\n",
      "Epoch [19/50], Loss: 0.0942\n",
      "Epoch [20/50], Loss: 0.0936\n",
      "Epoch [21/50], Loss: 0.0930\n",
      "Epoch [22/50], Loss: 0.0924\n",
      "Epoch [23/50], Loss: 0.0918\n",
      "Epoch [24/50], Loss: 0.0913\n",
      "Epoch [25/50], Loss: 0.0907\n",
      "Epoch [26/50], Loss: 0.0902\n",
      "Epoch [27/50], Loss: 0.0897\n",
      "Epoch [28/50], Loss: 0.0892\n",
      "Epoch [29/50], Loss: 0.0887\n",
      "Epoch [30/50], Loss: 0.0881\n",
      "Epoch [31/50], Loss: 0.0877\n",
      "Epoch [32/50], Loss: 0.0872\n",
      "Epoch [33/50], Loss: 0.0867\n",
      "Epoch [34/50], Loss: 0.0863\n",
      "Epoch [35/50], Loss: 0.0858\n",
      "Epoch [36/50], Loss: 0.0854\n",
      "Epoch [37/50], Loss: 0.0849\n",
      "Epoch [38/50], Loss: 0.0845\n",
      "Epoch [39/50], Loss: 0.0840\n",
      "Epoch [40/50], Loss: 0.0837\n",
      "Epoch [41/50], Loss: 0.0832\n",
      "Epoch [42/50], Loss: 0.0828\n",
      "Epoch [43/50], Loss: 0.0824\n",
      "Epoch [44/50], Loss: 0.0820\n",
      "Epoch [45/50], Loss: 0.0817\n",
      "Epoch [46/50], Loss: 0.0813\n",
      "Epoch [47/50], Loss: 0.0810\n",
      "Epoch [48/50], Loss: 0.0806\n",
      "Epoch [49/50], Loss: 0.0802\n",
      "Epoch [50/50], Loss: 0.0799\n",
      "update data..\n",
      "task data norm and number entries: tensor(431.6559, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567 17.46709442  0.          0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(52.40128, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1090\n",
      "Epoch [2/50], Loss: 0.1080\n",
      "Epoch [3/50], Loss: 0.1071\n",
      "Epoch [4/50], Loss: 0.1062\n",
      "Epoch [5/50], Loss: 0.1054\n",
      "Epoch [6/50], Loss: 0.1045\n",
      "Epoch [7/50], Loss: 0.1036\n",
      "Epoch [8/50], Loss: 0.1028\n",
      "Epoch [9/50], Loss: 0.1020\n",
      "Epoch [10/50], Loss: 0.1012\n",
      "Epoch [11/50], Loss: 0.1005\n",
      "Epoch [12/50], Loss: 0.0997\n",
      "Epoch [13/50], Loss: 0.0990\n",
      "Epoch [14/50], Loss: 0.0983\n",
      "Epoch [15/50], Loss: 0.0976\n",
      "Epoch [16/50], Loss: 0.0969\n",
      "Epoch [17/50], Loss: 0.0962\n",
      "Epoch [18/50], Loss: 0.0955\n",
      "Epoch [19/50], Loss: 0.0949\n",
      "Epoch [20/50], Loss: 0.0943\n",
      "Epoch [21/50], Loss: 0.0937\n",
      "Epoch [22/50], Loss: 0.0930\n",
      "Epoch [23/50], Loss: 0.0925\n",
      "Epoch [24/50], Loss: 0.0919\n",
      "Epoch [25/50], Loss: 0.0913\n",
      "Epoch [26/50], Loss: 0.0907\n",
      "Epoch [27/50], Loss: 0.0902\n",
      "Epoch [28/50], Loss: 0.0897\n",
      "Epoch [29/50], Loss: 0.0891\n",
      "Epoch [30/50], Loss: 0.0886\n",
      "Epoch [31/50], Loss: 0.0881\n",
      "Epoch [32/50], Loss: 0.0877\n",
      "Epoch [33/50], Loss: 0.0872\n",
      "Epoch [34/50], Loss: 0.0867\n",
      "Epoch [35/50], Loss: 0.0862\n",
      "Epoch [36/50], Loss: 0.0858\n",
      "Epoch [37/50], Loss: 0.0854\n",
      "Epoch [38/50], Loss: 0.0849\n",
      "Epoch [39/50], Loss: 0.0845\n",
      "Epoch [40/50], Loss: 0.0841\n",
      "Epoch [41/50], Loss: 0.0838\n",
      "Epoch [42/50], Loss: 0.0833\n",
      "Epoch [43/50], Loss: 0.0829\n",
      "Epoch [44/50], Loss: 0.0826\n",
      "Epoch [45/50], Loss: 0.0822\n",
      "Epoch [46/50], Loss: 0.0819\n",
      "Epoch [47/50], Loss: 0.0815\n",
      "Epoch [48/50], Loss: 0.0811\n",
      "Epoch [49/50], Loss: 0.0808\n",
      "Epoch [50/50], Loss: 0.0805\n",
      "update data..\n",
      "task data norm and number entries: tensor(450.8867, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567 17.46709442 12.94058418  0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(51.762337, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1084\n",
      "Epoch [2/50], Loss: 0.1074\n",
      "Epoch [3/50], Loss: 0.1065\n",
      "Epoch [4/50], Loss: 0.1057\n",
      "Epoch [5/50], Loss: 0.1048\n",
      "Epoch [6/50], Loss: 0.1040\n",
      "Epoch [7/50], Loss: 0.1031\n",
      "Epoch [8/50], Loss: 0.1023\n",
      "Epoch [9/50], Loss: 0.1016\n",
      "Epoch [10/50], Loss: 0.1008\n",
      "Epoch [11/50], Loss: 0.1001\n",
      "Epoch [12/50], Loss: 0.0993\n",
      "Epoch [13/50], Loss: 0.0986\n",
      "Epoch [14/50], Loss: 0.0979\n",
      "Epoch [15/50], Loss: 0.0972\n",
      "Epoch [16/50], Loss: 0.0966\n",
      "Epoch [17/50], Loss: 0.0959\n",
      "Epoch [18/50], Loss: 0.0953\n",
      "Epoch [19/50], Loss: 0.0947\n",
      "Epoch [20/50], Loss: 0.0941\n",
      "Epoch [21/50], Loss: 0.0935\n",
      "Epoch [22/50], Loss: 0.0929\n",
      "Epoch [23/50], Loss: 0.0924\n",
      "Epoch [24/50], Loss: 0.0918\n",
      "Epoch [25/50], Loss: 0.0912\n",
      "Epoch [26/50], Loss: 0.0907\n",
      "Epoch [27/50], Loss: 0.0902\n",
      "Epoch [28/50], Loss: 0.0898\n",
      "Epoch [29/50], Loss: 0.0893\n",
      "Epoch [30/50], Loss: 0.0888\n",
      "Epoch [31/50], Loss: 0.0883\n",
      "Epoch [32/50], Loss: 0.0879\n",
      "Epoch [33/50], Loss: 0.0874\n",
      "Epoch [34/50], Loss: 0.0870\n",
      "Epoch [35/50], Loss: 0.0866\n",
      "Epoch [36/50], Loss: 0.0861\n",
      "Epoch [37/50], Loss: 0.0857\n",
      "Epoch [38/50], Loss: 0.0853\n",
      "Epoch [39/50], Loss: 0.0850\n",
      "Epoch [40/50], Loss: 0.0846\n",
      "Epoch [41/50], Loss: 0.0842\n",
      "Epoch [42/50], Loss: 0.0838\n",
      "Epoch [43/50], Loss: 0.0835\n",
      "Epoch [44/50], Loss: 0.0831\n",
      "Epoch [45/50], Loss: 0.0828\n",
      "Epoch [46/50], Loss: 0.0825\n",
      "Epoch [47/50], Loss: 0.0821\n",
      "Epoch [48/50], Loss: 0.0818\n",
      "Epoch [49/50], Loss: 0.0816\n",
      "Epoch [50/50], Loss: 0.0813\n",
      "test performance :  [53.66430283 24.73065567 17.46709442 12.94058418 10.17650032]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(50.8825, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lr = 1e-3 # size of step\n",
    "res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-6,s=6*784),num_epochs=num_epochs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  4704 1e-06\n",
      "Epoch [1/50], Loss: 0.0983\n",
      "Epoch [2/50], Loss: 0.0849\n",
      "Epoch [3/50], Loss: 0.0743\n",
      "Epoch [4/50], Loss: 0.0664\n",
      "Epoch [5/50], Loss: 0.0607\n",
      "Epoch [6/50], Loss: 0.0566\n",
      "Epoch [7/50], Loss: 0.0540\n",
      "Epoch [8/50], Loss: 0.0523\n",
      "Epoch [9/50], Loss: 0.0514\n",
      "Epoch [10/50], Loss: 0.0505\n",
      "Epoch [11/50], Loss: 0.0500\n",
      "Epoch [12/50], Loss: 0.0500\n",
      "Epoch [13/50], Loss: 0.0500\n",
      "Epoch [14/50], Loss: 0.0497\n",
      "Epoch [15/50], Loss: 0.0497\n",
      "Epoch [16/50], Loss: 0.0496\n",
      "Epoch [17/50], Loss: 0.0494\n",
      "Epoch [18/50], Loss: 0.0496\n",
      "Epoch [19/50], Loss: 0.0497\n",
      "Epoch [20/50], Loss: 0.0494\n",
      "Epoch [21/50], Loss: 0.0500\n",
      "Epoch [22/50], Loss: 0.0496\n",
      "Epoch [23/50], Loss: 0.0500\n",
      "Epoch [24/50], Loss: 0.0493\n",
      "Epoch [25/50], Loss: 0.0495\n",
      "Epoch [26/50], Loss: 0.0493\n",
      "Epoch [27/50], Loss: 0.0489\n",
      "Epoch [28/50], Loss: 0.0493\n",
      "Epoch [29/50], Loss: 0.0491\n",
      "Epoch [30/50], Loss: 0.0491\n",
      "Epoch [31/50], Loss: 0.0489\n",
      "Epoch [32/50], Loss: 0.0492\n",
      "Epoch [33/50], Loss: 0.0489\n",
      "Epoch [34/50], Loss: 0.0492\n",
      "Epoch [35/50], Loss: 0.0490\n",
      "Epoch [36/50], Loss: 0.0492\n",
      "Epoch [37/50], Loss: 0.0488\n",
      "Epoch [38/50], Loss: 0.0494\n",
      "Epoch [39/50], Loss: 0.0489\n",
      "Epoch [40/50], Loss: 0.0493\n",
      "Epoch [41/50], Loss: 0.0488\n",
      "Epoch [42/50], Loss: 0.0489\n",
      "Epoch [43/50], Loss: 0.0485\n",
      "Epoch [44/50], Loss: 0.0491\n",
      "Epoch [45/50], Loss: 0.0488\n",
      "Epoch [46/50], Loss: 0.0489\n",
      "Epoch [47/50], Loss: 0.0488\n",
      "Epoch [48/50], Loss: 0.0490\n",
      "Epoch [49/50], Loss: 0.0488\n",
      "Epoch [50/50], Loss: 0.0490\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(464.3815, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(53.664303, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1501\n",
      "Epoch [2/50], Loss: 0.1244\n",
      "Epoch [3/50], Loss: 0.1042\n",
      "Epoch [4/50], Loss: 0.0894\n",
      "Epoch [5/50], Loss: 0.0790\n",
      "Epoch [6/50], Loss: 0.0721\n",
      "Epoch [7/50], Loss: 0.0676\n",
      "Epoch [8/50], Loss: 0.0649\n",
      "Epoch [9/50], Loss: 0.0632\n",
      "Epoch [10/50], Loss: 0.0624\n",
      "Epoch [11/50], Loss: 0.0620\n",
      "Epoch [12/50], Loss: 0.0617\n",
      "Epoch [13/50], Loss: 0.0617\n",
      "Epoch [14/50], Loss: 0.0616\n",
      "Epoch [15/50], Loss: 0.0615\n",
      "Epoch [16/50], Loss: 0.0615\n",
      "Epoch [17/50], Loss: 0.0614\n",
      "Epoch [18/50], Loss: 0.0615\n",
      "Epoch [19/50], Loss: 0.0615\n",
      "Epoch [20/50], Loss: 0.0615\n",
      "Epoch [21/50], Loss: 0.0614\n",
      "Epoch [22/50], Loss: 0.0613\n",
      "Epoch [23/50], Loss: 0.0614\n",
      "Epoch [24/50], Loss: 0.0615\n",
      "Epoch [25/50], Loss: 0.0614\n",
      "Epoch [26/50], Loss: 0.0613\n",
      "Epoch [27/50], Loss: 0.0614\n",
      "Epoch [28/50], Loss: 0.0613\n",
      "Epoch [29/50], Loss: 0.0612\n",
      "Epoch [30/50], Loss: 0.0613\n",
      "Epoch [31/50], Loss: 0.0612\n",
      "Epoch [32/50], Loss: 0.0612\n",
      "Epoch [33/50], Loss: 0.0613\n",
      "Epoch [34/50], Loss: 0.0614\n",
      "Epoch [35/50], Loss: 0.0613\n",
      "Epoch [36/50], Loss: 0.0614\n",
      "Epoch [37/50], Loss: 0.0613\n",
      "Epoch [38/50], Loss: 0.0612\n",
      "Epoch [39/50], Loss: 0.0613\n",
      "Epoch [40/50], Loss: 0.0612\n",
      "Epoch [41/50], Loss: 0.0611\n",
      "Epoch [42/50], Loss: 0.0612\n",
      "Epoch [43/50], Loss: 0.0612\n",
      "Epoch [44/50], Loss: 0.0612\n",
      "Epoch [45/50], Loss: 0.0612\n",
      "Epoch [46/50], Loss: 0.0612\n",
      "Epoch [47/50], Loss: 0.0610\n",
      "Epoch [48/50], Loss: 0.0612\n",
      "Epoch [49/50], Loss: 0.0611\n",
      "Epoch [50/50], Loss: 0.0611\n",
      "update data..\n",
      "task data norm and number entries: tensor(451.3575, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567  0.          0.          0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(49.46131, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1392\n",
      "Epoch [2/50], Loss: 0.1166\n",
      "Epoch [3/50], Loss: 0.0997\n",
      "Epoch [4/50], Loss: 0.0876\n",
      "Epoch [5/50], Loss: 0.0795\n",
      "Epoch [6/50], Loss: 0.0743\n",
      "Epoch [7/50], Loss: 0.0712\n",
      "Epoch [8/50], Loss: 0.0694\n",
      "Epoch [9/50], Loss: 0.0685\n",
      "Epoch [10/50], Loss: 0.0680\n",
      "Epoch [11/50], Loss: 0.0678\n",
      "Epoch [12/50], Loss: 0.0677\n",
      "Epoch [13/50], Loss: 0.0675\n",
      "Epoch [14/50], Loss: 0.0673\n",
      "Epoch [15/50], Loss: 0.0675\n",
      "Epoch [16/50], Loss: 0.0673\n",
      "Epoch [17/50], Loss: 0.0675\n",
      "Epoch [18/50], Loss: 0.0677\n",
      "Epoch [19/50], Loss: 0.0676\n",
      "Epoch [20/50], Loss: 0.0676\n",
      "Epoch [21/50], Loss: 0.0674\n",
      "Epoch [22/50], Loss: 0.0674\n",
      "Epoch [23/50], Loss: 0.0673\n",
      "Epoch [24/50], Loss: 0.0675\n",
      "Epoch [25/50], Loss: 0.0676\n",
      "Epoch [26/50], Loss: 0.0675\n",
      "Epoch [27/50], Loss: 0.0673\n",
      "Epoch [28/50], Loss: 0.0673\n",
      "Epoch [29/50], Loss: 0.0672\n",
      "Epoch [30/50], Loss: 0.0674\n",
      "Epoch [31/50], Loss: 0.0674\n",
      "Epoch [32/50], Loss: 0.0675\n",
      "Epoch [33/50], Loss: 0.0672\n",
      "Epoch [34/50], Loss: 0.0675\n",
      "Epoch [35/50], Loss: 0.0674\n",
      "Epoch [36/50], Loss: 0.0675\n",
      "Epoch [37/50], Loss: 0.0674\n",
      "Epoch [38/50], Loss: 0.0674\n",
      "Epoch [39/50], Loss: 0.0672\n",
      "Epoch [40/50], Loss: 0.0672\n",
      "Epoch [41/50], Loss: 0.0671\n",
      "Epoch [42/50], Loss: 0.0674\n",
      "Epoch [43/50], Loss: 0.0672\n",
      "Epoch [44/50], Loss: 0.0672\n",
      "Epoch [45/50], Loss: 0.0673\n",
      "Epoch [46/50], Loss: 0.0672\n",
      "Epoch [47/50], Loss: 0.0672\n",
      "Epoch [48/50], Loss: 0.0669\n",
      "Epoch [49/50], Loss: 0.0671\n",
      "Epoch [50/50], Loss: 0.0671\n",
      "update data..\n",
      "task data norm and number entries: tensor(435.2971, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567 17.46709442  0.          0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(52.40128, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1340\n",
      "Epoch [2/50], Loss: 0.1103\n",
      "Epoch [3/50], Loss: 0.0944\n",
      "Epoch [4/50], Loss: 0.0843\n",
      "Epoch [5/50], Loss: 0.0783\n",
      "Epoch [6/50], Loss: 0.0750\n",
      "Epoch [7/50], Loss: 0.0735\n",
      "Epoch [8/50], Loss: 0.0727\n",
      "Epoch [9/50], Loss: 0.0725\n",
      "Epoch [10/50], Loss: 0.0724\n",
      "Epoch [11/50], Loss: 0.0721\n",
      "Epoch [12/50], Loss: 0.0723\n",
      "Epoch [13/50], Loss: 0.0721\n",
      "Epoch [14/50], Loss: 0.0721\n",
      "Epoch [15/50], Loss: 0.0721\n",
      "Epoch [16/50], Loss: 0.0721\n",
      "Epoch [17/50], Loss: 0.0721\n",
      "Epoch [18/50], Loss: 0.0721\n",
      "Epoch [19/50], Loss: 0.0720\n",
      "Epoch [20/50], Loss: 0.0719\n",
      "Epoch [21/50], Loss: 0.0720\n",
      "Epoch [22/50], Loss: 0.0719\n",
      "Epoch [23/50], Loss: 0.0720\n",
      "Epoch [24/50], Loss: 0.0720\n",
      "Epoch [25/50], Loss: 0.0718\n",
      "Epoch [26/50], Loss: 0.0718\n",
      "Epoch [27/50], Loss: 0.0718\n",
      "Epoch [28/50], Loss: 0.0719\n",
      "Epoch [29/50], Loss: 0.0717\n",
      "Epoch [30/50], Loss: 0.0717\n",
      "Epoch [31/50], Loss: 0.0718\n",
      "Epoch [32/50], Loss: 0.0716\n",
      "Epoch [33/50], Loss: 0.0717\n",
      "Epoch [34/50], Loss: 0.0719\n",
      "Epoch [35/50], Loss: 0.0717\n",
      "Epoch [36/50], Loss: 0.0717\n",
      "Epoch [37/50], Loss: 0.0715\n",
      "Epoch [38/50], Loss: 0.0717\n",
      "Epoch [39/50], Loss: 0.0716\n",
      "Epoch [40/50], Loss: 0.0714\n",
      "Epoch [41/50], Loss: 0.0715\n",
      "Epoch [42/50], Loss: 0.0715\n",
      "Epoch [43/50], Loss: 0.0715\n",
      "Epoch [44/50], Loss: 0.0715\n",
      "Epoch [45/50], Loss: 0.0714\n",
      "Epoch [46/50], Loss: 0.0712\n",
      "Epoch [47/50], Loss: 0.0713\n",
      "Epoch [48/50], Loss: 0.0714\n",
      "Epoch [49/50], Loss: 0.0713\n",
      "Epoch [50/50], Loss: 0.0713\n",
      "update data..\n",
      "task data norm and number entries: tensor(450.5428, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [53.66430283 24.73065567 17.46709442 12.94058418  0.        ]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(51.762337, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1295\n",
      "Epoch [2/50], Loss: 0.1066\n",
      "Epoch [3/50], Loss: 0.0923\n",
      "Epoch [4/50], Loss: 0.0839\n",
      "Epoch [5/50], Loss: 0.0794\n",
      "Epoch [6/50], Loss: 0.0771\n",
      "Epoch [7/50], Loss: 0.0762\n",
      "Epoch [8/50], Loss: 0.0757\n",
      "Epoch [9/50], Loss: 0.0756\n",
      "Epoch [10/50], Loss: 0.0755\n",
      "Epoch [11/50], Loss: 0.0755\n",
      "Epoch [12/50], Loss: 0.0755\n",
      "Epoch [13/50], Loss: 0.0755\n",
      "Epoch [14/50], Loss: 0.0755\n",
      "Epoch [15/50], Loss: 0.0755\n",
      "Epoch [16/50], Loss: 0.0755\n",
      "Epoch [17/50], Loss: 0.0754\n",
      "Epoch [18/50], Loss: 0.0754\n",
      "Epoch [19/50], Loss: 0.0754\n",
      "Epoch [20/50], Loss: 0.0754\n",
      "Epoch [21/50], Loss: 0.0754\n",
      "Epoch [22/50], Loss: 0.0754\n",
      "Epoch [23/50], Loss: 0.0754\n",
      "Epoch [24/50], Loss: 0.0753\n",
      "Epoch [25/50], Loss: 0.0753\n",
      "Epoch [26/50], Loss: 0.0754\n",
      "Epoch [27/50], Loss: 0.0753\n",
      "Epoch [28/50], Loss: 0.0753\n",
      "Epoch [29/50], Loss: 0.0753\n",
      "Epoch [30/50], Loss: 0.0753\n",
      "Epoch [31/50], Loss: 0.0753\n",
      "Epoch [32/50], Loss: 0.0752\n",
      "Epoch [33/50], Loss: 0.0752\n",
      "Epoch [34/50], Loss: 0.0752\n",
      "Epoch [35/50], Loss: 0.0752\n",
      "Epoch [36/50], Loss: 0.0753\n",
      "Epoch [37/50], Loss: 0.0752\n",
      "Epoch [38/50], Loss: 0.0754\n",
      "Epoch [39/50], Loss: 0.0752\n",
      "Epoch [40/50], Loss: 0.0750\n",
      "Epoch [41/50], Loss: 0.0751\n",
      "Epoch [42/50], Loss: 0.0751\n",
      "Epoch [43/50], Loss: 0.0751\n",
      "Epoch [44/50], Loss: 0.0751\n",
      "Epoch [45/50], Loss: 0.0751\n",
      "Epoch [46/50], Loss: 0.0751\n",
      "Epoch [47/50], Loss: 0.0751\n",
      "Epoch [48/50], Loss: 0.0750\n",
      "Epoch [49/50], Loss: 0.0750\n",
      "Epoch [50/50], Loss: 0.0751\n",
      "test performance :  [53.66430283 24.73065567 17.46709442 12.94058418 17.39788246]\n",
      "individual errors:  [array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(86.98941, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lr = 1e-4 # size of step\n",
    "res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-6,s=6*784),num_epochs=num_epochs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EWC++  4704 1e-06\n",
      "Epoch [1/50], Loss: 0.0993\n",
      "Epoch [2/50], Loss: 0.0498\n",
      "Epoch [3/50], Loss: 0.0478\n",
      "Epoch [4/50], Loss: 0.0463\n",
      "Epoch [5/50], Loss: 0.0448\n",
      "Epoch [6/50], Loss: 0.0428\n",
      "Epoch [7/50], Loss: 0.0406\n",
      "Epoch [8/50], Loss: 0.0393\n",
      "Epoch [9/50], Loss: 0.0371\n",
      "Epoch [10/50], Loss: 0.0356\n",
      "Epoch [11/50], Loss: 0.0336\n",
      "Epoch [12/50], Loss: 0.0319\n",
      "Epoch [13/50], Loss: 0.0299\n",
      "Epoch [14/50], Loss: 0.0289\n",
      "Epoch [15/50], Loss: 0.0270\n",
      "Epoch [16/50], Loss: 0.0250\n",
      "Epoch [17/50], Loss: 0.0237\n",
      "Epoch [18/50], Loss: 0.0228\n",
      "Epoch [19/50], Loss: 0.0209\n",
      "Epoch [20/50], Loss: 0.0195\n",
      "Epoch [21/50], Loss: 0.0193\n",
      "Epoch [22/50], Loss: 0.0173\n",
      "Epoch [23/50], Loss: 0.0173\n",
      "Epoch [24/50], Loss: 0.0164\n",
      "Epoch [25/50], Loss: 0.0153\n",
      "Epoch [26/50], Loss: 0.0147\n",
      "Epoch [27/50], Loss: 0.0137\n",
      "Epoch [28/50], Loss: 0.0127\n",
      "Epoch [29/50], Loss: 0.0112\n",
      "Epoch [30/50], Loss: 0.0107\n",
      "Epoch [31/50], Loss: 0.0106\n",
      "Epoch [32/50], Loss: 0.0104\n",
      "Epoch [33/50], Loss: 0.0096\n",
      "Epoch [34/50], Loss: 0.0095\n",
      "Epoch [35/50], Loss: 0.0083\n",
      "Epoch [36/50], Loss: 0.0093\n",
      "Epoch [37/50], Loss: 0.0084\n",
      "Epoch [38/50], Loss: 0.0076\n",
      "Epoch [39/50], Loss: 0.0079\n",
      "Epoch [40/50], Loss: 0.0074\n",
      "Epoch [41/50], Loss: 0.0059\n",
      "Epoch [42/50], Loss: 0.0058\n",
      "Epoch [43/50], Loss: 0.0067\n",
      "Epoch [44/50], Loss: 0.0066\n",
      "Epoch [45/50], Loss: 0.0058\n",
      "Epoch [46/50], Loss: 0.0058\n",
      "Epoch [47/50], Loss: 0.0053\n",
      "Epoch [48/50], Loss: 0.0058\n",
      "Epoch [49/50], Loss: 0.0055\n",
      "Epoch [50/50], Loss: 0.0050\n",
      "generate task data..\n",
      "task data norm and number entries: tensor(462.4635, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.62174988  0.          0.          0.          0.        ]\n",
      "individual errors:  [array(99.62175, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1543\n",
      "Epoch [2/50], Loss: 0.0671\n",
      "Epoch [3/50], Loss: 0.0646\n",
      "Epoch [4/50], Loss: 0.0636\n",
      "Epoch [5/50], Loss: 0.0633\n",
      "Epoch [6/50], Loss: 0.0630\n",
      "Epoch [7/50], Loss: 0.0616\n",
      "Epoch [8/50], Loss: 0.0608\n",
      "Epoch [9/50], Loss: 0.0600\n",
      "Epoch [10/50], Loss: 0.0597\n",
      "Epoch [11/50], Loss: 0.0586\n",
      "Epoch [12/50], Loss: 0.0575\n",
      "Epoch [13/50], Loss: 0.0562\n",
      "Epoch [14/50], Loss: 0.0555\n",
      "Epoch [15/50], Loss: 0.0545\n",
      "Epoch [16/50], Loss: 0.0534\n",
      "Epoch [17/50], Loss: 0.0528\n",
      "Epoch [18/50], Loss: 0.0519\n",
      "Epoch [19/50], Loss: 0.0510\n",
      "Epoch [20/50], Loss: 0.0496\n",
      "Epoch [21/50], Loss: 0.0492\n",
      "Epoch [22/50], Loss: 0.0484\n",
      "Epoch [23/50], Loss: 0.0475\n",
      "Epoch [24/50], Loss: 0.0468\n",
      "Epoch [25/50], Loss: 0.0462\n",
      "Epoch [26/50], Loss: 0.0446\n",
      "Epoch [27/50], Loss: 0.0453\n",
      "Epoch [28/50], Loss: 0.0443\n",
      "Epoch [29/50], Loss: 0.0449\n",
      "Epoch [30/50], Loss: 0.0428\n",
      "Epoch [31/50], Loss: 0.0417\n",
      "Epoch [32/50], Loss: 0.0409\n",
      "Epoch [33/50], Loss: 0.0408\n",
      "Epoch [34/50], Loss: 0.0401\n",
      "Epoch [35/50], Loss: 0.0389\n",
      "Epoch [36/50], Loss: 0.0386\n",
      "Epoch [37/50], Loss: 0.0385\n",
      "Epoch [38/50], Loss: 0.0370\n",
      "Epoch [39/50], Loss: 0.0369\n",
      "Epoch [40/50], Loss: 0.0356\n",
      "Epoch [41/50], Loss: 0.0367\n",
      "Epoch [42/50], Loss: 0.0348\n",
      "Epoch [43/50], Loss: 0.0350\n",
      "Epoch [44/50], Loss: 0.0336\n",
      "Epoch [45/50], Loss: 0.0352\n",
      "Epoch [46/50], Loss: 0.0334\n",
      "Epoch [47/50], Loss: 0.0326\n",
      "Epoch [48/50], Loss: 0.0328\n",
      "Epoch [49/50], Loss: 0.0318\n",
      "Epoch [50/50], Loss: 0.0323\n",
      "update data..\n",
      "task data norm and number entries: tensor(454.3265, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.62174988 66.75859833  0.          0.          0.        ]\n",
      "individual errors:  [array(39.148937, dtype=float32), array(94.36826, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1446\n",
      "Epoch [2/50], Loss: 0.0766\n",
      "Epoch [3/50], Loss: 0.0737\n",
      "Epoch [4/50], Loss: 0.0741\n",
      "Epoch [5/50], Loss: 0.0733\n",
      "Epoch [6/50], Loss: 0.0727\n",
      "Epoch [7/50], Loss: 0.0710\n",
      "Epoch [8/50], Loss: 0.0699\n",
      "Epoch [9/50], Loss: 0.0699\n",
      "Epoch [10/50], Loss: 0.0681\n",
      "Epoch [11/50], Loss: 0.0682\n",
      "Epoch [12/50], Loss: 0.0667\n",
      "Epoch [13/50], Loss: 0.0664\n",
      "Epoch [14/50], Loss: 0.0651\n",
      "Epoch [15/50], Loss: 0.0637\n",
      "Epoch [16/50], Loss: 0.0634\n",
      "Epoch [17/50], Loss: 0.0626\n",
      "Epoch [18/50], Loss: 0.0621\n",
      "Epoch [19/50], Loss: 0.0609\n",
      "Epoch [20/50], Loss: 0.0599\n",
      "Epoch [21/50], Loss: 0.0580\n",
      "Epoch [22/50], Loss: 0.0586\n",
      "Epoch [23/50], Loss: 0.0570\n",
      "Epoch [24/50], Loss: 0.0560\n",
      "Epoch [25/50], Loss: 0.0557\n",
      "Epoch [26/50], Loss: 0.0547\n",
      "Epoch [27/50], Loss: 0.0538\n",
      "Epoch [28/50], Loss: 0.0528\n",
      "Epoch [29/50], Loss: 0.0521\n",
      "Epoch [30/50], Loss: 0.0522\n",
      "Epoch [31/50], Loss: 0.0518\n",
      "Epoch [32/50], Loss: 0.0510\n",
      "Epoch [33/50], Loss: 0.0495\n",
      "Epoch [34/50], Loss: 0.0492\n",
      "Epoch [35/50], Loss: 0.0487\n",
      "Epoch [36/50], Loss: 0.0469\n",
      "Epoch [37/50], Loss: 0.0468\n",
      "Epoch [38/50], Loss: 0.0471\n",
      "Epoch [39/50], Loss: 0.0465\n",
      "Epoch [40/50], Loss: 0.0448\n",
      "Epoch [41/50], Loss: 0.0451\n",
      "Epoch [42/50], Loss: 0.0444\n",
      "Epoch [43/50], Loss: 0.0433\n",
      "Epoch [44/50], Loss: 0.0431\n",
      "Epoch [45/50], Loss: 0.0429\n",
      "Epoch [46/50], Loss: 0.0413\n",
      "Epoch [47/50], Loss: 0.0420\n",
      "Epoch [48/50], Loss: 0.0411\n",
      "Epoch [49/50], Loss: 0.0393\n",
      "Epoch [50/50], Loss: 0.0409\n",
      "update data..\n",
      "task data norm and number entries: tensor(437.6384, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.62174988 66.75859833 40.17470551  0.          0.        ]\n",
      "individual errors:  [array(2.6477542, dtype=float32), array(23.212536, dtype=float32), array(94.66382, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1372\n",
      "Epoch [2/50], Loss: 0.0777\n",
      "Epoch [3/50], Loss: 0.0745\n",
      "Epoch [4/50], Loss: 0.0734\n",
      "Epoch [5/50], Loss: 0.0718\n",
      "Epoch [6/50], Loss: 0.0709\n",
      "Epoch [7/50], Loss: 0.0696\n",
      "Epoch [8/50], Loss: 0.0680\n",
      "Epoch [9/50], Loss: 0.0674\n",
      "Epoch [10/50], Loss: 0.0657\n",
      "Epoch [11/50], Loss: 0.0649\n",
      "Epoch [12/50], Loss: 0.0631\n",
      "Epoch [13/50], Loss: 0.0624\n",
      "Epoch [14/50], Loss: 0.0597\n",
      "Epoch [15/50], Loss: 0.0589\n",
      "Epoch [16/50], Loss: 0.0582\n",
      "Epoch [17/50], Loss: 0.0564\n",
      "Epoch [18/50], Loss: 0.0549\n",
      "Epoch [19/50], Loss: 0.0535\n",
      "Epoch [20/50], Loss: 0.0520\n",
      "Epoch [21/50], Loss: 0.0511\n",
      "Epoch [22/50], Loss: 0.0495\n",
      "Epoch [23/50], Loss: 0.0489\n",
      "Epoch [24/50], Loss: 0.0480\n",
      "Epoch [25/50], Loss: 0.0472\n",
      "Epoch [26/50], Loss: 0.0457\n",
      "Epoch [27/50], Loss: 0.0456\n",
      "Epoch [28/50], Loss: 0.0435\n",
      "Epoch [29/50], Loss: 0.0427\n",
      "Epoch [30/50], Loss: 0.0429\n",
      "Epoch [31/50], Loss: 0.0400\n",
      "Epoch [32/50], Loss: 0.0399\n",
      "Epoch [33/50], Loss: 0.0392\n",
      "Epoch [34/50], Loss: 0.0395\n",
      "Epoch [35/50], Loss: 0.0376\n",
      "Epoch [36/50], Loss: 0.0375\n",
      "Epoch [37/50], Loss: 0.0365\n",
      "Epoch [38/50], Loss: 0.0358\n",
      "Epoch [39/50], Loss: 0.0344\n",
      "Epoch [40/50], Loss: 0.0351\n",
      "Epoch [41/50], Loss: 0.0340\n",
      "Epoch [42/50], Loss: 0.0327\n",
      "Epoch [43/50], Loss: 0.0324\n",
      "Epoch [44/50], Loss: 0.0330\n",
      "Epoch [45/50], Loss: 0.0313\n",
      "Epoch [46/50], Loss: 0.0316\n",
      "Epoch [47/50], Loss: 0.0305\n",
      "Epoch [48/50], Loss: 0.0306\n",
      "Epoch [49/50], Loss: 0.0308\n",
      "Epoch [50/50], Loss: 0.0295\n",
      "update data..\n",
      "task data norm and number entries: tensor(455.0964, device='cuda:0') torch.Size([4704, 31370])\n",
      "..done\n",
      "test performance :  [99.62174988 66.75859833 40.17470551 31.42702866  0.        ]\n",
      "individual errors:  [array(0.23640661, dtype=float32), array(1.8609207, dtype=float32), array(24.919956, dtype=float32), array(98.690834, dtype=float32)]\n",
      "Epoch [1/50], Loss: 0.1344\n",
      "Epoch [2/50], Loss: 0.0829\n",
      "Epoch [3/50], Loss: 0.0807\n",
      "Epoch [4/50], Loss: 0.0801\n",
      "Epoch [5/50], Loss: 0.0796\n",
      "Epoch [6/50], Loss: 0.0796\n",
      "Epoch [7/50], Loss: 0.0781\n",
      "Epoch [8/50], Loss: 0.0776\n",
      "Epoch [9/50], Loss: 0.0762\n",
      "Epoch [10/50], Loss: 0.0752\n",
      "Epoch [11/50], Loss: 0.0746\n",
      "Epoch [12/50], Loss: 0.0750\n",
      "Epoch [13/50], Loss: 0.0726\n",
      "Epoch [14/50], Loss: 0.0740\n",
      "Epoch [15/50], Loss: 0.0714\n",
      "Epoch [16/50], Loss: 0.0704\n",
      "Epoch [17/50], Loss: 0.0699\n",
      "Epoch [18/50], Loss: 0.0691\n",
      "Epoch [19/50], Loss: 0.0681\n",
      "Epoch [20/50], Loss: 0.0677\n",
      "Epoch [21/50], Loss: 0.0673\n",
      "Epoch [22/50], Loss: 0.0671\n",
      "Epoch [23/50], Loss: 0.0653\n",
      "Epoch [24/50], Loss: 0.0643\n",
      "Epoch [25/50], Loss: 0.0648\n",
      "Epoch [26/50], Loss: 0.0635\n",
      "Epoch [27/50], Loss: 0.0641\n",
      "Epoch [28/50], Loss: 0.0620\n",
      "Epoch [29/50], Loss: 0.0607\n",
      "Epoch [30/50], Loss: 0.0608\n",
      "Epoch [31/50], Loss: 0.0616\n",
      "Epoch [32/50], Loss: 0.0590\n",
      "Epoch [33/50], Loss: 0.0589\n",
      "Epoch [34/50], Loss: 0.0579\n",
      "Epoch [35/50], Loss: 0.0570\n",
      "Epoch [36/50], Loss: 0.0560\n",
      "Epoch [37/50], Loss: 0.0568\n",
      "Epoch [38/50], Loss: 0.0576\n",
      "Epoch [39/50], Loss: 0.0557\n",
      "Epoch [40/50], Loss: 0.0561\n",
      "Epoch [41/50], Loss: 0.0557\n",
      "Epoch [42/50], Loss: 0.0542\n",
      "Epoch [43/50], Loss: 0.0546\n",
      "Epoch [44/50], Loss: 0.0546\n",
      "Epoch [45/50], Loss: 0.0543\n",
      "Epoch [46/50], Loss: 0.0527\n",
      "Epoch [47/50], Loss: 0.0524\n",
      "Epoch [48/50], Loss: 0.0526\n",
      "Epoch [49/50], Loss: 0.0529\n",
      "Epoch [50/50], Loss: 0.0502\n",
      "test performance :  [99.62174988 66.75859833 40.17470551 31.42702866 30.09048843]\n",
      "individual errors:  [array(0., dtype=float32), array(0.04897159, dtype=float32), array(0.16008538, dtype=float32), array(55.790535, dtype=float32), array(94.45285, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "lr = 5e-3 # size of step\n",
    "res,inds = run_simulation( get_random_feature_model(),train_loaders,test_loaders,EWCplusplus(lam=1e-6,s=6*784),num_epochs=num_epochs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
